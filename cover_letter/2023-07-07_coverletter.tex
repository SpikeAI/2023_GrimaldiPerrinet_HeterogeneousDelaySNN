% !TEX encoding = UTF-8 Unicode
% !TeX TS-program = pdfLaTeX
% !TeX spellcheck = en-US
% !BIB TS-program = bibtex
% -*- coding: UTF-8; -*-
% vim: set fenc=utf-8
%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[10pt,english]{article}

\usepackage{charter,graphicx}
\usepackage[margin=1in]{geometry}

\usepackage{natbib}

\usepackage{hyperref,tabularx}
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{.4pt}% Default header rule
\renewcommand{\footrulewidth}{0pt}% No footer rule
\fancyhf{}% Clear header/footer
\fancypagestyle{plain}{
  \renewcommand{\headrulewidth}{0pt}% No header rule
  \renewcommand{\footrulewidth}{.4pt}% Default footer rule
  \fancyhf{}% Clear header/footer
}
\usepackage%[disable]	% uncomment to hide all the notes
	{todonotes}
\newcommand{\noteRev}[1]{\todo[color=blue!10, inline]{#1}}

\AtBeginDocument{\thispagestyle{plain}}

\setlength{\parindent}{0pt}
\setlength{\parskip}{.5\baselineskip plus 1pt minus 1pt}
\usepackage[utf8]{inputenc}%
\usepackage{babel}%
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@zfancyhead}{\fancy@reset}{\f@nch@reset}{}{}
\patchcmd{\@set@em@up}{\f@ncyolh}{\f@nch@olh}{}{}
\patchcmd{\@set@em@up}{\f@ncyolh}{\f@nch@olh}{}{}
\patchcmd{\@set@em@up}{\f@ncyorh}{\f@nch@orh}{}{}
\makeatother
%\usepackage{kpfonts}
%\usepackage{babel}
%\usepackage{csquotes}
\usepackage{url}
\usepackage{charter} % Use the Charter font for the document text
%----------------------------------------------------------------------------------------
%	YOUR NAME AND CONTACT INFORMATION
%----------------------------------------------------------------------------------------
%Jean-Nicolas Jérémie\\
%Institute of Neuroscience of la Timone\\
%CNRS - Aix Marseille University\\
%27, boulevard Jean Moulin\\
%13005 Marseille, France
\newcommand{\LastName}{Perrinet}%Grimaldi}%{
\newcommand{\FirstName}{Laurent U.}%Antoine}%{
\newcommand{\Institute}{Institut de Neurosciences de la Timone, CNRS / Aix-Marseille Universit\'e}%
\newcommand{\Address}{27, Bd. Jean Moulin, 13385 Marseille Cedex 5, France}%
\newcommand{\Website}{\url{https://laurentperrinet.github.io/}}%
\newcommand{\Email}{\url{antoine.grimaldi@univ-amu.fr}}%
%----------------------------------------------------------------------------------------
%	YOUR DOCUMENT
%----------------------------------------------------------------------------------------
\usepackage[document]{ragged2e}
\begin{document}
%\centerline{
\includegraphics[width=.4\textwidth]{troislogos.png}
%}
\\
\vspace{.1\baselineskip}
\hrulefill
\vspace{.1\baselineskip}

\begin{flushright}
	\FirstName\  \LastName\  \\
	\Institute\\[6pt]
	\Address\\%[6pt]
	\Website \\
	  Email: \Email \\[6pt]
\end{flushright}
\justifying
\vspace{1\baselineskip}
%----------------------------------------------------------------------------------------
%	ADDRESSEE AND GREETING/CLOSING
%----------------------------------------------------------------------------------------
%À qui de droit,\\
Marseille, 
% February 20th, 2023%
\today
\\[12pt] % Date
	
Dear editor,

%----------------------------------------------------------------------------------------
%	LETTER CONTENT
%----------------------------------------------------------------------------------------
Please find attached the revised manuscript entitled ``Learning heterogeneous delays in a layer of spiking neurons for fast motion detection'' for consideration as an article in \emph{Biological Cybernetics}. Both authors were involved in the work, approved the manuscript, and agreed to revise it. The original submission ID is a7f45f8e-87d6-4a30-ac7f-9f0c94e2592a. 

Our manuscript presents an innovative approach inspired by neuroscience to address challenges in computer vision, particularly when handling large datasets. We propose the use of an event-based representation and introduce a novel spiking neuron method that utilizes heterogeneous delays on different synapses. This method effectively detects spiking motifs, as demonstrated through experiments conducted on synthetic event-based data. Our results indicate that this approach has the potential to pave the way for future spiking neural network algorithms, offering comparable performance to their analog counterparts while consuming less energy.

We express our gratitude to the reviewer for their positive assessment, which motivated us to further enhance our manuscript. In response to their valuable comments, we have undertaken a major revision of the paper. Notably, we have expanded our experimental results to include natural scenes, thereby increasing the broader impact of our work. As we have extensively modified and streamlined various sections of the manuscript for improved clarity, we have not provided a tracked changes version of the revision. However, we are prepared to furnish such a document upon request. To address the reviewer's comments, we have provided a detailed response below, referring to the relevant sections of the manuscript.

%----------------------------------------------------------------------------------------
Sincerely yours,

\FirstName\ \LastName \\

\includegraphics[height=3cm]{~/quantic/RTC/signature_LuP.jpg}

\newpage

\textbf{REVIEWER REPORTS}

In the following we will give response to reviewers using: \noteRev{framed boxes.}

\textbf{Reviewer \#1}

\begin{quote}
	The author's organization of the paper is much clearer than last time, and I suggest making the following modifications:
	1. For the natural-like texture images used, the author carried out some operations, such as changing texture parameters, etc. I suggest that the authors give 1-2 examples of these images corresponding to the different subgraphs in Figure 5, such as isotropic textures and grating-like textures.
\end{quote} 

\noteRev{We thank the reviewer for his constructive comments. While keeping the same computational framework, this encouraged us to extend our task from using natural-like textures to actual natural images. This was further extended by using biologically inspired eye movements to generate dynamic scenes with known ground truth. We retained the use of synthetic textures to evaluate the relevant image parameters for motion detection, and we drew the analogies of our model to those found in the neurophysiological and psychophysical literature. We have added a subgraph inset to illustrate the changes in parameters for the generation of figures.}

\begin{quote}
	2. Experiments that assess accuracy should be repeated many times (and give deviation) to eliminate data uncertainty.
\end{quote} 
 
\noteRev{We have repeated the testing of our model using $200$ movies and report less variable estimates for accuracy. Thank you for this suggestion.}

\begin{quote}
	3. I would still recommend that the authors add experiments on other data sets, or compare with other works  on the current data set.
\end{quote} 
 
\noteRev{By extending the learning and testing of our model to this redefined motion detection task, we hope to have provided a more thorough exploration of the capabilities of our model. The accuracy comparison was also performed on the synthetic texture dataset to provide a direct comparison with biological observations.}


\begin{quote}
	4. There are two “observe” in line 355.
\end{quote} 
 
 \noteRev{Fixed.}


\end{document}

