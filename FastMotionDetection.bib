
@article{macdonald_neuromorphic_2022,
	title = {Neuromorphic {Tactile} {Edge} {Orientation} {Classification} in an {Unsupervised} {Spiking} {Neural} {Network}},
	volume = {22},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/18/6998},
	doi = {10.3390/s22186998},
	abstract = {Dexterous manipulation in robotic hands relies on an accurate sense of artificial touch. Here we investigate neuromorphic tactile sensation with an event-based optical tactile sensor combined with spiking neural networks for edge orientation detection. The sensor incorporates an event-based vision system (mini-eDVS) into a low-form factor artificial fingertip (the NeuroTac). The processing of tactile information is performed through a Spiking Neural Network with unsupervised Spike-Timing-Dependent Plasticity (STDP) learning, and the resultant output is classified with a 3-nearest neighbours classifier. Edge orientations were classified in 10-degree increments while tapping vertically downward and sliding horizontally across the edge. In both cases, we demonstrate that the sensor is able to reliably detect edge orientation, and could lead to accurate, bio-inspired, tactile processing in robotics and prosthetics applications.},
	language = {en},
	number = {18},
	urldate = {2022-09-26},
	journal = {Sensors},
	author = {Macdonald, Fraser L. A. and Lepora, Nathan F. and Conradt, Jörg and Ward-Cherrier, Benjamin},
	month = jan,
	year = {2022},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {⛔ No INSPIRE recid found},
	pages = {6998},
}

@article{izhikevich_polychronization_2006,
	title = {Polychronization: {Computation} with spikes},
	volume = {18},
	issn = {0899-7667},
	shorttitle = {Polychronization},
	url = {https://doi.org/10.1162/089976606775093882},
	doi = {10.1162/089976606775093882},
	abstract = {We present a minimal spiking network that can polychronize, that is, exhibit reproducible time-locked but not synchronous firing patterns with millisecond precision, as in synfire braids. The network consists of cortical spiking neurons with axonal conduction delays and spike-timing-dependent plasticity (STDP); a ready-to-use MATLAB code is included. It exhibits sleeplike oscillations, gamma (40 Hz) rhythms, conversion of firing rates to spike timings, and other interesting regimes. Due to the interplay between the delays and STDP, the spiking neurons spontaneously self-organize into groups and generate patterns of stereotypical polychronous activity. To our surprise, the number of coexisting polychronous groups far exceeds the number of neurons in the network, resulting in an unprecedented memory capacity of the system. We speculate on the significance of polychrony to the theory of neuronal group selection (TNGS, neural Darwinism), cognitive neural computations, binding and gamma rhythm, mechanisms of attention, and consciousness as “attention to memories.”},
	number = {2},
	urldate = {2018-09-24},
	journal = {Neural Computation},
	author = {Izhikevich, Eugene M.},
	month = feb,
	year = {2006},
	note = {publisher: MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …
tex.ids= izhikevich2006polychronization},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {245--282},
}

@article{berens_fast_2012,
	title = {A {Fast} and {Simple} {Population} {Code} for {Orientation} in {Primate} {V1}},
	volume = {32},
	copyright = {Copyright © 2012 the authors 0270-6474/12/3210618-09\$15.00/0. This article is freely available online through the J Neurosci Open Choice option.},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/31/10618},
	doi = {10.1523/jneurosci.1335-12.2012},
	abstract = {Orientation tuning has been a classic model for understanding single-neuron computation in the neocortex. However, little is known about how orientation can be read out from the activity of neural populations, in particular in alert animals. Our study is a first step toward that goal. We recorded from up to 20 well isolated single neurons in the primary visual cortex of alert macaques simultaneously and applied a simple, neurally plausible decoder to read out the population code. We focus on two questions: First, what are the time course and the timescale at which orientation can be read out from the population response? Second, how complex does the decoding mechanism in a downstream neuron have to be to reliably discriminate between visual stimuli with different orientations? We show that the neural ensembles in primary visual cortex of awake macaques represent orientation in a way that facilitates a fast and simple readout mechanism: With an average latency of 30–80 ms, the population code can be read out instantaneously with a short integration time of only tens of milliseconds, and neither stimulus contrast nor correlations need to be taken into account to compute the optimal synaptic weight pattern. Our study shows that—similar to the case of single-neuron computation—the representation of orientation in the spike patterns of neural populations can serve as an exemplary case for understanding the computations performed by neural ensembles underlying visual processing during behavior.},
	language = {en},
	number = {31},
	urldate = {2020-11-09},
	journal = {Journal of Neuroscience},
	author = {Berens, Philipp and Ecker, Alexander S. and Cotton, R. James and Ma, Wei Ji and Bethge, Matthias and Tolias, Andreas S.},
	month = aug,
	year = {2012},
	pmid = {22855811},
	note = {00000
tex.ids= Berens12a
publisher: Society for Neuroscience
section: Articles},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {10618--10626},
}

@techreport{bernert_fully_2017,
	title = {Fully unsupervised online spike sorting based on an artificial spiking neural network},
	copyright = {© 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/236224v1},
	abstract = {Spike sorting is a crucial step of neural data processing widely used in neuroscience and neuroprosthetics. However, current methods remain not fully automatic and require heavy computations making them not embeddable in implantable devices. To overcome these limitations, we propose a novel method based on an artificial spiking neural network designed to process neural data online and completely automatically. An input layer continuously encodes the data stream into artificial spike trains, which are then processed by two further layers to output artificial trains of spikes reproducing the real spiking activity present in the input signal. The proposed method can be adapted to process several channels simultaneously in the case of tetrode recordings. It outperforms two existing algorithms at low SNR and has the advantage to be compatible with neuromorphic computing and the perspective of being embedded in very low-power analog systems for future implantable devices serving neurorehabilitation applications.},
	language = {en},
	urldate = {2022-04-08},
	institution = {bioRxiv},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2017},
	doi = {10.1101/236224},
	note = {tex.ids= Bernert2017a
section: New Results
type: article},
	keywords = {⛔ No INSPIRE recid found},
	pages = {236224},
}

@article{bernert_attention-based_2018,
	title = {An {Attention}-{Based} {Spiking} {Neural} {Network} for {Unsupervised} {Spike}-{Sorting}},
	volume = {29},
	issn = {0129-0657},
	url = {https://www.worldscientific.com/doi/10.1142/S0129065718500594},
	doi = {10.1142/s0129065718500594},
	abstract = {Bio-inspired computing using artificial spiking neural networks promises performances outperforming currently available computational approaches. Yet, the number of applications of such networks remains limited due to the absence of generic training procedures for complex pattern recognition, which require the design of dedicated architectures for each situation. We developed a spike-timing-dependent plasticity (STDP) spiking neural network (SSN) to address spike-sorting, a central pattern recognition problem in neuroscience. This network is designed to process an extracellular neural signal in an online and unsupervised fashion. The signal stream is continuously fed to the network and processed through several layers to output spike trains matching the truth after a short learning period requiring only few data. The network features an attention mechanism to handle the scarcity of action potential occurrences in the signal, and a threshold adaptation mechanism to handle patterns with different sizes. This method outperforms two existing spike-sorting algorithms at low signal-to-noise ratio (SNR) and can be adapted to process several channels simultaneously in the case of tetrode recordings. Such attention-based STDP network applied to spike-sorting opens perspectives to embed neuromorphic processing of neural data in future brain implants.},
	number = {08},
	urldate = {2021-01-26},
	journal = {International Journal of Neural Systems},
	author = {Bernert, Marie and Yvert, Blaise},
	month = dec,
	year = {2018},
	note = {00016
tex.ids= Bernert2019, Bernert2019a
publisher: World Scientific Publishing Co.},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1850059},
}

@article{haag_fly_2004,
	title = {Fly motion vision is based on {Reichardt} detectors regardless of the signal-to-noise ratio},
	volume = {101},
	issn = {0027-8424},
	doi = {10.1073/pnas.0407368101},
	abstract = {The computational structure of an optimal motion detector was proposed to depend on the signal-to-noise ratio (SNR) of the stimulus: At low SNR, the optimal motion detector should be a correlation or "Reichardt" type, whereas at high SNR, the detector would employ a gradient scheme [Potters, M. \& Bialek, W. (1994) J. Physiol. (Paris) 4, 1755-1775]. Although a large body of experiments supports the Reichardt detector as the processing scheme leading to direction selectivity in fly motion vision, in most of these studies the SNR was rather low. We therefore reinvestigated the question over a much larger SNR range. Using 2-photon microscopy, we found that local dendritic [Ca(2+)] modulations, which are characteristic of Reichardt detectors, occur in response to drifting gratings over a wide range of luminance levels and contrasts. We also explored, as another fingerprint of Reichardt detectors, the dependence of the velocity optimum on the pattern wavelength. Again, we found Reichardt-typical behavior throughout the whole luminance and contrast range tested. Our results, therefore, provide strong evidence that only a single elementary processing scheme is used in fly motion vision.},
	language = {eng},
	number = {46},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Haag, J. and Denk, W. and Borst, A.},
	month = nov,
	year = {2004},
	pmid = {15534201},
	pmcid = {PMC526200},
	keywords = {Algorithms, Animals, Calcium Signaling, Diptera, Electrophysiology, Female, Models, Neurological, Motion, Motion Perception, Optics and Photonics, Photic Stimulation, Vision, Ocular, biology, delay-learning, insects, ⛔ No INSPIRE recid found},
	pages = {16333--16338},
}

@article{paredes-valles_unsupervised_2020,
	title = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}: {From} {Events} to {Global} {Motion} {Perception}},
	volume = {42},
	issn = {1939-3539},
	shorttitle = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}},
	doi = {10.1109/tpami.2019.2903179},
	abstract = {The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNN library, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Paredes-Vallés, Federico and Scheper, Kirk Y. W. and de Croon, Guido C. H. E.},
	month = aug,
	year = {2020},
	note = {00047 
Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Biological information theory, Biological system modeling, Biomedical optical imaging, Event-based vision, Neurons, Optical sensors, Vision sensors, Visualization, feature extraction, motion detection, neural nets, neuromorphic computing, unsupervised learning, ⛔ No INSPIRE recid found},
	pages = {2051--2064},
}

@article{benosman_event-based_2014,
	title = {Event-{Based} {Visual} {Flow}},
	volume = {25},
	issn = {2162-237X, 2162-2388},
	url = {https://www.neuromorphic-vision.com/public/publications/3/publication.pdf},
	doi = {10.1109/tnnls.2013.2273537},
	abstract = {This paper introduces a new methodology to compute dense visual ﬂow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artiﬁcial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual ﬂow from the local properties of events’ spatiotemporal space. We will show that precise visual ﬂow orientation and amplitude can be estimated using a local differential approach on the surface deﬁned by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion ﬂow with microsecond accuracy and at very low computational cost.},
	language = {en},
	number = {2},
	urldate = {2022-02-01},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and {Sio-Hoi Ieng} and Bartolozzi, Chiara},
	month = feb,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {407--417},
}

@inproceedings{lee_real-time_2014,
	address = {Paris, France},
	title = {Real-time motion estimation based on event-based vision sensor},
	isbn = {978-1-4799-5751-4},
	url = {http://ieeexplore.ieee.org/document/7025040/},
	doi = {10.1109/ICIP.2014.7025040},
	abstract = {Fast and efficient motion estimation is essential for a number of applications including the gesture-based user interface (UI) for portable devices like smart phones. In this paper, we propose a highly efficient method that can estimate four degree of freedom (DOF) motional components of a moving object based on an event-based vision sensor, the dynamic vision sensor (DVS). The proposed method finds informative events occurred at edges and estimates their velocities for global motion analysis. We will also describe a novel method to correct the aperture problem in the motion estimation.},
	language = {en},
	urldate = {2022-07-19},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	publisher = {IEEE},
	author = {Lee, Jun Haeng and Lee, Kyoobin and Ryu, Hyunsurk and Park, Paul K. J. and Shin, Chang-Woo and Woo, Jooyeon and Kim, Jun-Seok},
	month = oct,
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {204--208},
}

@article{frye_elementary_2015,
	title = {Elementary motion detectors},
	volume = {25},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982215000159},
	doi = {10.1016/j.cub.2015.01.013},
	language = {en},
	number = {6},
	urldate = {2022-03-21},
	journal = {Current Biology},
	author = {Frye, Mark},
	month = mar,
	year = {2015},
	keywords = {⛔ No INSPIRE recid found},
	pages = {R215--R217},
}

@article{nawrot_eye_2003,
	title = {Eye movements provide the extra-retinal signal required for the perception of depth from motion parallax},
	volume = {43},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698903001445},
	doi = {10.1016/S0042-6989(03)00144-5},
	abstract = {It has been unclear whether the perception of depth from motion parallax is an entirely visual process or whether it requires extra-retinal information such as head movements, vestibular activation, or eye movements. Using a motion aftereffect and static test stimulus technique to eliminate visual cues to depth, this psychophysical study demonstrates that the visual system employs a slow eye movement signal, optokinetic response (OKR) in particular, for the unambiguous perception of depth from motion parallax. A vestibular signal, or vestibularly driven eye movement signal is insufficient for unambiguous depth from motion parallax. Removal of the OKR eye movement signal gives rise to ambiguous perceived depth in motion parallax conditions. Neurophysiological studies suggest a possible neural mechanism in medial temporal and medial superior temporal cortical neurons that are selective to depth, motion, and direction of eye movement.},
	language = {en},
	number = {14},
	urldate = {2022-09-15},
	journal = {Vision Research},
	author = {Nawrot, Mark},
	month = jun,
	year = {2003},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1553--1562},
}

@article{masquelier_competitive_2009,
	title = {Competitive {STDP}-{Based} {Spike} {Pattern} {Learning}},
	volume = {21},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.2008.06-08-804},
	doi = {10.1162/neco.2008.06-08-804},
	language = {en},
	number = {5},
	urldate = {2018-09-10},
	journal = {Neural Computation},
	author = {Masquelier, Timothée and Guyonneau, Rudy and Thorpe, Simon J.},
	month = may,
	year = {2009},
	note = {00203},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {1259--1276},
}

@article{barlow_unsupervised_1989,
	title = {Unsupervised {Learning}},
	volume = {1},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1989.1.3.295},
	doi = {10.1162/neco.1989.1.3.295},
	abstract = {What use can the brain make of the massive flow of sensory information that occurs without any associated rewards or punishments? This question is reviewed in the light of connectionist models of unsupervised learning and some older ideas, namely the cognitive maps and working models of Tolman and Craik, and the idea that redundancy is important for understanding perception (Attneave 1954), the physiology of sensory pathways (Barlow 1959), and pattern recognition (Watanabe 1960). It is argued that (1) The redundancy of sensory messages provides the knowledge incorporated in the maps or models. (2) Some of this knowledge can be obtained by observations of mean, variance, and covariance of sensory messages, and perhaps also by a method called “minimum entropy coding.” (3) Such knowledge may be incorporated in a model of “what usually happens” with which incoming messages are automatically compared, enabling unexpected discrepancies to be immediately identified. (4) Knowledge of the sort incorporated into such a filter is a necessary prerequisite of ordinary learning, and a representation whose elements are independent makes it possible to form associations with logical functions of the elements, not just with the elements themselves.},
	number = {3},
	urldate = {2022-09-15},
	journal = {Neural Computation},
	author = {Barlow, H.B.},
	month = sep,
	year = {1989},
	keywords = {⛔ No INSPIRE recid found},
	pages = {295--311},
}

@article{yoonessi_contribution_2011,
	title = {Contribution of motion parallax to segmentation and depth perception},
	volume = {11},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/11.9.13},
	doi = {10.1167/11.9.13},
	abstract = {Relative image motion resulting from active movement of the observer could potentially serve as a powerful perceptual cue, both for segmentation of object boundaries and for depth perception. To examine the perceptual role of motion parallax from shearing motion, we measured human performance in three psychophysical tasks: segmentation, depth ordering, and depth magnitude estimation. Stimuli consisted of random dot textures that were synchronized to head movement with sine- or square-wave modulation patterns. Segmentation was assessed with a 2AFC orientation judgment of a motion-defined boundary. In the depth-ordering task, observers reported which modulation half-cycle appeared in front of the other. Perceived depth magnitude was matched to that of a 3D rendered image with multiple static cues. The results indicate that head movement might not be important for segmentation, even though it is crucial for obtaining depth from motion parallax—thus, concomitant depth perception does not appear to facilitate segmentation. Our findings suggest that segmentation works best for abrupt, sharply defined motion boundaries, whereas smooth gradients are more powerful for obtaining depth from motion parallax. Thus, motion parallax may contribute in a different manner to segmentation and to depth perception and suggests that their underlying mechanisms might be distinct.},
	number = {9},
	urldate = {2022-09-15},
	journal = {Journal of Vision},
	author = {Yoonessi, Ahmad and Baker, Jr., Curtis L.},
	month = aug,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {13},
}

@article{perrinet_emergence_2004,
	title = {Emergence of filters from natural scenes in a sparse spike coding scheme},
	volume = {58-60},
	copyright = {All rights reserved},
	issn = {09252312},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204001389},
	doi = {10.1016/j.neucom.2004.01.133},
	abstract = {As an alternative to classical representations in machine learning algorithms, we explore coding strategies using events as is observed for spiking neurons in the central nervous system. Focusing on visual processing, we have previously shown that we may define a sparse spike coding scheme by implementing accordingly lateral interactions (Neurocomputing 57 (2004) 125). This class of algorithms is both compatible with biological constraints and also to neurophysiological observations and yields a performant algorithm of computing by events. We explore here learning mechanisms to unsupervisely derive an optimal overcomplete set of filters based on previous work of (Vision Res. 37 (1998) 3311) and show its biological relevance. © 2004 Elsevier B.V. All rights reserved.},
	number = {C},
	journal = {Neurocomputing},
	author = {Perrinet, Laurent},
	year = {2004},
	keywords = {Sparse spike coding, Unsupervised learning, Vision, area-v1, receptive field, receptive\_field, sparse coding, sparse\_coding, ⛔ No INSPIRE recid found},
	pages = {821--826},
}

@article{pastalkova_internally_2008,
	title = {Internally {Generated} {Cell} {Assembly} {Sequences} in the {Rat} {Hippocampus}},
	volume = {321},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570043/},
	doi = {10.1126/science.1159775},
	abstract = {A longstanding conjecture in neuroscience is that aspects of cognition depend on the brain's ability to self-generate sequential neuronal activity. We found that reliably and continually-changing cell assemblies in the rat hippocampus appeared not only during spatial navigation but also in the absence of changing environmental or body-derived inputs. During the delay period of a memory task each moment in time was characterized by the activity of a unique assembly of neurons. Identical initial conditions triggered a similar assembly sequence, whereas different conditions gave rise, uniquely, to different sequences, thereby predicting behavioral choices, including errors. Such sequences were not formed in control, non-memory, tasks. We hypothesize that neuronal representations, evolved for encoding distance in spatial navigation, also support episodic recall and the planning of action sequences.},
	number = {5894},
	urldate = {2022-02-23},
	journal = {Science (New York, N.Y.)},
	author = {Pastalkova, Eva and Itskov, Vladimir and Amarasingham, Asohan and Buzsáki, György},
	month = sep,
	year = {2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1322--1327},
}

@article{malvache_awake_2016,
	title = {Awake hippocampal reactivations project onto orthogonal neuronal assemblies},
	volume = {353},
	issn = {1095-9203},
	doi = {10.1126/science.aaf3319},
	abstract = {The chained activation of neuronal assemblies is thought to support major cognitive processes, including memory. In the hippocampus, this is observed during population bursts often associated with sharp-wave ripples, in the form of an ordered reactivation of neurons. However, the organization and lifetime of these assemblies remain unknown. We used calcium imaging to map patterns of synchronous neuronal activation in the CA1 region of awake mice during runs on a treadmill. The patterns were composed of the recurring activation of anatomically intermingled, but functionally orthogonal, assemblies. These assemblies reactivated discrete temporal segments of neuronal sequences observed during runs and could be stable across consecutive days. A binding of these assemblies into longer chains revealed temporally ordered replay. These modules may represent the default building blocks for encoding or retrieving experience.},
	language = {eng},
	number = {6305},
	journal = {Science (New York, N.Y.)},
	author = {Malvache, Arnaud and Reichinnek, Susanne and Villette, Vincent and Haimerl, Caroline and Cossart, Rosa},
	month = sep,
	year = {2016},
	keywords = {Animals, Brain Mapping, CA1 Region, Hippocampal, Calcium Signaling, Exercise Test, Male, Mice, Nerve Net, Neurons, Running, Wakefulness, ⛔ No INSPIRE recid found},
	pages = {1280--1283},
}

@article{haimerl_internal_2019,
	title = {Internal representation of hippocampal neuronal population spans a time-distance continuum},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/116/15/7477},
	doi = {10.1073/pnas.1718518116},
	abstract = {The hippocampus plays a critical role in episodic memory: the sequential representation of visited places and experienced events. This function is mirrored by hippocampal activity that self organizes into sequences of neuronal activation that integrate spatiotemporal information. What are the underlying mechanisms of such integration is still unknown. Single cell activity was recently shown to combine time and distance information; however, it remains unknown whether a degree of tuning between space and time can be defined at the network level. Here, combining daily calcium imaging of CA1 sequence dynamics in running head-fixed mice and network modeling, we show that CA1 network activity tends to represent a specific combination of space and time at any given moment, and that the degree of tuning can shift within a continuum from 1 day to the next. Our computational model shows that this shift in tuning can happen under the control of the external drive power. We propose that extrinsic global inputs shape the nature of spatiotemporal integration in the hippocampus at the population level depending on the task at hand, a hypothesis which may guide future experimental studies.},
	language = {en},
	number = {15},
	urldate = {2022-01-17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Haimerl, Caroline and Angulo-Garcia, David and Villette, Vincent and Reichinnek, Susanne and Torcini, Alessandro and Cossart, Rosa and Malvache, Arnaud},
	month = apr,
	year = {2019},
	keywords = {attractor network, hippocampus, neural model, space representation, time representation, ⛔ No INSPIRE recid found},
	pages = {7477--7482},
}

@article{luczak_sequential_2007,
	title = {Sequential structure of neocortical spontaneous activity in vivo},
	volume = {104},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/104/1/347},
	doi = {10.1073/pnas.0605643104},
	abstract = {Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating “DOWN” states of generalized neural silence and “UP” states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50–200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.},
	language = {en},
	number = {1},
	urldate = {2022-02-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Luczak, Artur and Barthó, Peter and Marguet, Stephan L. and Buzsáki, György and Harris, Kenneth D.},
	month = jan,
	year = {2007},
	keywords = {microcircuits, neuronal assembly, repeating sequences, slow oscillations, syntire chains, ⛔ No INSPIRE recid found},
	pages = {347--352},
}

@article{ikegaya_synfire_2004,
	title = {Synfire {Chains} and {Cortical} {Songs}: {Temporal} {Modules} of {Cortical} {Activity}},
	volume = {304},
	shorttitle = {Synfire {Chains} and {Cortical} {Songs}},
	url = {http://www.science.org/doi/10.1126/science.1093173},
	doi = {10.1126/science.1093173},
	number = {5670},
	urldate = {2021-11-29},
	journal = {Science},
	author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, Rafael},
	month = apr,
	year = {2004},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {559--564},
}

@article{engbert_integrated_2011,
	title = {An integrated model of fixational eye movements and microsaccades},
	volume = {108},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/108/39/E765},
	doi = {10.1073/pnas.1102730108},
	abstract = {When we fixate a stationary target, our eyes generate miniature (or fixational) eye movements involuntarily. These fixational eye movements are classified as slow components (physiological drift, tremor) and microsaccades, which represent rapid, small-amplitude movements. Here we propose an integrated mathematical model for the generation of slow fixational eye movements and microsaccades. The model is based on the concept of self-avoiding random walks in a potential, a process driven by a self-generated activation field. The self-avoiding walk generates persistent movements on a short timescale, whereas, on a longer timescale, the potential produces antipersistent motions that keep the eye close to an intended fixation position. We introduce microsaccades as fast movements triggered by critical activation values. As a consequence, both slow movements and microsaccades follow the same law of motion; i.e., movements are driven by the self-generated activation field. Thus, the model contributes a unified explanation of why it has been a long-standing problem to separate slow movements and microsaccades with respect to their motion-generating principles. We conclude that the concept of a self-avoiding random walk captures fundamental properties of fixational eye movements and provides a coherent theoretical framework for two physiologically distinct movement types.},
	language = {en},
	number = {39},
	urldate = {2021-02-18},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Engbert, Ralf and Mergenthaler, Konstantin and Sinn, Petra and Pikovsky, Arkady},
	month = sep,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {E765--E770},
}

@article{villette_internally_2015,
	title = {Internally {Recurring} {Hippocampal} {Sequences} as a {Population} {Template} of {Spatiotemporal} {Information}},
	volume = {88},
	issn = {0896-6273},
	doi = {10.1016/j.neuron.2015.09.052},
	abstract = {The hippocampus is essential for spatiotemporal cognition. Sequences of neuronal activation provide a substrate for this fundamental function. At the behavioral timescale, these sequences have been shown to occur either in the presence of successive external landmarks or through internal mechanisms within an episodic memory task. In both cases, activity is externally constrained by the organization of the task and by the size of the environment explored. Therefore, it remains unknown whether hippocampal activity can self-organize into a default mode in the absence of any external memory demand or spatiotemporal boundary. Here we show that, in the presence of self-motion cues, a population code integrating distance naturally emerges in the hippocampus in the form of recurring sequences. These internal dynamics clamp spontaneous travel since run distance distributes into integer multiples of the span of these sequences. These sequences may thus guide navigation when external landmarks are reduced.},
	language = {en},
	number = {2},
	urldate = {2022-01-17},
	journal = {Neuron},
	author = {Villette, Vincent and Malvache, Arnaud and Tressard, Thomas and Dupuy, Nathalie and Cossart, Rosa},
	month = oct,
	year = {2015},
	keywords = {⛔ No INSPIRE recid found},
	pages = {357--366},
}

@misc{dardelet_event-by-event_2021,
	title = {An {Event}-by-{Event} {Feature} {Detection} and {Tracking} {Invariant} to {Motion} {Direction} and {Velocity}},
	url = {https://www.techrxiv.org/articles/preprint/An_Event-by-Event_Feature_Detection_and_Tracking_Invariant_to_Motion_Direction_and_Velocity/17013824/1},
	doi = {10.36227/techrxiv.17013824.v1},
	abstract = {Contour velocity estimation and tracking from a fully event-based perspective.},
	urldate = {2021-12-14},
	author = {Dardelet, Laurent and Benosman, Ryad and Ieng, Sio-Hoi},
	month = nov,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
}

@article{brette_exact_2007,
	title = {Exact {Simulation} of {Integrate}-and-{Fire} {Models} with {Exponential} {Currents}},
	volume = {19},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/19/10/2604-2609/7220},
	doi = {10.1162/neco.2007.19.10.2604},
	abstract = {Neural networks can be simulated exactly using event-driven strategies, in which the algorithm advances directly from one spike to the next spike. It applies to neuron models for which we have (1) an explicit expression for the evolution of the state variables between spikes and (2) an explicit test on the state variables that predicts whether and when a spike will be emitted. In a previous work, we proposed a method that allows exact simulation of an integrate-and-fire model with exponential conductances, with the constraint of a single synaptic time constant. In this note, we propose a method, based on polynomial root finding, that applies to integrate-and-fire models with exponential currents, with possibly many different synaptic time constants. Models can include biexponential synaptic currents and spike-triggered adaptation currents.},
	language = {en},
	number = {10},
	urldate = {2022-09-15},
	journal = {Neural Computation},
	author = {Brette, Romain},
	month = oct,
	year = {2007},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2604--2609},
}

@article{benosman_asynchronous_2012,
	title = {Asynchronous frameless event-based optical flow},
	volume = {27},
	url = {https://doi.org/10/b55t75},
	doi = {10.1016/j.neunet.2011.11.001},
	abstract = {This paper introduces a process to compute optical flow using an asynchronous event-based retina at high speed and low computational load. A new generation of artificial vision sensors has now started to rely on biologically inspired designs for light acquisition. Biological retinas, and their artificial counterparts, are totally asynchronous and data driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework for processing visual data using asynchronous event-based acquisition, providing a method for the evaluation of optical flow. The paper shows that current limitations of optical flow computation can be overcome by using event-based visual acquisition, where high data sparseness and high temporal resolution permit the computation of optical flow with micro-second accuracy and at very low computational cost.},
	language = {english},
	journal = {Neural Networks},
	author = {Benosman, Ryad},
	year = {2012},
	keywords = {⛔ No INSPIRE recid found},
	pages = {6},
}

@article{bohte_evidence_2004,
	title = {The evidence for neural information processing with precise spike-times: {A} survey},
	volume = {3},
	doi = {10.1023/B:NACO.0000027755.02868.60},
	number = {2},
	journal = {Natural Computing},
	author = {Bohte, Sander M},
	year = {2004},
	keywords = {⛔ No INSPIRE recid found},
	pages = {195--206},
}

@article{boutin_effect_2020,
	title = {Effect of top-down connections in {Hierarchical} {Sparse} {Coding}},
	volume = {32},
	copyright = {All rights reserved},
	url = {https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/},
	doi = {10.1162/neco_a_01325},
	abstract = {Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images. The simplest solution to solve this computationally hard problem is to decompose it into independent layer-wise subproblems. However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers. In this study, a new model called 2-Layers Sparse Predictive Coding (2L-SPC) is introduced to assess the impact of this inter-layer feedback connection. In particular, the 2L-SPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of independent Lasso layers. The 2L-SPC and the 2-layers Hi-La networks are trained on 4 different databases and with different sparsity parameters on each layer. First, we show that the overall prediction error generated by 2L-SPC is lower thanks to the feedback mechanism as it transfers prediction error between layers. Second, we demonstrate that the inference stage of the 2L-SPC is faster to converge than for the Hi-La model. Third, we show that the 2L-SPC also accelerates the learning process. Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the 2L-SPC features are more generic and informative.},
	number = {11},
	journal = {Neural Computation},
	author = {Boutin, Victor and Franciosini, Angelo and Ruffier, Franck and Perrinet, Laurent U},
	month = feb,
	year = {2020},
	keywords = {deep-learning, sparse coding, ⛔ No INSPIRE recid found},
	pages = {2279--2309},
}

@article{boutin_sparse_2020,
	title = {Sparse {Deep} {Predictive} {Coding} captures contour integration capabilities of the early visual system},
	copyright = {All rights reserved},
	url = {https://doi.org/10.1371/journal.pcbi.1008629},
	doi = {10.1371/journal.pcbi.1008629},
	abstract = {Both neurophysiological and psychophysical experiments have pointed out the crucial role of recurrent and feedback connections to process context-dependent information in the early visual cortex. While numerous models have accounted for feedback effects at either neural or representational level, none of them were able to bind those two levels of analysis. Is it possible to describe feedback effects at both levels using the same model? We answer this question by combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical and convolutional framework. In this Sparse Deep Predictive Coding (SDPC) model, the SC component models the internal recurrent processing within each layer, and the PC component describes the interactions between layers using feedforward and feedback connections. Here, we train a 2-layered SDPC on two different databases of images, and we interpret it as a model of the early visual system (V1 \& V2). We first demonstrate that once the training has converged, SDPC exhibits oriented and localized receptive fields in V1 and more complex features in V2. Second, we analyze the effects of feedback on the neural organization beyond the classical receptive field of V1 neurons using interaction maps. These maps are similar to association fields and reflect the Gestalt principle of good continuation. We demonstrate that feedback signals reorganize interaction maps and modulate neural activity to promote contour integration. Third, we demonstrate at the representational level that the SDPC feedback connections are able to overcome noise in input images. Therefore, the SDPC captures the association field principle at the neural level which results in better disambiguation of blurred images at the representational level.},
	journal = {PLoS Computational Biology},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Frédéric Y and Ruffier, Franck and Perrinet, Laurent U},
	month = may,
	year = {2020},
	keywords = {deep-learning, sparse coding, ⛔ No INSPIRE recid found},
}

@article{boutin_pooling_2022,
	title = {Pooling strategies in {V1} can account for the functional and structural diversity across species},
	volume = {18},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010270},
	doi = {10.1371/journal.pcbi.1010270},
	abstract = {Neurons in the primary visual cortex are selective to orientation with various degrees of selectivity to the spatial phase, from high selectivity in simple cells to low selectivity in complex cells. Various computational models have suggested a possible link between the presence of phase invariant cells and the existence of orientation maps in higher mammals’ V1. These models, however, do not explain the emergence of complex cells in animals that do not show orientation maps. In this study, we build a theoretical model based on a convolutional network called Sparse Deep Predictive Coding (SDPC) and show that a single computational mechanism, pooling, allows the SDPC model to account for the emergence in V1 of complex cells with or without that of orientation maps, as observed in distinct species of mammals. In particular, we observed that pooling in the feature space is directly related to the orientation map formation while pooling in the retinotopic space is responsible for the emergence of a complex cells population. Introducing different forms of pooling in a predictive model of early visual processing as implemented in SDPC can therefore be viewed as a theoretical framework that explains the diversity of structural and functional phenomena observed in V1.},
	language = {en},
	number = {7},
	urldate = {2022-09-14},
	journal = {PLOS Computational Biology},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Frédéric and Perrinet, Laurent U.},
	year = {2022},
	keywords = {Coding mechanisms, Convolution, Neural networks, Neuronal tuning, Neurons, Neurophysiology, Visual cortex, Visual system, ⛔ No INSPIRE recid found},
	pages = {e1010270},
}

@article{carr_circuit_1990,
	title = {A circuit for detection of interaural time differences in the brain stem of the barn owl},
	volume = {10},
	doi = {10.1523/JNEUROSCI.10-10-03227.1990},
	number = {10},
	journal = {Journal of Neuroscience},
	author = {Carr, CE and Konishi, M},
	year = {1990},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3227--3246},
}

@article{dandekar_neural_2012,
	title = {Neural saccadic response estimation during natural viewing},
	volume = {107},
	issn = {0022-3077},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3311669/},
	doi = {10.1152/jn.00237.2011},
	abstract = {Studying neural activity during natural viewing conditions is not often attempted. Isolating the neural response of a single saccade is necessary to study neural activity during natural viewing; however, the close temporal spacing of saccades that occurs during natural viewing makes it difficult to determine the response to a single saccade. Herein, a general linear model (GLM) approach is applied to estimate the EEG neural saccadic response for different segments of the saccadic main sequence separately. It is determined that, in visual search conditions, neural responses estimated by conventional event-related averaging are significantly and systematically distorted relative to GLM estimates due to the close temporal spacing of saccades during visual search. Before the GLM is applied, analyses are applied that demonstrate that saccades during visual search with intersaccadic spacings as low as 100–150 ms do not exhibit significant refractory effects. Therefore, saccades displaying different intersaccadic spacings during visual search can be modeled using the same regressor in a GLM. With the use of the GLM approach, neural responses were separately estimated for five different ranges of saccade amplitudes during visual search. Occipital responses time locked to the onsets of saccades during visual search were found to account for, on average, 79 percent of the variance of EEG activity in a window 90–200 ms after the onsets of saccades for all five saccade amplitude ranges that spanned a range of 0.2–6.0 degrees. A GLM approach was also used to examine the lateralized ocular artifacts associated with saccades. Possible extensions of the methods presented here to account for the superposition of microsaccades in event-related EEG studies conducted in nominal fixation conditions are discussed.},
	number = {6},
	urldate = {2022-09-14},
	journal = {Journal of Neurophysiology},
	author = {Dandekar, Sangita and Privitera, Claudio and Carney, Thom and Klein, Stanley A.},
	month = mar,
	year = {2012},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1776--1790},
}

@article{davis_spontaneous_2021,
	title = {Spontaneous traveling waves naturally emerge from horizontal fiber time delays and travel through locally asynchronous-irregular states},
	volume = {12},
	doi = {10.1038/s41467-021-26175-1},
	number = {1},
	journal = {Nature Communications},
	author = {Davis, Zachary W and Benigno, Gabriel B and Fletterman, Charlee and Desbordes, Theo and Steward, Christopher and Sejnowski, Terrence J and H Reynolds, John and Muller, Lyle},
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1--16},
}

@article{ghosh_spatiotemporal_2019,
	title = {Spatiotemporal filtering for event-based action recognition},
	volume = {abs/1903.07067},
	url = {http://arxiv.org/abs/1903.07067},
	journal = {CoRR},
	author = {Ghosh, Rohan and Gupta, Anupam and Silva, Andrei Nakagawa and Soares, Alcimar and Thakor, Nitish V.},
	year = {2019},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{gollisch_rapid_2008,
	title = {Rapid neural coding in the retina with relative spike latencies},
	volume = {319},
	doi = {10.1126/science.1149639},
	number = {5866},
	journal = {Science (New York, N.Y.)},
	author = {Gollisch, Tim and Meister, Markus},
	year = {2008},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1108--1111},
}

@article{grimaldi_robust_2022,
	title = {A robust event-driven approach to always-on object recognition},
	url = {https://www.techrxiv.org/articles/preprint/A<sub>r</sub>obustₑvent-drivenₐpproachₜoₐlways-onₒbject<sub>r</sub>ecognition/18003077/1},
	doi = {10.36227/techrxiv.18003077.v1},
	abstract = {We propose a neuromimetic architecture able to perform always-on pattern recognition. To achieve this, we extended an existing event-based algorithm [1], which introduced novel spatio-temporal features as a Hierarchy Of Time-Surfaces (HOTS). Built from asynchronous events acquired by a neuromorphic camera, these time surfaces allow to code the local dynamics of a visual scene and to create an efficient event-based pattern recognition architecture. Inspired by neuroscience, we extended this method to increase its performance. Our first contribution was to add a homeostatic gain control on the activity of neurons to improve the learning of spatio-temporal patterns [2]. A second contribution is to draw an analogy between the HOTS algorithm and Spiking Neural Networks (SNN). Following that analogy, our last contribution is to modify the classification layer and remodel the offline pattern categorization method previously used into an online and event-driven one. This classifier uses the spiking output of the network to define novel time surfaces and we then perform online classification with a neuromimetic implementation of a multinomial logistic regression. Not only do these improvements increase consistently the performances of the network, they also make this event-driven pattern recognition algorithm online and bio-realistic. Results were validated on different datasets: DVS barrel [3], Poker-DVS [4] and N-MNIST [5]. We foresee to develop the SNN version of the method and to extend this fully event-driven approach to more naturalistic tasks, notably for always-on, ultra-fast object categorization.},
	urldate = {2022-01-13},
	journal = {TechRxiv preprint},
	author = {Grimaldi, Antoine and Boutin, Victor and Ieng, Sio-Hoi and Benosman, Ryad and Perrinet, Laurent U},
	month = jan,
	year = {2022},
	keywords = {efficient coding, event-based vision, homeostasis, neuromorphic hardware, online classification, ⛔ No INSPIRE recid found},
}

@article{guise_bayesian_2014,
	title = {A {Bayesian} model of polychronicity},
	volume = {26},
	doi = {10.1162/NECO_a_00620},
	number = {9},
	journal = {Neural Computation},
	author = {Guise, Mira and Knott, Alistair and Benuskova, Lubica},
	year = {2014},
	keywords = {⛔ No INSPIRE recid found},
	pages = {2052--2073},
}

@article{gutig_tempotron_2006,
	title = {The tempotron: {A} neuron that learns spike {Timing}–{Based} decisions},
	volume = {9},
	issn = {1546-1726},
	shorttitle = {The tempotron},
	url = {http://www.nature.com/articles/nn1643/},
	doi = {10.1038/nn1643},
	abstract = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing–based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony.},
	language = {english},
	number = {3},
	urldate = {2022-01-31},
	journal = {Nature Neuroscience},
	author = {Gütig, Robert and Sompolinsky, Haim},
	month = mar,
	year = {2006},
	keywords = {⛔ No INSPIRE recid found},
	pages = {420--428},
}

@article{hanuschkin_general_2010,
	title = {A {General} and {Efficient} {Method} for {Incorporating} {Precise} {Spike} {Times} in {Globally} {Time}-{Driven} {Simulations}},
	volume = {4},
	issn = {1662-5196},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965048/},
	doi = {10.3389/fninf.2010.00113},
	abstract = {Traditionally, event-driven simulations have been limited to the very restricted class of neuronal models for which the timing of future spikes can be expressed in closed form. Recently, the class of models that is amenable to event-driven simulation has been extended by the development of techniques to accurately calculate firing times for some integrate-and-fire neuron models that do not enable the prediction of future spikes in closed form. The motivation of this development is the general perception that time-driven simulations are imprecise. Here, we demonstrate that a globally time-driven scheme can calculate firing times that cannot be discriminated from those calculated by an event-driven implementation of the same model; moreover, the time-driven scheme incurs lower computational costs. The key insight is that time-driven methods are based on identifying a threshold crossing in the recent past, which can be implemented by a much simpler algorithm than the techniques for predicting future threshold crossings that are necessary for event-driven approaches. As run time is dominated by the cost of the operations performed at each incoming spike, which includes spike prediction in the case of event-driven simulation and retrospective detection in the case of time-driven simulation, the simple time-driven algorithm outperforms the event-driven approaches. Additionally, our method is generally applicable to all commonly used integrate-and-fire neuronal models; we show that a non-linear model employing a standard adaptive solver can reproduce a reference spike train with a high degree of precision.},
	urldate = {2022-09-14},
	journal = {Frontiers in Neuroinformatics},
	author = {Hanuschkin, Alexander and Kunkel, Susanne and Helias, Moritz and Morrison, Abigail and Diesmann, Markus},
	month = oct,
	year = {2010},
	keywords = {⛔ No INSPIRE recid found},
	pages = {113},
}

@article{hogendoorn_predictive_2019,
	title = {Predictive {Coding} with {Neural} {Transmission} {Delays}: {A} {Real}-{Time} {Temporal} {Alignment} {Hypothesis}},
	volume = {6},
	issn = {2373-2822},
	shorttitle = {Predictive {Coding} with {Neural} {Transmission} {Delays}},
	url = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0412-18.2019},
	doi = {10.1523/eneuro.0412-18.2019},
	language = {en},
	number = {2},
	urldate = {2019-11-12},
	journal = {eneuro},
	author = {Hogendoorn, Hinze and Burkitt, Anthony N.},
	month = mar,
	year = {2019},
	keywords = {⛔ No INSPIRE recid found},
	pages = {ENEURO.0412--18.2019},
}

@article{izhikevich_polychronization_2006-1,
	title = {Polychronization: computation with spikes},
	volume = {18},
	doi = {10.1162/089976606775093882},
	number = {2},
	journal = {Neural computation},
	author = {Izhikevich, Eugene M},
	year = {2006},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {245--282},
}

@article{khoei_flash-lag_2017,
	title = {The {Flash}-{Lag} {Effect} as a {Motion}-{Based} {Predictive} {Shift}},
	volume = {13},
	copyright = {Licence Creative Commons Attribution - Pas d’utilisation commerciale - Partage dans les mêmes conditions 4.0 International (CC-BY-NC-SA)},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068},
	doi = {10.1371/journal.pcbi.1005068},
	abstract = {Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object’s motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects’ position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.},
	language = {en},
	number = {1},
	urldate = {2022-08-31},
	journal = {PLOS Computational Biology},
	author = {Khoei, Mina A. and Masson, Guillaume S. and Perrinet, Laurent U.},
	month = jan,
	year = {2017},
	keywords = {Coding mechanisms, Extrapolation, Motion, Psychophysics, Sensory perception, Velocity, Vision, Visual system, ⛔ No INSPIRE recid found},
	pages = {e1005068},
}

@article{koenderink_representation_1987,
	title = {Representation of local geometry in the visual system},
	volume = {55},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/BF00318371},
	doi = {10.1007/BF00318371},
	abstract = {It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.},
	language = {en},
	number = {6},
	urldate = {2022-08-31},
	journal = {Biological Cybernetics},
	author = {Koenderink, J. J. and van Doorn, A. J.},
	month = mar,
	year = {1987},
	keywords = {⛔ No INSPIRE recid found},
	pages = {367--375},
}

@article{lagorce_hots_2017,
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	volume = {39},
	issn = {0162-8828},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	doi = {10.1109/TPAMI.2016.2574707},
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	number = {7},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B.},
	year = {2017},
	keywords = {Neuromorphic sensing, event-based vision, feature extraction, ⛔ No INSPIRE recid found},
	pages = {1346--1359},
}

@article{leon_motion_2012,
	title = {Motion {Clouds}: {Model}-based stimulus synthesis of natural-like random textures for the study of motion perception},
	volume = {107},
	doi = {10.1152/jn.00737.2011},
	number = {11},
	journal = {Journal of Neurophysiology},
	author = {Leon, Paula Sanz and Vanzetta, Ivo and Masson, Guillaume S and Perrinet, Laurent U},
	year = {2012},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3217--3226},
}

@article{lin_supervised_2021,
	title = {Supervised {Learning} {Algorithm} for {Multilayer} {Spiking} {Neural} {Networks} with {Long}-{Term} {Memory} {Spike} {Response} {Model}},
	volume = {2021},
	issn = {1687-5265},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8635912/},
	doi = {10.1155/2021/8592824},
	abstract = {As a new brain-inspired computational model of artificial neural networks, spiking neural networks transmit and process information via precisely timed spike trains. Constructing efficient learning methods is a significant research field in spiking neural networks. In this paper, we present a supervised learning algorithm for multilayer feedforward spiking neural networks; all neurons can fire multiple spikes in all layers. The feedforward network consists of spiking neurons governed by biologically plausible long-term memory spike response model, in which the effect of earlier spikes on the refractoriness is not neglected to incorporate adaptation effects. The gradient descent method is employed to derive synaptic weight updating rule for learning spike trains. The proposed algorithm is tested and verified on spatiotemporal pattern learning problems, including a set of spike train learning tasks and nonlinear pattern classification problems on four UCI datasets. Simulation results indicate that the proposed algorithm can improve learning accuracy in comparison with other supervised learning algorithms.},
	urldate = {2022-09-14},
	journal = {Computational Intelligence and Neuroscience},
	author = {Lin, Xianghong and Zhang, Mengwei and Wang, Xiangwen},
	month = nov,
	year = {2021},
	keywords = {⛔ No INSPIRE recid found},
	pages = {8592824},
}

@article{luo_supervised_2022,
	title = {Supervised {Learning} in {Multilayer} {Spiking} {Neural} {Networks} {With} {Spike} {Temporal} {Error} {Backpropagation}},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2022.3164930},
	abstract = {The brain-inspired spiking neural networks (SNNs) hold the advantages of lower power consumption and powerful computing capability. However, the lack of effective learning algorithms has obstructed the theoretical advance and applications of SNNs. The majority of the existing learning algorithms for SNNs are based on the synaptic weight adjustment. However, neuroscience findings confirm that synaptic delays can also be modulated to play an important role in the learning process. Here, we propose a gradient descent-based learning algorithm for synaptic delays to enhance the sequential learning performance of single spiking neuron. Moreover, we extend the proposed method to multilayer SNNs with spike temporal-based error backpropagation. In the proposed multilayer learning algorithm, information is encoded in the relative timing of individual neuronal spikes, and learning is performed based on the exact derivatives of the postsynaptic spike times with respect to presynaptic spike times. Experimental results on both synthetic and realistic datasets show significant improvements in learning efficiency and accuracy over the existing spike temporal-based learning algorithms. We also evaluate the proposed learning method in an SNN-based multimodal computational model for audiovisual pattern recognition, and it achieves better performance compared with its counterparts.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Luo, Xiaoling and Qu, Hong and Wang, Yuchen and Yi, Zhang and Zhang, Jilun and Zhang, Malu},
	year = {2022},
	keywords = {Backpropagation, Biological system modeling, Delays, Heuristic algorithms, Membrane potentials, Neurons, Nonhomogeneous media, spike neural networks, spike neurons, supervised learning, synaptic delay plasticity., ⛔ No INSPIRE recid found},
	pages = {1--13},
}

@article{nessler_bayesian_2013,
	title = {Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity},
	volume = {9},
	doi = {10.1371/journal.pcbi.1003037},
	number = {4},
	journal = {PLoS computational biology},
	author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
	year = {2013},
	keywords = {⛔ No INSPIRE recid found},
	pages = {e1003037},
}

@article{olshausen_emergence_1996,
	title = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images.},
	volume = {381},
	issn = {0028-0836},
	url = {http://dx.doi.org/10.1038/381607a0 http://www.ncbi.nlm.nih.gov/htbin-post/Entrez/query?db=m&form=6&dopt=r&uid=8637596 http://www.ncbi.nlm.nih.gov/pubmed/8637596 http://www.nature.com/doifinder/10.1038/381607a0},
	doi = {10.1038/381607a0},
	abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
	number = {6583},
	journal = {Nature},
	author = {Olshausen, Bruno A. and Field, David J.},
	year = {1996},
	keywords = {\#nosource, Algorithms, Learning, Models, Neurological, Neurons, Neurons: physiology, Ocular, Ocular: physiology, Vision, Visual Cortex, Visual Cortex: cytology, Visual Cortex: physiology, anr-trax, bicv-sparse, perrinetadamsfriston14, sparse\_coding, sparse\_hebbian\_learning, sparse\_spike\_coding, ⛔ No INSPIRE recid found},
	pages = {607--609},
}

@article{perrinet_motion-based_2012,
	title = {Motion-{Based} {Prediction} {Is} {Sufficient} to {Solve} the {Aperture} {Problem}},
	volume = {24},
	copyright = {All rights reserved},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/NECO_a_00332 http://arxiv.org/abs/1208.6471 http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00332 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3472550&tool=pmcentrez&rendertype=abstract http://arxiv.org/pdf/12},
	doi = {10.1162/neco_a_00332},
	abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to physio-logy and behavior. We demonstrate that this solution is the result of two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independent of their texture. Second, we observe that incoherent features are explained away, while coherent information diffuses progressively to the global scale. Most previous models included ad hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features as necessary conditions to solve the aperture problem. Here, we have proved that motion-based predictive coding, as it is implemented in this functional model, is sufficient to solve the aperture problem. This solution may give insights into the role of prediction underlying a large class of sensory computations.},
	number = {10},
	journal = {Neural Computation},
	author = {Perrinet, Laurent U. and Masson, G.S. Guillaume S.},
	month = aug,
	year = {2012},
	keywords = {\#nosource, Bayesian model, aperture, aperture problem, aperture-problem, association field, coding, emergence, khoei12jpp, khoei13jpp, motion detection, motion prediction, perrinet12pred, predictive, predictive coding, predictive-coding, probabilistic, probabilistic representation, problem, representation, thesis, toupate-inpress, ⛔ No INSPIRE recid found},
	pages = {2726--2750},
}

@article{perrinet_active_2014,
	title = {Active inference, eye movements and oculomotor delays},
	volume = {108},
	copyright = {All rights reserved},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/s00422-014-0620-8},
	doi = {10.1007/s00422-014-0620-8},
	abstract = {This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system, like the oculomotor system, tries to control its environment with delayed signals.},
	number = {6},
	journal = {Biological Cybernetics},
	author = {Perrinet, Laurent U and Adams, Rick A and Friston, Karl J},
	month = dec,
	year = {2014},
	keywords = {\#nosource, Active inference, Bayesian model, Biologically Inspired Computer vision, Generalised coordinates, Oculomotor delays, Smooth pursuit eye movements, Tracking eye movements, Variational free energy, active inference, active-inference, bayesian, bicv-motion, bicv-sparse, delays, eye, eye movements, eye-movements, free energy, free-energy, generalized-coordinates, generalized-filtering, motion detection, oculomotor, perception, perrinetadamsfriston14, smooth-pursuit, tracking-eye-movements, variational-filtering, ⛔ No INSPIRE recid found},
	pages = {777--801},
}

@article{perrinet_edge_2015,
	title = {Edge co-occurrences can account for rapid categorization of natural versus animal images},
	volume = {5},
	doi = {10.1038/srep11400},
	journal = {Scientific reports},
	author = {Perrinet, Laurent U and Bednar, James A},
	year = {2015},
	keywords = {\#nosource, Biologically Inspired Computer vision, anr-trax, association field, assofield, bicv-sparse, perrinetbednar15, sanz12jnp, sparse coding, vacher14, ⛔ No INSPIRE recid found},
	pages = {11400},
}

@article{poletti_head-eye_2015,
	title = {Head-{Eye} {Coordination} at a {Microscopic} {Scale}},
	volume = {25},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(15)01365-2},
	doi = {10.1016/j.cub.2015.11.004},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Humans explore static visual scenes by alternating rapid eye movements (saccades) with periods of slow and incessant eye drifts [1–3]. These drifts are commonly believed to be the consequence of physiological limits in maintaining steady gaze, resulting in Brownian-like trajectories [4–7], which are almost independent in the two eyes [8–10]. However, because of the technical difficulty of recording minute eye movements, most knowledge on ocular drift comes from artificial laboratory conditions, in which the head of the observer is strictly immobilized. Little is known about eye drift during natural head-free fixation, when microscopic head movements are also continually present [11–13]. We have recently observed that the power spectrum of the visual input to the retina during ocular drift is largely unaffected by fixational head movements [14]. Here we elucidate the mechanism responsible for this invariance. We show that, contrary to common assumption, ocular drift does not move the eyes randomly, but compensates for microscopic head movements, thereby yielding highly correlated movements in the two eyes. This compensatory behavior is extremely fast, persists with one eye patched, and results in image motion trajectories that are only partially correlated on the two retinas. These findings challenge established views of how humans acquire visual information. They show that ocular drift is precisely controlled, as long speculated [15], and imply the existence of neural mechanisms that integrate minute multimodal signals.{\textless}/p{\textgreater}},
	language = {English},
	number = {24},
	urldate = {2022-09-13},
	journal = {Current Biology},
	author = {Poletti, Martina and Aytekin, Murat and Rucci, Michele},
	month = dec,
	year = {2015},
	keywords = {⛔ No INSPIRE recid found},
	pages = {3253--3259},
}

@article{van_der_stigchel_eye_2006,
	title = {Eye movement trajectories and what they tell us},
	volume = {30},
	issn = {0149-7634},
	url = {https://www.sciencedirect.com/science/article/pii/S0149763405001740},
	doi = {10.1016/j.neubiorev.2005.12.001},
	abstract = {In the last two decades, research has shown that eye movement trajectories can be modified by situational determinants. These modifications can inform us about the mechanisms that control eye movements and they can yield information about the oculomotor, memory and attention system that is not easily obtained via other sources. Eye movement trajectories can deviate either towards or away from elements in the visual field. We review the conditions in which these deviations are found and the mechanisms underlying trajectory deviations. It is argued that deviations towards an element are caused by the unresolved competition in the oculomotor system between elements in a visual scene. Deviations away from an element are mainly observed in situations in which top-down preparation can influence the target selection process, but the exact cause of such deviations remains unclear.},
	language = {en},
	number = {5},
	urldate = {2022-09-13},
	journal = {Neuroscience \& Biobehavioral Reviews},
	author = {Van der Stigchel, Stefan and Meeter, Martijn and Theeuwes, Jan},
	month = jan,
	year = {2006},
	keywords = {⛔ No INSPIRE recid found},
	pages = {666--679},
}

@incollection{perrinet_sparse_2015,
	address = {Weinheim, Germany},
	title = {Sparse {Models} for {Computer} {Vision}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9783527680863.ch14/summary},
	booktitle = {Biologically {Inspired} {Computer} {Vision}},
	publisher = {Wiley-VCH Verlag GmbH \& Co. KGaA},
	author = {Perrinet, Laurent U},
	editor = {Keil, Matthias and Cristóbal, Gabriel and Perrinet, Laurent U},
	month = aug,
	year = {2015},
	keywords = {\#nosource, Biologically Inspired Computer vision, anr-trax, bicv-sparse, sanz12jnp, sparse coding, vacher14, ⛔ No INSPIRE recid found},
	pages = {319--346},
}

@article{rogers_motion_1979,
	title = {Motion {Parallax} as an {Independent} {Cue} for {Depth} {Perception}},
	volume = {8},
	issn = {0301-0066},
	url = {https://doi.org/10.1068/p080125},
	doi = {10.1068/p080125},
	abstract = {The perspective transformations of the retinal image, produced by either the movement of an observer or the movement of objects in the visual world, were found to produce a reliable, consistent, and unambiguous impression of relative depth in the absence of all other cues to depth and distance. The stimulus displays consisted of computer-generated random-dot patterns that could be transformed by each movement of the observer or the display oscilloscope to simulate the relative movement information produced by a three-dimensional surface. Using a stereoscopic matching task, the second experiment showed that the perceived depth from parallax transformations is in close agreement with the degree of relative image displacement, as well as producing a compelling impression of three-dimensionality not unlike that found with random-dot stereograms.},
	language = {en},
	number = {2},
	urldate = {2022-09-15},
	journal = {Perception},
	author = {Rogers, Brian and Graham, Maureen},
	month = apr,
	year = {1979},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {125--134},
}

@article{wang_delay_2019,
	title = {A {Delay} {Learning} {Algorithm} {Based} on {Spike} {Train} {Kernels} for {Spiking} {Neurons}},
	volume = {13},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2019.00252},
	abstract = {Neuroscience research confirms that the synaptic delays are not constant, but can be modulated. This paper proposes a supervised delay learning algorithm for spiking neurons with temporal encoding, in which both the weight and delay of a synaptic connection can be adjusted to enhance the learning performance. The proposed algorithm firstly defines spike train kernels to transform discrete spike trains during the learning phase into continuous analog signals so that common mathematical operations can be performed on them, and then deduces the supervised learning rules of synaptic weights and delays by gradient descent method. The proposed algorithm is successfully applied to various spike train learning tasks, and the effects of parameters of synaptic delays are analyzed in detail. Experimental results show that the network with dynamic delays achieves higher learning accuracy and less learning epochs than the network with static delays. The delay learning algorithm is further validated on a practical example of an image classification problem. The results again show that it can achieve a good classification performance with a proper receptive field. Therefore, the synaptic delay learning is significant for practical applications and theoretical researches of spiking neural networks.},
	urldate = {2022-09-14},
	journal = {Frontiers in Neuroscience},
	author = {Wang, Xiangwen and Lin, Xianghong and Dang, Xiaochao},
	year = {2019},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{tatler_eye_2011,
	title = {Eye guidance in natural vision: {Reinterpreting} salience},
	volume = {11},
	issn = {1534-7362},
	shorttitle = {Eye guidance in natural vision},
	url = {https://doi.org/10.1167/11.5.5},
	doi = {10.1167/11.5.5},
	abstract = {Models of gaze allocation in complex scenes are derived mainly from studies of static picture viewing. The dominant framework to emerge has been image salience, where properties of the stimulus play a crucial role in guiding the eyes. However, salience-based schemes are poor at accounting for many aspects of picture viewing and can fail dramatically in the context of natural task performance. These failures have led to the development of new models of gaze allocation in scene viewing that address a number of these issues. However, models based on the picture-viewing paradigm are unlikely to generalize to a broader range of experimental contexts, because the stimulus context is limited, and the dynamic, task-driven nature of vision is not represented. We argue that there is a need to move away from this class of model and find the principles that govern gaze allocation in a broader range of settings. We outline the major limitations of salience-based selection schemes and highlight what we have learned from studies of gaze allocation in natural vision. Clear principles of selection are found across many instances of natural vision and these are not the principles that might be expected from picture-viewing studies. We discuss the emerging theoretical framework for gaze allocation on the basis of reward maximization and uncertainty reduction.},
	number = {5},
	urldate = {2022-09-14},
	journal = {Journal of Vision},
	author = {Tatler, Benjamin W. and Hayhoe, Mary M. and Land, Michael F. and Ballard, Dana H.},
	month = may,
	year = {2011},
	keywords = {⛔ No INSPIRE recid found},
	pages = {5},
}

@article{zhang_supervised_2020,
	title = {Supervised learning in spiking neural networks with synaptic delay-weight plasticity},
	volume = {409},
	doi = {10.1016/j.neucom.2020.03.079},
	journal = {Neurocomputing},
	author = {Zhang, Malu and Wu, Jibin and Belatreche, Ammar and Pan, Zihan and Xie, Xiurui and Chua, Yansong and Li, Guoqi and Qu, Hong and Li, Haizhou},
	year = {2020},
	note = {Publisher: Elsevier},
	keywords = {⛔ No INSPIRE recid found},
	pages = {103--118},
}

@article{perrinet_coding_2004,
	title = {Coding static natural images using spiking event times: do neurons cooperate?},
	volume = {15},
	doi = {10.1109/TNN.2004.833303},
	number = {5},
	journal = {IEEE Transactions on neural networks},
	author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
	year = {2004},
	note = {Publisher: IEEE},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1164--1175},
}

@article{riehle_spike_1997,
	title = {Spike synchronization and rate modulation differentially involved in motor cortical function},
	volume = {278},
	doi = {10.1126/science.278.5345.1950},
	number = {5345},
	journal = {Science (New York, N.Y.)},
	author = {Riehle, Alexa and Grun, Sonja and Diesmann, Markus and Aertsen, Ad},
	year = {1997},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {⛔ No INSPIRE recid found},
	pages = {1950--1953},
}

@article{rasetto_challenges_2022,
	title = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}: {How} {Memristors} {Dynamic} {Properties} {Could} {Revolutionize} {Machine} {Learning}},
	shorttitle = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}},
	url = {http://arxiv.org/abs/2201.12673},
	abstract = {Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artificial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efficient approach to build novel bio-inspired processing units in silicon.},
	language = {english},
	urldate = {2022-02-02},
	journal = {arXiv:2201.12673 [cs]},
	author = {Rasetto, Marco and Wan, Qingzhou and Akolkar, Himanshu and Shi, Bertram and Xiong, Feng and Benosman, Ryad},
	month = jan,
	year = {2022},
	note = {arXiv: 2201.12673 [cs]},
	keywords = {Computer Science - Emerging Technologies, ⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{chavane_revisiting_2022,
	title = {Revisiting horizontal connectivity rules in {V1}: from like-to-like towards like-to-all},
	copyright = {All rights reserved},
	issn = {1863-2661},
	shorttitle = {Revisiting horizontal connectivity rules in {V1}},
	url = {https://doi.org/10.1007/s00429-022-02455-4},
	doi = {10.1007/s00429-022-02455-4},
	abstract = {Horizontal connections in the primary visual cortex of carnivores, ungulates and primates organize on a near-regular lattice. Given the similar length scale for the regularity found in cortical orientation maps, the currently accepted theoretical standpoint is that these maps are underpinned by a like-to-like connectivity rule: horizontal axons connect preferentially to neurons with similar preferred orientation. However, there is reason to doubt the rule’s explanatory power, since a growing number of quantitative studies show that the like-to-like connectivity preference and bias mostly observed at short-range scale, are highly variable on a neuron-to-neuron level and depend on the origin of the presynaptic neuron. Despite the wide availability of published data, the accepted model of visual processing has never been revised. Here, we review three lines of independent evidence supporting a much-needed revision of the like-to-like connectivity rule, ranging from anatomy to population functional measures, computational models and to theoretical approaches. We advocate an alternative, distance-dependent connectivity rule that is consistent with new structural and functional evidence: from like-to-like bias at short horizontal distance to like-to-all at long horizontal distance. This generic rule accounts for the observed high heterogeneity in interactions between the orientation and retinotopic domains, that we argue is necessary to process non-trivial stimuli in a task-dependent manner.},
	language = {en},
	urldate = {2022-02-06},
	journal = {Brain Structure and Function},
	author = {Chavane, Frédéric and Perrinet, Laurent Udo and Rankin, James},
	month = feb,
	year = {2022},
	keywords = {⛔ No INSPIRE recid found},
}

@article{deweese_binary_2002,
	title = {Binary coding in auditory cortex},
	volume = {15},
	journal = {Advances in neural information processing systems},
	author = {DeWeese, Michael and Zador, Anthony},
	year = {2002},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
}

@article{dan_efficient_1996,
	title = {Efficient coding of natural scenes in the lateral geniculate nucleus: experimental test of a computational theory},
	volume = {16},
	doi = {10.1523/jneurosci.16-10-03351.1996},
	number = {10},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Dan, Yang and Atick, Joseph J and Reid, R C},
	month = may,
	year = {1996},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	pages = {3351--3362},
}

@article{abeles_role_1982,
	title = {Role of the cortical neuron: integrator or coincidence detector?},
	volume = {18},
	number = {1},
	journal = {Israel journal of medical sciences},
	author = {Abeles, Moshe},
	year = {1982},
	keywords = {⛔ No DOI found, ⛔ No INSPIRE recid found},
	pages = {83--92},
}

@article{roelfsema_early_2016,
	title = {Early visual cortex as a multiscale cognitive blackboard},
	volume = {2},
	doi = {10.1146/annurev-vision-111815-114443},
	journal = {Annual review of vision science},
	author = {Roelfsema, Pieter R and de Lange, Floris P},
	year = {2016},
	note = {Publisher: Annual Reviews},
	keywords = {⛔ No INSPIRE recid found},
	pages = {131--151},
}
