%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Laurent Perrinet at 2023-07-10 09:48:52 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{KeatingPerrinet23ICANN,
	abstract = {Recently, there has been growing interest in the hypothesis that information can be carried within neural activity by precise spiking motifs. As a result, there have been several recent proposals for algorithms to detect such motifs in the Spiking Unit Activity (SUA) of populations of neurons. In this study, we introduce a detection model as an inversion of a generative model of raster plot synthesis. From this model, an optimal detection procedure is derived. This takes the form of a logistic regression coupled with a temporal convolution. Since this model is differentiable, we derive a supervised learning method in the form of gradient descent on the loss function of an auto-encoder model. We evaluate the ability of this model to detect spiking motifs in synthetic data. This learning method is able to recover the synthetically generated spiking motifs, and we plan to extend this method to neurobiological data as well.},
	author = {Keating, Miles and Perrinet, Laurent U},
	date-added = {2023-07-10 09:48:36 +0200},
	date-modified = {2023-07-10 09:48:49 +0200},
	grants = {polychronies},
	journal = {ICANN Special Session on Recent Advances in Spiking Neural Networks},
	title = {Accurate detection of spiking motifs in multi-unit raster plots},
	url = {https://laurentperrinet.github.io/publication/keating-perrinet-23-icann/},
	year = {2023},
	bdsk-url-1 = {https://laurentperrinet.github.io/publication/perrinet-23-icann/}}

@article{Gallego2022,
	abstract = {Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of ms), very high dynamic range (140 dB versus 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as low-latency, high speed, and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging field of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic flow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efficient, bio-inspired way for machines to perceive and interact with the world.},
	author = {Gallego, Guillermo and Delbruck, Tobi and Orchard, Garrick and Bartolozzi, Chiara and Taba, Brian and Censi, Andrea and Leutenegger, Stefan and Davison, Andrew J. and Conradt, Jorg and Daniilidis, Kostas and Scaramuzza, Davide},
	doi = {10.1109/TPAMI.2020.3008413},
	file = {Gallego et al. - 2022 - Event-Based Vision A Survey.pdf:/Users/laurentperrinet/Zotero/storage/8TCSL4E7/Gallego et al. - 2022 - Event-Based Vision A Survey.pdf:application/pdf},
	issn = {0162-8828, 2160-9292, 1939-3539},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	number = {1},
	pages = {154--180},
	shorttitle = {Event-{Based} {Vision}},
	title = {Event-{Based} {Vision}: {A} {Survey}},
	url = {https://ieeexplore.ieee.org/document/9138762/},
	urldate = {2022-07-19},
	volume = {44},
	year = {2022},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/9138762/},
	bdsk-url-2 = {https://doi.org/10.1109/TPAMI.2020.3008413}}

@article{kaplan_anisotropic_2013,
	abstract = {Predictive coding hypothesizes that the brain explicitly infers upcoming sensory input to establish a coherent representation of the world. Although it is becoming generally accepted, it is not clear on which level spiking neural networks may implement predictive coding and what function their connectivity may have. We present a network model of conductance-based integrate-and-fire neurons inspired by the architecture of retinotopic cortical areas that assumes predictive coding is implemented through network connectivity, namely in the connection delays and in selectiveness for the tuning properties of source and target cells. We show that the applied connection pattern leads to motion-based prediction in an experiment tracking a moving dot. In contrast to our proposed model, a network with random or isotropic connectivity fails to predict the path when the moving dot disappears. Furthermore, we show that a simple linear decoding approach is sufficient to transform neuronal spiking activity into a probabilistic estimate for reading out the target trajectory.},
	author = {Kaplan, Bernhard and Lansner, Anders and Masson, Guillaume S and Perrinet, Laurent U},
	issn = {1662-5188},
	journal = {Frontiers in Computational Neuroscience},
	title = {Anisotropic connectivity implements motion-based prediction in a spiking neural network},
	url = {https://www.frontiersin.org/articles/10.3389/fncom.2013.00112},
	urldate = {2023-04-06},
	volume = {7},
	year = {2013},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fncom.2013.00112}}

@inproceedings{zhu_unsupervised_2019,
	abstract = {In this work, we propose a novel framework for unsupervised learning for event cameras that learns motion information from only the event stream. In particular, we propose an input representation of the events in the form of a discretized volume that maintains the temporal distribution of the events, which we pass through a neural network to predict the motion of the events. This motion is used to attempt to remove any motion blur in the event image. We then propose a loss function applied to the motion compensated event image that measures the motion blur in this image. We train two networks with this framework, one to predict optical flow, and one to predict egomotion and depths, and evaluate these networks on the Multi Vehicle Stereo Event Camera dataset, along with qualitative results from a variety of different scenes.},
	address = {Long Beach, CA, USA},
	author = {Zhu, Alex Zihao and Yuan, Liangzhe and Chaney, Kenneth and Daniilidis, Kostas},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	doi = {10.1109/CVPR.2019.00108},
	isbn = {978-1-72813-293-8},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = jun,
	pages = {989--997},
	publisher = {IEEE},
	title = {Unsupervised {Event}-{Based} {Learning} of {Optical} {Flow}, {Depth}, and {Egomotion}},
	url = {https://ieeexplore.ieee.org/document/8953979/},
	urldate = {2023-03-21},
	year = {2019},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/8953979/},
	bdsk-url-2 = {https://doi.org/10.1109/CVPR.2019.00108}}

@article{ravello_speed-selectivity_2019,
	abstract = {Motion detection represents one of the critical tasks of the visual system and has motivated a large body of research. However, it remains unclear precisely why the response of retinal ganglion cells (RGCs) to simple artificial stimuli does not predict their response to complex, naturalistic stimuli. To explore this topic, we use Motion Clouds (MC), which are synthetic textures that preserve properties of natural images and are merely parameterized, in particular by modulating the spatiotemporal spectrum complexity of the stimulus by adjusting the frequency bandwidths. By stimulating the retina of the diurnal rodent, Octodon degus with MC we show that the RGCs respond to increasingly complex stimuli by narrowing their adjustment curves in response to movement. At the level of the population, complex stimuli produce a sparser code while preserving movement information; therefore, the stimuli are encoded more efficiently. Interestingly, these properties were observed throughout different populations of RGCs. Thus, our results reveal that the response at the level of RGCs is modulated by the naturalness of the stimulus - in particular for motion - which suggests that the tuning to the statistics of natural images already emerges at the level of the retina.},
	author = {Ravello, C{\'e}sar R. and Perrinet, Laurent U and Escobar, Mar{\'\i}a-Jos{\'e} and Palacios, Adri{\'a}n G},
	doi = {10.1038/s41598-018-36861-8},
	issn = {2045-2322},
	journal = {Scientific Reports},
	keywords = {\#nosource, Retina, motion detection, motion-clouds, ⛔ No INSPIRE recid found},
	language = {En},
	month = jan,
	note = {tex.ids= Ravello19, Ravello2019a tex.bdsk-url-2: https://doi.org/10.1038/s41598-018-36861-8 tex.date-modified: 2019-11-12 13:43:38 +0100 tex.preprint: https://hal-amu.archives-ouvertes.fr/hal-02007905 tex.publisher: Springer Nature number: 1 publisher: Nature Publishing Group},
	number = {1},
	pages = {456},
	title = {Speed-{Selectivity} in {Retinal} {Ganglion} {Cells} is {Sharpened} by {Broad} {Spatial} {Frequency}, {Naturalistic} {Stimuli}},
	url = {https://www.nature.com/articles/s41598-018-36861-8},
	urldate = {2019-02-07},
	volume = {9},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41598-018-36861-8},
	bdsk-url-2 = {https://doi.org/10.1038/s41598-018-36861-8}}

@article{grimaldi_robust_2022,
	abstract = {We propose a neuromimetic architecture able to perform always-on pattern recognition. To achieve this, we extended an existing event-based algorithm [1], which introduced novel spatio-temporal features as a Hierarchy Of Time-Surfaces (HOTS). Built from asynchronous events acquired by a neuromorphic camera, these time surfaces allow to code the local dynamics of a visual scene and to create an efficient event-based pattern recognition architecture. Inspired by neuroscience, we extended this method to increase its performance. Our first contribution was to add a homeostatic gain control on the activity of neurons to improve the learning of spatio-temporal patterns [2]. A second contribution is to draw an analogy between the HOTS algorithm and Spiking Neural Networks (SNN). Following that analogy, our last contribution is to modify the classification layer and remodel the offline pattern categorization method previously used into an online and event-driven one. This classifier uses the spiking output of the network to define novel time surfaces and we then perform online classification with a neuromimetic implementation of a multinomial logistic regression. Not only do these improvements increase consistently the performances of the network, they also make this event-driven pattern recognition algorithm online and bio-realistic. Results were validated on different datasets: DVS barrel [3], Poker-DVS [4] and N-MNIST [5]. We foresee to develop the SNN version of the method and to extend this fully event-driven approach to more naturalistic tasks, notably for always-on, ultra-fast object categorization.},
	author = {Grimaldi, Antoine and Boutin, Victor and Ieng, Sio-Hoi and Benosman, Ryad and Perrinet, Laurent U},
	doi = {10.36227/techrxiv.18003077.v1},
	keywords = {efficient coding, event-based vision, homeostasis, neuromorphic hardware, online classification, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	title = {A robust event-driven approach to always-on object recognition},
	url = {https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1},
	urldate = {2022-01-13},
	year = {2023},
	bdsk-url-1 = {https://www.techrxiv.org/articles/preprint/A_robust_event-driven_approach_to_always-on_object_recognition/18003077/1},
	bdsk-url-2 = {https://doi.org/10.36227/techrxiv.18003077.v1}}

@article{nessler_bayesian_2013,
	abstract = {The principles by which networks of neurons compute, and how spike-timing dependent plasticity (STDP) of synaptic weights generates and maintains their computational function, are unknown. Preceding work has shown that soft winner-take-all (WTA) circuits, where pyramidal neurons inhibit each other via interneurons, are a common motif of cortical microcircuits. We show through theoretical analysis and computer simulations that Bayesian computation is induced in these network motifs through STDP in combination with activity-dependent changes in the excitability of neurons. The fundamental components of this emergent Bayesian computation are priors that result from adaptation of neuronal excitability and implicit generative models for hidden causes that are created in the synaptic weights through STDP. In fact, a surprising result is that STDP is able to approximate a powerful principle for fitting such implicit generative models to high-dimensional spike inputs: Expectation Maximization. Our results suggest that the experimentally observed spontaneous activity and trial-to-trial variability of cortical neurons are essential features of their information processing capability, since their functional role is to represent probability distributions rather than static neural codes. Furthermore it suggests networks of Bayesian computation modules as a new model for distributed information processing in the cortex.},
	author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
	doi = {10.1371/journal.pcbi.1003037},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Action potentials, Learning, Machine learning, Neural networks, Neuronal plasticity, Neurons, Probability distribution, Synapses, ⛔ No INSPIRE recid found},
	language = {en},
	note = {Publisher: Public Library of Science},
	number = {4},
	pages = {e1003037},
	title = {Bayesian {Computation} {Emerges} in {Generic} {Cortical} {Microcircuits} through {Spike}-{Timing}-{Dependent} {Plasticity}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037},
	urldate = {2021-05-20},
	volume = {9},
	year = {2013},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003037},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1003037}}

@article{nadafian_bio-plausible_2020,
	abstract = {The plasticity of the conduction delay between neurons plays a fundamental role in learning. However, the exact underlying mechanisms in the brain for this modulation is still an open problem. Understanding the precise adjustment of synaptic delays could help us in developing effective brain-inspired computational models in providing aligned insights with the experimental evidence. In this paper, we propose an unsupervised biologically plausible learning rule for adjusting the synaptic delays in spiking neural networks. Then, we provided some mathematical proofs to show that our learning rule gives a neuron the ability to learn repeating spatio-temporal patterns. Furthermore, the experimental results of applying an STDP-based spiking neural network equipped with our proposed delay learning rule on Random Dot Kinematogram indicate the efficacy of the proposed delay learning rule in extracting temporal features.},
	author = {Nadafian, Alireza and Ganjtabesh, Mohammad},
	journal = {arXiv:2011.09380 [cs, q-bio]},
	keywords = {Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	month = nov,
	note = {00000 arXiv: 2011.09380},
	title = {Bio-plausible {Unsupervised} {Delay} {Learning} for {Extracting} {Temporal} {Features} in {Spiking} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2011.09380},
	urldate = {2021-04-06},
	year = {2020},
	bdsk-url-1 = {http://arxiv.org/abs/2011.09380}}

@article{grimaldi_precise_2023,
	abstract = {Why do neurons communicate through spikes? By definition, spikes are all-or-none neural events which occur at continuous times. In other words, spikes are on one side binary, existing or not without further details, and on the other, can occur at any asynchronous time, without the need for a centralized clock. This stands in stark contrast to the analog representation of values and the discretized timing classically used in digital processing and at the base of modern-day neural networks. As neural systems almost systematically use this so-called event-based representation in the living world, a better understanding of this phenomenon remains a fundamental challenge in neurobiology in order to better interpret the profusion of recorded data. With the growing need for intelligent embedded systems, it also emerges as a new computing paradigm to enable the efficient operation of a new class of sensors and event-based computers, called neuromorphic, which could enable significant gains in computation time and energy consumption---a major societal issue in the era of the digital economy and global warming. In this review paper, we provide evidence from biology, theory and engineering that the precise timing of spikes plays a crucial role in our understanding of the efficiency of neural networks.},
	author = {Grimaldi, Antoine and Gruel, Am{\'e}lie and Besnainou, Camille and J{\'e}r{\'e}mie, Jean-Nicolas and Martinet, Jean and Perrinet, Laurent U},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	doi = {10.3390/brainsci13010068},
	issn = {2076-3425},
	journal = {Brain Sciences},
	keywords = {asynchronous computing, computational neuroscience, heterogeneous delays, neurobiology, neuromorphic engineering, polychronization, spikes, spiking motifs, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	note = {Number: 1 Publisher: Multidisciplinary Digital Publishing Institute},
	number = {1},
	pages = {68},
	title = {Precise {Spiking} {Motifs} in {Neurobiological} and {Neuromorphic} {Data}},
	url = {https://www.mdpi.com/2076-3425/13/1/68},
	urldate = {2023-01-31},
	volume = {13},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2076-3425/13/1/68},
	bdsk-url-2 = {https://doi.org/10.3390/brainsci13010068}}

@article{zeng_synchronization_2014,
	abstract = {With advances in biochemistry, molecular biology, and neurochemistry there has been impressive progress in the understanding of the molecular properties of anesthetic agents. However, despite these advances, we still do not understand how anesthetic agents affect the properties of neurons that translate into the induction of general anesthesia at the macroscopic level. There is extensive experimental verification that collections of neurons may function as oscillators and the synchronization of oscillators may play a key role in the transmission of information within the central nervous system. This may be particularly relevant to understand the mechanism of action for general anesthesia. In this paper, we develop a stochastic synaptic drive firing rate model for an excitatory and inhibitory cortical neuronal network in the face of system time delays and stochastic input disturbances. In addition, we provide sufficient conditions for global asymptotic and exponential mean-square synchronization for this model.},
	author = {Zeng, Xianlin and Hui, Qing and Haddad, Wassim M. and Hayakawa, Tomohisa and Bailey, James M.},
	doi = {10.1016/j.jfranklin.2013.10.008},
	issn = {00160032},
	journal = {Journal of the Franklin Institute},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = mar,
	number = {3},
	pages = {1205--1225},
	title = {Synchronization of biological neural network systems with stochastic perturbations and time delays},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0016003213003761},
	urldate = {2023-01-31},
	volume = {351},
	year = {2014},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0016003213003761},
	bdsk-url-2 = {https://doi.org/10.1016/j.jfranklin.2013.10.008}}

@inproceedings{zeng_synchronization_2012,
	abstract = {With advances in biochemistry, molecular biology, and neurochemistry there has been impressive progress in the understanding of the molecular properties of anesthetic agents. However, despite these advances, we still do not understand how anesthetic agents affect the properties of neurons that translate into the induction of general anesthesia at the macroscopic level. There is extensive experimental verification that collections of neurons may function as oscillators and the synchronization of oscillators may play a key role in the transmission of information within the central nervous system. This may be particularly relevant to understanding the mechanism of action for general anesthesia. In this paper, we develop a stochastic synaptic drive firing rate model for an excitatory and inhibitory cortical neuronal network in the face of system time delays. In addition, we provide sufficient conditions for global asymptotic mean-square synchronization for this model.},
	author = {Zeng, Xianlin and Hui, Qing and Haddad, Wassim M. and Hayakawa, Tomohisa and Bailey, James M.},
	booktitle = {2012 {IEEE} 51st {IEEE} {Conference} on {Decision} and {Control} ({CDC})},
	doi = {10.1109/CDC.2012.6425969},
	keywords = {Biological neural networks, Biological system modeling, Delay effects, Neurons, Oscillators, Stochastic processes, Synchronization, ⛔ No INSPIRE recid found},
	month = dec,
	note = {ISSN: 0743-1546},
	pages = {1059--1064},
	title = {Synchronization of biological neural network systems with stochastic perturbations and time delays},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1109/CDC.2012.6425969}}

@inproceedings{grimaldi_learning_2022,
	abstract = {The response of a biological neuron depends on the precise timing of afferent spikes. This temporal aspect of the neuronal code is essential in understanding information processing in neurobiology and applies particularly well to the output of neuromorphic hardware such as event-based cameras. However, most artificial neuronal models do not take advantage of this minute temporal dimension and here, we develop a model for the efficient detection of temporal spiking motifs based on a layer of neurons with hetero-synaptic delays. Indeed, the variety of synaptic delays on the dendritic tree allows to synchronize synaptic inputs as they reach the basal dendritic tree. We show this can be formalized as a time-invariant logistic regression which can be trained using labelled data. We apply this model to solve the specific computer vision problem of motion detection, and demonstrate its application to synthetic naturalistic videos transformed into event streams similar to the output of event-based cameras. In particular, we quantify how its accuracy can vary with the total computational load. This end-to-end event-driven computational brick could help improve the performance of future Spiking Neural Network (SNN) algorithms and their prospective use in neuromorphic chips.},
	author = {Grimaldi, Antoine and Perrinet, Laurent U},
	booktitle = {2022 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	doi = {10.1109/ICIP46576.2022.9897394},
	keywords = {Biological neural networks, Cameras, Delays, Motion detection, Neuromorphics, Neurons, Synchronization, efficient coding, event-based computations, logistic regression, motion detection, spiking neural networks, time code, ⛔ No INSPIRE recid found},
	month = oct,
	note = {ISSN: 2381-8549},
	pages = {3591--3595},
	title = {Learning hetero-synaptic delays for motion detection in a single layer of spiking neurons},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/ICIP46576.2022.9897394}}

@article{wang_event-based_2016,
	abstract = {A new multiple orientation event-based neurobiological recognition system is proposed by integrating recognition and tracking function in this paper, which is used for asynchronous address-event representation (AER) image sensors. The characteristic of this system has been enriched to recognize the objects in multiple orientations with only training samples moving in a single orientation. The system extracts multi-scale and multi-orientation line features inspired by models of the primate visual cortex. An orientation detector based on modified Gaussian blob tracking algorithm is introduced for object tracking and orientation detection. The orientation detector and feature extraction block work in simultaneous mode, without any increase in categorization time. An addresses lookup table (addresses LUT) is also presented to adjust the feature maps by addresses mapping and reordering, and they are categorized in the trained spiking neural network. This recognition system is evaluated with the MNIST dataset which have played important roles in the development of computer vision, and the accuracy is increased owing to the use of both ON and OFF events. AER data acquired by a dynamic vision senses (DVS) are also tested on the system, such as moving digits, pokers, and vehicles. The experimental results show that the proposed system can realize event-based multi-orientation recognition. The work presented in this paper makes a number of contributions to the event-based vision processing system for multi-orientation object recognition. It develops a new tracking-recognition architecture to feedforward categorization system and an address reorder approach to classify multi-orientation objects using event-based data. It provides a new way to recognize multiple orientation objects with only samples in single orientation.},
	author = {Wang, Hanyu and Xu, Jiangtao and Gao, Zhiyuan and Lu, Chengye and Yao, Suying and Ma, Jianguo},
	doi = {10.3389/fnins.2016.00498},
	issn = {1662-453X},
	journal = {Frontiers in Neuroscience},
	keywords = {⛔ No INSPIRE recid found},
	title = {An {Event}-{Based} {Neurobiological} {Recognition} {System} with {Orientation} {Detector} for {Objects} in {Multiple} {Orientations}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2016.00498},
	urldate = {2023-01-20},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2016.00498},
	bdsk-url-2 = {https://doi.org/10.3389/fnins.2016.00498}}

@inproceedings{sekikawa_constant_2018,
	abstract = {We propose a novel three-dimensional (3D)-convolution method, cv3dconv, for detecting spatiotemporal features from videos. It reduces the number of sum-of-products of 3D convolution by thousands of times by assuming the constant moving velocity of the camera. We observed that a specific class of video sequences, such as those captured by an in-vehicle camera, can be well approximated with piece-wise linear movements of 2D features in the temporal dimension. Our principal finding is that the 3D kernel, represented by the constant-velocity, can be decomposed into a convolution of a 2D kernel representing the shapes and a 3D kernel representing the velocity. We derived the efficient recursive algorithm for this class of 3D convolution which is exceptionally suited for sparse data, and this parameterized decomposed representation imposes a structured regularization along the temporal direction. We experimentally verified the validity of our approximation using a controlled dataset, and we also showed the effectiveness of cv3dconv for the visual odometry estimation task using real event camera data captured in urban road scene.},
	address = {Verona},
	author = {Sekikawa, Yusuke and Ishikawa, Kohta and Hara, Kosuke and Yoshida, Yuuichi and Suzuki, Koichiro and Sato, Ikuro and Saito, Hideo},
	booktitle = {2018 {International} {Conference} on {3D} {Vision} ({3DV})},
	doi = {10.1109/3DV.2018.00047},
	isbn = {978-1-5386-8425-2},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = sep,
	pages = {343--351},
	publisher = {IEEE},
	title = {Constant {Velocity} {3D} {Convolution}},
	url = {https://ieeexplore.ieee.org/document/8490985/},
	urldate = {2023-01-23},
	year = {2018},
	bdsk-url-1 = {https://ieeexplore.ieee.org/document/8490985/},
	bdsk-url-2 = {https://doi.org/10.1109/3DV.2018.00047}}

@misc{ghosh_spatiotemporal_2019,
	abstract = {In this paper, we address the challenging problem of action recognition, using event-based cameras. To recognise most gestural actions, often higher temporal precision is required for sampling visual information. Actions are defined by motion, and therefore, when using event-based cameras it is often unnecessary to re-sample the entire scene. Neuromorphic, event-based cameras have presented an alternative to visual information acquisition by asynchronously time-encoding pixel intensity changes, through temporally precise spikes (≈ 10 µs resolution), making them well equipped for action recognition. However, other challenges exist, which are intrinsic to event-based imagers, such as higher signal-to-noise ratio, and a spatiotemporally sparse information. One option is to convert event-data into frames, but this could result in significant temporal precision loss. In this work we introduce spatiotemporal filtering in the spike-event domain, as an alternative way of channeling spatiotemporal information through to a convolutional neural network. The filters are local spatiotemporal weight matrices, learned from the spike-event data, in an unsupervised manner. We find that appropriate spatiotemporal filtering significantly improves CNN performance beyond state-of-the-art on the event-based DVS Gesture dataset. On our newly recorded action recognition dataset, our method shows significant improvement when compared with other, standard ways of generating the spatiotemporal filters.},
	author = {Ghosh, Rohan and Gupta, Anupam and Nakagawa, Andrei and Soares, Alcimar and Thakor, Nitish},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, ⛔ No INSPIRE recid found},
	language = {en},
	month = mar,
	note = {arXiv:1903.07067 [cs]},
	publisher = {arXiv},
	title = {Spatiotemporal {Filtering} for {Event}-{Based} {Action} {Recognition}},
	url = {http://arxiv.org/abs/1903.07067},
	urldate = {2023-01-20},
	year = {2019},
	bdsk-url-1 = {http://arxiv.org/abs/1903.07067}}

@article{simoncini_more_2012,
	abstract = {Moving objects generate motion information at different scales, which are processed in the visual system with a bank of spatiotemporal frequency channels. It is not known how the brain pools this information to reconstruct object speed and whether this pooling is generic or adaptive; that is, dependent on the behavioral task. We used rich textured motion stimuli of varying bandwidths to decipher how the human visual motion system computes object speed in different behavioral contexts. We found that, although a simple visuomotor behavior such as short-latency ocular following responses takes advantage of the full distribution of motion signals, perceptual speed discrimination is impaired for stimuli with large bandwidths. Such opposite dependencies can be explained by an adaptive gain control mechanism in which the divisive normalization pool is adjusted to meet the different constraints of perception and action. },
	author = {Simoncini, Claudio and Perrinet, Laurent U and Montagnini, Anna and Mamassian, Pascal and Masson, Guillaume S},
	copyright = {All rights reserved},
	doi = {10.1038/nn.3229},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	month = sep,
	number = {11},
	pages = {1596--1603},
	title = {More is not always better: {Adaptive} gain control explains dissociation between perception and action.},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/23023292 http://dx.doi.org/10.1038/nn.3229},
	volume = {15},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/23023292%20http://dx.doi.org/10.1038/nn.3229},
	bdsk-url-2 = {https://doi.org/10.1038/nn.3229}}

@inproceedings{mansour_pour_speed_2018,
	abstract = {It is still not fully understood how visual system integrates motion energy across different spatial and temporal frequencies to build a coherent percept of the global motion under the complex, noisy naturalistic conditions. We addressed this question by manipulating local speed variability distribution (i. e. speed bandwidth) using a well-controlled class of broadband random-texture stimuli called Motion Clouds (MCs) with continuous naturalistic spatiotemporal frequency spectra (Sanz-Leon et al., 2012, ; Simoncini et al., 2012). In a first 2AFC experiment on speed discrimination, participants had to compare the speed of a broad speed bandwidth MC (range: 0.05-8 $^{\textrm{∘}}$/s) moving at 1 of 5 possible mean speeds (ranging from 5 to 13  $^{\textrm{∘}}$/s) to that of another MC with a small speed bandwidth (SD: 0.05  $^{\textrm{∘}}$/s), always moving at a mean speed of 10 $^{\textrm{∘}}$/s . We found that MCs with larger speed bandwidth (between 0.05-0.5 $^{\textrm{∘}}$/s) were perceived moving faster. Within this range, speed uncertainty results in over-estimating stimulus velocity. However, beyond a critical bandwidth (SD: 0.5  $^{\textrm{∘}}$/s), perception of a coherent speed was lost. In a second 2AFC experiment on direction discrimination, participants had to estimate the motion direction of moving MCs with different speed bandwidths. We found that for large band MCs participant could no longer discriminate motion direction. These results suggest that when increasing speed bandwidth from small to large range, the observer experiences different perceptual regimes. We then decided to run a Maximum Likelihood Difference Scaling (Knoblauch \& Maloney, 2008) experiment with our speed bandwidth stimuli to investigate these different possible perceptual regimes. We identified three regimes within this space that correspond to motion coherency, motion transparency and motion incoherency. These results allow to further characterize the shape of the interactions kernel observed between different speed tuned channels and different spatiotemporal scales (Gekas et al ., 2017) that underlies global velocity estimation.},
	author = {Mansour Pour, Kiana and Gekas, Nikos and Mamassian, Pascal and Perrinet, Laurent U and Montagnini, Anna and Masson, Guillaume S},
	booktitle = {Journal of {Vision}, {Vol}.18, 345, proceedings of {VSS}},
	copyright = {All rights reserved},
	doi = {10.1167/18.10.345},
	keywords = {\#nosource, motion detection, ⛔ No INSPIRE recid found},
	title = {Speed uncertainty and motion perception with naturalistic random textures},
	url = {https://laurentperrinet.github.io/publication/mansour-18-vss},
	year = {2018},
	bdsk-url-1 = {https://laurentperrinet.github.io/publication/mansour-18-vss},
	bdsk-url-2 = {https://doi.org/10.1167/18.10.345}}

@article{priebe_tuning_2006,
	abstract = {We recorded the responses of direction-selective simple and complex cells in the primary visual cortex (V1) of anesthetized, paralyzed macaque monkeys. When studied with sine-wave gratings, almost all simple cells in V1 had responses that were separable for spatial and temporal frequency: the preferred temporal frequency did not change and preferred speed decreased as a function of the spatial frequency of the grating. As in previous recordings from the middle temporal visual area (MT), approximately one-quarter of V1 complex cells had separable responses to spatial and temporal frequency, and one-quarter were ``speed tuned'' in the sense that preferred speed did not change as a function of spatial frequency. Half fell between these two extremes. Reducing the contrast of the gratings caused the population of V1 complex cells to become more separable in their tuning for spatial and temporal frequency. Contrast dependence is explained by the contrast gain of the neurons, which was relatively higher for gratings that were either both of high or both of low temporal and spatial frequency. For stimuli that comprised two spatially superimposed sine-wave gratings, the preferred speeds and tuning bandwidths of V1 neurons could be predicted from the sum of the responses to the component gratings presented alone, unlike neurons in MT that showed nonlinear interactions. We conclude that spatiotemporal modulation of contrast gain creates speed tuning from separable inputs in V1 complex cells. Speed tuning in MT could be primarily inherited from V1, but processing that occurs after V1 and possibly within MT computes selective combinations of speed-tuned signals of special relevance for downstream perceptual and motor mechanisms.},
	author = {Priebe, Nicholas J. and Lisberger, Stephen G. and Movshon, J. Anthony},
	doi = {10.1523/JNEUROSCI.3936-05.2006},
	issn = {0270-6474},
	journal = {The Journal of Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = mar,
	number = {11},
	pages = {2941--2950},
	title = {Tuning for {Spatiotemporal} {Frequency} and {Speed} in {Directionally} {Selective} {Neurons} of {Macaque} {Striate} {Cortex}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2532672/},
	urldate = {2022-09-29},
	volume = {26},
	year = {2006},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2532672/},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3936-05.2006}}

@article{vacher_bayesian_2018,
	abstract = {A common practice to account for psychophysical biases in vision is to frame them as consequences of a dynamic process relying on optimal inference with respect to a generative model. The present study details the complete formulation of such a gen-erative model intended to probe visual motion perception. It is first derived in a set of axiomatic steps constrained by biological plausibility. We then extend previous con-tributions by detailing three equivalent formulations of the Gaussian dynamic texture model. First, the composite dynamic textures are constructed by the random aggrega-tion of warped patterns, which can be viewed as 3D Gaussian fields. Second, these textures are cast as solutions to a stochastic partial differential equation (sPDE). This essential step enables real time, on-the-fly, texture synthesis using time-discretized auto-regressive processes. It also allows for the derivation of a local motion-energy model, which corresponds to the log-likelihood of the probability density. The log-likelihoods are finally essential for the construction of a Bayesian inference framework. We use the model to probe speed perception in humans psychophysically using zoom-like changes in stimulus spatial frequency content. The likelihood is contained within the genera-tive model and we chose a slow speed prior consistent with previous literature. We then validated the fitting process of the model using synthesized data. The human data replicates previous findings that relative perceived speed is positively biased by spatial frequency increments. The effect cannot be fully accounted for by previous models, but the current prior acting on the spatio-temporal likelihoods has proved necessary in accounting for the perceptual bias.},
	author = {Vacher, Jonathan and Meso, Andrew Isaac and Perrinet, Laurent U and Peyr{\'e}, Gabriel},
	copyright = {All rights reserved},
	doi = {10.1162/neco_a_01142},
	journal = {Neural Computation},
	keywords = {\#nosource, Bayesian model, Psychophysics, motion detection, motion-clouds, ⛔ No INSPIRE recid found},
	month = nov,
	title = {Bayesian modeling of motion perception using dynamical stochastic textures},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1162/neco_a_01142}}

@article{baudot_animation_2013,
	abstract = {Synaptic noise is thought to be a limiting factor for computational efficiency in the brain. In visual cortex (V1), ongoing activity is present in vivo, and spiking responses to simple stimuli are highly unreliable across trials. Stimulus statistics used to plot receptive fields, however, are quite different from those experienced during natural visuomotor exploration. We recorded V1 neurons intracellularly in the anaesthetized and paralyzed cat and compared their spiking and synaptic responses to full field natural images animated by simulated eye-movements to those evoked by simpler (grating) or higher dimensionality statistics (dense noise). In most cells, natural scene animation was the only condition where high temporal precision (in the 10--20 ms range) was maintained during sparse and reliable activity. At the subthreshold level, irregular but highly reproducible membrane potential dynamics were observed, even during long (several 100 ms) ``spike-less'' periods. We showed that both the spatial structure of natural scenes and the temporal dynamics of eye-movements increase the signal-to-noise ratio by a non-linear amplification of the signal combined with a reduction of the subthreshold contextual noise. These data support the view that the sparsening and the time precision of the neural code in V1 may depend primarily on three factors: (1) broadband input spectrum: the bandwidth must be rich enough for recruiting optimally the diversity of spatial and time constants during recurrent processing; (2) tight temporal interplay of excitation and inhibition: conductance measurements demonstrate that natural scene statistics narrow selectively the duration of the spiking opportunity window during which the balance between excitation and inhibition changes transiently and reversibly; (3) signal energy in the lower frequency band: a minimal level of power is needed below 10 Hz to reach consistently the spiking threshold, a situation rarely reached with visual dense noise.},
	author = {Baudot, Pierre and Levy, Manuel and Marre, Olivier and Monier, Cyril and Pananceau, Marc and Fr{\'e}gnac, Yves},
	doi = {10.3389/fncir.2013.00206},
	issn = {1662-5110},
	journal = {Frontiers in Neural Circuits},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	title = {Animation of natural scene by virtual eye-movements evokes high precision and low noise in {V1} neurons},
	url = {https://www.frontiersin.org/articles/10.3389/fncir.2013.00206},
	urldate = {2022-09-29},
	volume = {7},
	year = {2013},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fncir.2013.00206},
	bdsk-url-2 = {https://doi.org/10.3389/fncir.2013.00206}}

@article{kremkow_push-pull_2016,
	abstract = {Neurons in the primary visual cortex are known for responding vigorously but with high variability to classical stimuli such as drifting bars or gratings. By contrast, natural scenes are encoded more efficiently by sparse and temporal precise spiking responses. We used a conductance-based model of the visual system in higher mammals to investigate how two specific features of the thalamo-cortical pathway, namely push-pull receptive field organization and synaptic depression, can contribute to this contextual reshaping of V1 responses. By comparing cortical dynamics evoked respectively by natural vs. artificial stimuli in a comprehensive parametric space analysis, we demonstrate that the reliability and sparseness of the spiking responses during natural vision is not a mere consequence of the increased bandwidth in the sensory input spectrum. Rather, it results from the combined impacts of synaptic depression and push-pull inhibition, the later acting for natural scenes as a form of ``effective'' feed-forward inhibition as demonstrated in other sensory systems. Thus, the combination of feedforward-like inhibition with fast thalamo-cortical synaptic depression by simple cells receiving a direct structured input from thalamus composes a generic computational mechanism for generating a sparse and reliable encoding of natural sensory events.},
	author = {Kremkow, Jens and Perrinet, Laurent U and Monier, Cyril and Alonso, Jose-Manuel and Aertsen, Ad and Fr{\'e}gnac, Yves and Masson, Guillaume S},
	copyright = {All rights reserved},
	doi = {10.3389/fncir.2016.00037},
	issn = {1662-5110},
	journal = {Frontiers in Neural Circuits},
	keywords = {\#nosource, Excitation/inhibition, RetinaClouds, Sensory coding, Visual Cortex, area V1, area-v1, natural visual stimuli, push-pull receptive field, statistics of natural images, ⛔ No INSPIRE recid found},
	language = {English},
	month = may,
	title = {Push-{Pull} {Receptive} {Field} {Organization} and {Synaptic} {Depression}: {Mechanisms} for {Reliably} {Encoding} {Naturalistic} {Stimuli} in {V1}},
	url = {https://doi.org/10.3389/fncir.2016.00037},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.3389/fncir.2016.00037}}

@article{deangelis_functional_1999,
	author = {DeAngelis, Gregory C and Ghose, Geoffrey M and Ohzawa, Izumi and Freeman, Ralph D},
	doi = {10.1523/JNEUROSCI.19-10-04046.1999},
	journal = {Journal of Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {10},
	pages = {4046--4064},
	title = {Functional micro-organization of primary visual cortex: receptive field analysis of nearby neurons},
	volume = {19},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1523/JNEUROSCI.19-10-04046.1999}}

@article{masquelier_unsupervised_2007,
	abstract = {Spike timing dependent plasticity (STDP) is a learning rule that modifies synaptic strength as a function of the relative timing of pre- and postsynaptic spikes. When a neuron is repeatedly presented with similar inputs, STDP is known to have the effect of concentrating high synaptic weights on afferents that systematically fire early, while postsynaptic spike latencies decrease. Here we use this learning rule in an asynchronous feedforward spiking neural network that mimics the ventral visual pathway and shows that when the network is presented with natural images, selectivity to intermediate-complexity visual features emerges. Those features, which correspond to prototypical patterns that are both salient and consistently present in the images, are highly informative and enable robust object recognition, as demonstrated on various classification tasks. Taken together, these results show that temporal codes may be a key to understanding the phenomenal processing speed achieved by the visual system and that STDP can lead to fast and selective responses.},
	author = {Masquelier, Timoth{\'e}e and Thorpe, Simon J.},
	doi = {10/cjkr36},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = feb,
	note = {00314},
	number = {2},
	pages = {e31},
	title = {Unsupervised {Learning} of {Visual} {Features} through {Spike} {Timing} {Dependent} {Plasticity}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030031},
	urldate = {2018-09-10},
	volume = {3},
	year = {2007},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030031},
	bdsk-url-2 = {https://doi.org/10/cjkr36}}

@article{zenke_remarkable_2021,
	abstract = {Brains process information in spiking neural networks. Their intricate connections shape the diverse functions these networks perform. Yet how network connectivity relates to function is poorly understood, and the functional capabilities of models of spiking networks are still rudimentary. The lack of both theoretical insight and practical algorithms to find the necessary connectivity poses a major impediment to both studying information processing in the brain and building efficient neuromorphic hardware systems. The training algorithms that solve this problem for artificial neural networks typically rely on gradient descent. But doing so in spiking networks has remained challenging due to the nondifferentiable nonlinearity of spikes. To avoid this issue, one can employ surrogate gradients to discover the required connectivity. However, the choice of a surrogate is not unique, raising the question of how its implementation influences the effectiveness of the method. Here, we use numerical simulations to systematically study how essential design parameters of surrogate gradients affect learning performance on a range of classification problems. We show that surrogate gradient learning is robust to different shapes of underlying surrogate derivatives, but the choice of the derivative's scale can substantially affect learning performance. When we combine surrogate gradients with suitable activity regularization techniques, spiking networks perform robust information processing at the sparse activity limit. Our study provides a systematic account of the remarkable robustness of surrogate gradient learning and serves as a practical guide to model functional spiking neural networks.},
	author = {Zenke, Friedemann and Vogels, Tim P.},
	doi = {10.1162/neco_a_01367},
	issn = {0899-7667},
	journal = {Neural Computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = mar,
	number = {4},
	pages = {899--925},
	title = {The {Remarkable} {Robustness} of {Surrogate} {Gradient} {Learning} for {Instilling} {Complex} {Function} in {Spiking} {Neural} {Networks}},
	urldate = {2021-12-02},
	volume = {33},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1162/neco_a_01367}}

@article{maro_event-based_2020,
	abstract = {In this paper, we introduce a framework for dynamic gesture recognition with background suppression operating on the output of a moving event-based camera. The system is developed to operate in real-time using only the computational capabilities of a mobile phone. It introduces a new development around the concept of time-surfaces. It also presents a novel event-based methodology to dynamically remove backgrounds that uses the high temporal resolution properties of event-based cameras. To our knowledge, this is the first Android event-based framework for vision-based recognition of dynamic gestures running on a smartphone without off-board processing. We assess the performances by considering several scenarios in both indoors and outdoors, for static and dynamic conditions, in uncontrolled lighting conditions. We also introduce a new event-based dataset for gesture recognition with static and dynamic backgrounds (made publicly available). The set of gestures has been selected following a clinical trial to allow human-machine interaction for the visually impaired and older adults. We finally report comparisons with prior work that addressed event-based gesture recognition reporting comparable results, without the use of advanced classification techniques nor power greedy hardware.},
	author = {Maro, Jean-Matthieu and Ieng, Sio-Hoi and Benosman, Ryad},
	doi = {10.3389/fnins.2020.00275},
	issn = {1662-453X},
	journal = {Frontiers in neuroscience},
	keywords = {\#nosource, Background Suppression, Dynamic Gesture Recognition, Dynamic Vision Sensor (Dvs), Event-based, Gesture Recognition, Mobile Device, Neuromorphic, Smartphone, ⛔ No INSPIRE recid found},
	language = {eng},
	month = jan,
	pages = {275},
	title = {Event-{Based} {Gesture} {Recognition} {With} {Dynamic} {Background} {Suppression} {Using} {Smartphone} {Computational} {Capabilities}},
	url = {https://europepmc.org/articles/PMC7160298},
	urldate = {2022-09-28},
	volume = {14},
	year = {2020},
	bdsk-url-1 = {https://europepmc.org/articles/PMC7160298},
	bdsk-url-2 = {https://doi.org/10.3389/fnins.2020.00275}}

@article{dardelet_event-by-event_2021,
	abstract = {Contour velocity estimation and tracking from a fully event-based perspective.},
	author = {Dardelet, Laurent and Benosman, Ryad and Ieng, Sio-Hoi},
	doi = {10.36227/techrxiv.17013824.v1},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = nov,
	title = {An {Event}-by-{Event} {Feature} {Detection} and {Tracking} {Invariant} to {Motion} {Direction} and {Velocity}},
	urldate = {2022-09-28},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.36227/techrxiv.17013824.v1}}

@article{delorme_spikenet_1999,
	abstract = {SpikeNET is a simulator for modeling large networks of asynchronously spiking neurons. It uses simple integrate-and-fire neurons which undergo step-like changes in membrane potential when synaptic inputs arrive. If a threshold is exceeded, the potential is reset and the neuron added to a list to be propagated on the next time step. Using such spike lists greatly reduces the computations associated with large networks, and simplifies implementations using parallel hardware since inter-processor communication can be limited to sending lists of the neurons which just fired. We have used it to model complex multi-layer architectures based on the primate visual system that involve millions of neurons and billions of synaptic connections. Such models are not only biological but also efficient, robust and very fast, qualities which they share with the human visual system.},
	author = {Delorme, Arnaud and Gautrais, Jacques and van Rullen, Rufin and Thorpe, Simon},
	doi = {10.1016/S0925-2312(99)00095-8},
	issn = {0925-2312},
	journal = {Neurocomputing},
	keywords = {\#nosource, Biological visual systems, Categorization, Modeling software, Natural scenes, ⛔ No INSPIRE recid found},
	language = {en},
	month = jun,
	pages = {989--996},
	shorttitle = {{SpikeNET}},
	title = {{SpikeNET}: {A} simulator for modeling large networks of integrate and fire neurons},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231299000958},
	urldate = {2022-09-28},
	volume = {26-27},
	year = {1999},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0925231299000958},
	bdsk-url-2 = {https://doi.org/10.1016/S0925-2312(99)00095-8}}

@article{Leon2012,
	annote = {Publisher: American Physiological Society Bethesda, MD},
	author = {Leon, Paula Sanz and Vanzetta, Ivo and Masson, Guillaume S and Perrinet, Laurent U},
	doi = {10.1152/jn.00737.2011},
	journal = {Journal of neurophysiology},
	keywords = {\#nosource, motion-clouds, anr-trax, bicv-sparse, sanz12jnp, vacher14, Eye movements, Motion detection, log-gabor, kaplan13, Low-level sensory systems, Natural scenes, Optimal stimulation, perrinetadamsfriston14, Python, ⛔ No INSPIRE recid found},
	number = {11},
	pages = {3217--3226},
	title = {Motion clouds: model-based stimulus synthesis of natural-like random textures for the study of motion perception},
	volume = {107},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1152/jn.00737.2011}}

@article{sanz_leon_virtual_2013,
	abstract = {We present The Virtual Brain (TVB), a neuroinformatics platform for full brain network simulations using biologically realistic connectivity. This simulation environment enables the model-based inference of neurophysiological mechanisms across different brain scales that underlie the generation of macroscopic neuroimaging signals including functional MRI (fMRI), EEG and MEG. Researchers from different backgrounds can benefit from an integrative software platform including a supporting framework for data management (generation, organization, storage, integration and sharing) and a simulation core written in Python. TVB allows the reproduction and evaluation of personalized configurations of the brain by using individual subject data. This personalization facilitates an exploration of the consequences of pathological changes in the system, permitting to investigate potential ways to counteract such unfavorable processes. The architecture of TVB supports interaction with MATLAB packages, for example, the well known Brain Connectivity Toolbox. TVB can be used in a client-server configuration, such that it can be remotely accessed through the Internet thanks to its web-based HTML5, JS, and WebGL graphical user interface. TVB is also accessible as a standalone cross-platform Python library and application, and users can interact with the scientific core through the scripting interface IDLE, enabling easy modeling, development and debugging of the scientific kernel. This second interface makes TVB extensible by combining it with other libraries and modules developed by the Python scientific community. In this article, we describe the theoretical background and foundations that led to the development of TVB, the architecture and features of its major software components as well as potential neuroscience applications.},
	author = {Sanz Leon, Paula and Knock, Stuart and Woodman, M. and Domide, Lia and Mersmann, Jochen and McIntosh, Anthony and Jirsa, Viktor},
	doi = {10.3389/fninf.2013.00010},
	issn = {1662-5196},
	journal = {Frontiers in Neuroinformatics},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	shorttitle = {The {Virtual} {Brain}},
	title = {The {Virtual} {Brain}: a simulator of primate brain network dynamics},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2013.00010},
	urldate = {2022-09-28},
	volume = {7},
	year = {2013},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fninf.2013.00010},
	bdsk-url-2 = {https://doi.org/10.3389/fninf.2013.00010}}

@article{bohte_error-backpropagation_2002,
	abstract = {For a network of spiking neurons that encodes information in the timing of individual spike times, we derive a supervised learning rule, SpikeProp, akin to traditional error-backpropagation. With this algorithm, we demonstrate how networks of spiking neurons with biologically reasonable action potentials can perform complex non-linear classification in fast temporal coding just as well as rate-coded networks. We perform experiments for the classical XOR problem, when posed in a temporal setting, as well as for a number of other benchmark datasets. Comparing the (implicit) number of spiking neurons required for the encoding of the interpolated XOR problem, the trained networks demonstrate that temporal coding is a viable code for fast neural information processing, and as such requires less neurons than instantaneous rate-coding. Furthermore, we find that reliable temporal computation in the spiking networks was only accomplished when using spike response functions with a time constant longer than the coding interval, as has been predicted by theoretical considerations.},
	author = {Bohte, Sander M and Kok, Joost N and La Poutr{\'e}, Han},
	doi = {10.1016/S0925-2312(01)00658-0},
	issn = {0925-2312},
	journal = {Neurocomputing},
	language = {en},
	month = oct,
	number = {1},
	pages = {17--37},
	title = {Error-backpropagation in temporally encoded networks of spiking neurons},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231201006580},
	urldate = {2022-09-28},
	volume = {48},
	year = {2002},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0925231201006580},
	bdsk-url-2 = {https://doi.org/10.1016/S0925-2312(01)00658-0}}

@article{brunel_phase_2000,
	author = {Brunel, Nicolas},
	doi = {10.1016/s0925-2312(00)00179-x},
	issn = {09252312},
	journal = {Neurocomputing},
	language = {en},
	month = jun,
	pages = {307--312},
	title = {Phase diagrams of sparsely connected networks of excitatory and inhibitory spiking neurons},
	urldate = {2019-01-14},
	volume = {32-33},
	year = {2000},
	bdsk-url-1 = {https://doi.org/10.1016/s0925-2312(00)00179-x}}

@article{schrimpf_brain-score_2020,
	abstract = {The internal representations of early deep artificial neural networks (ANNs) were found to be remarkably similar to the internal neural representations measured experimentally in the primate brain. Here we ask, as deep ANNs have continued to evolve, are they becoming more or less brain-like? ANNs that are most functionally similar to the brain will contain mechanisms that are most like those used by the brain. We therefore developed Brain-Score -- a composite of multiple neural and behavioral benchmarks that score any ANN on how similar it is to the brain's mechanisms for core object recognition -- and we deployed it to evaluate a wide range of state-of-the-art deep ANNs. Using this scoring system, we here report that: (1) DenseNet-169, CORnet-S and ResNet-101 are the most brain-like ANNs. (2) There remains considerable variability in neural and behavioral responses that is not predicted by any ANN, suggesting that no ANN model has yet captured all the relevant mechanisms. (3) Extending prior work, we found that gains in ANN ImageNet performance led to gains on Brain-Score. However, correlation weakened at ¿= 70\% top-1 ImageNet performance, suggesting that additional guidance from neuroscience is needed to make further advances in capturing brain mechanisms. (4) We uncovered smaller (i.e. less complex) ANNs that are more brain-like than many of the best-performing ImageNet models, which suggests the opportunity to simplify ANNs to better understand the ventral stream. The scoring system used here is far from complete. However, we propose that evaluating and tracking model-benchmark correspondences through a Brain-Score that is regularly updated with new brain data is an exciting opportunity: experimental benchmarks can be used to guide machine network evolution, and machine networks are mechanistic hypotheses of the brain's network and thus drive next experiments. To facilitate both of these, we release Brain-Score.org: a platform that hosts the neural and behavioral benchmarks, where ANNs for visual processing can be submitted to receive a Brain-Score and their rank relative to other models, and where new experimental data can be naturally incorporated.},
	author = {Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Kar, Kohitij and Bashivan, Pouya and Prescott-Roy, Jonathan and Geiger, Franziska and Schmidt, Kailyn and Yamins, Daniel L. K. and DiCarlo, James J.},
	doi = {10.1101/407007},
	journal = {bioRxiv : the preprint server for biology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	note = {Publisher: Cold Spring Harbor Laboratory tex.elocation-id: 407007 tex.eprint: https://www.biorxiv.org/content/early/2020/01/02/407007.full.pdf},
	title = {Brain-score: {Which} artificial neural network for object recognition is most brain-like?},
	url = {https://www.biorxiv.org/content/early/2020/01/02/407007},
	year = {2020},
	bdsk-url-1 = {https://www.biorxiv.org/content/early/2020/01/02/407007},
	bdsk-url-2 = {https://doi.org/10.1101/407007}}

@article{simonyan_very_2015,
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	author = {Simonyan, Karen and Zisserman, Andrew},
	keywords = {\#nosource, Computer Science - Computer Vision and Pattern Recognition, ⛔ No DOI found},
	month = apr,
	note = {158 citations (INSPIRE 2022/10/1) 158 citations w/o self (INSPIRE 2022/10/1) arXiv:1409.1556 [cs.CV]},
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	urldate = {2021-05-24},
	year = {2015},
	bdsk-url-1 = {http://arxiv.org/abs/1409.1556}}

@book{mandelbrot_fractal_1982,
	abstract = {Rev. ed. of: Fractals. c1977; Includes indexes; Bibliography: p. [425]-443},
	author = {Mandelbrot, Benoit B.},
	collaborator = {{Internet Archive}},
	isbn = {978-0-7167-1186-5},
	language = {eng},
	publisher = {San Francisco: W.H. Freeman},
	title = {The fractal geometry of nature},
	url = {http://archive.org/details/fractalgeometryo00beno},
	urldate = {2022-09-27},
	year = {1982},
	bdsk-url-1 = {http://archive.org/details/fractalgeometryo00beno}}

@article{goodman_spike-timing-based_2010,
	abstract = {Spike timing is precise in the auditory system and it has been argued that it conveys information about auditory stimuli, in particular about the location of a sound source. However, beyond simple time differences, the way in which neurons might extract this information is unclear and the potential computational advantages are unknown. The computational difficulty of this task for an animal is to locate the source of an unexpected sound from two monaural signals that are highly dependent on the unknown source signal. In neuron models consisting of spectro-temporal filtering and spiking nonlinearity, we found that the binaural structure induced by spatialized sounds is mapped to synchrony patterns that depend on source location rather than on source signal. Location-specific synchrony patterns would then result in the activation of location-specific assemblies of postsynaptic neurons. We designed a spiking neuron model which exploited this principle to locate a variety of sound sources in a virtual acoustic environment using measured human head-related transfer functions. The model was able to accurately estimate the location of previously unknown sounds in both azimuth and elevation (including front/back discrimination) in a known acoustic environment. We found that multiple representations of different acoustic environments could coexist as sets of overlapping neural assemblies which could be associated with spatial locations by Hebbian learning. The model demonstrates the computational relevance of relative spike timing to extract spatial information about sources independently of the source signal.},
	author = {Goodman, Dan F. M. and Brette, Romain},
	doi = {10.1371/journal.pcbi.1000993},
	issn = {1553-7358},
	journal = {PLoS Comput Biol},
	keywords = {\#nosource, spike, spikes, synchrony, ⛔ No INSPIRE recid found},
	month = nov,
	number = {11},
	pmid = {21085681},
	title = {Spike-timing-based computation in sound localization.},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2978676/},
	volume = {6},
	year = {2010},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2978676/},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1000993}}

@article{macdonald_neuromorphic_2022,
	abstract = {Dexterous manipulation in robotic hands relies on an accurate sense of artificial touch. Here we investigate neuromorphic tactile sensation with an event-based optical tactile sensor combined with spiking neural networks for edge orientation detection. The sensor incorporates an event-based vision system (mini-eDVS) into a low-form factor artificial fingertip (the NeuroTac). The processing of tactile information is performed through a Spiking Neural Network with unsupervised Spike-Timing-Dependent Plasticity (STDP) learning, and the resultant output is classified with a 3-nearest neighbours classifier. Edge orientations were classified in 10-degree increments while tapping vertically downward and sliding horizontally across the edge. In both cases, we demonstrate that the sensor is able to reliably detect edge orientation, and could lead to accurate, bio-inspired, tactile processing in robotics and prosthetics applications.},
	author = {Macdonald, Fraser L. A. and Lepora, Nathan F. and Conradt, J{\"o}rg and Ward-Cherrier, Benjamin},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	doi = {10.3390/s22186998},
	issn = {1424-8220},
	journal = {Sensors},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	note = {Number: 18 Publisher: Multidisciplinary Digital Publishing Institute},
	number = {18},
	pages = {6998},
	title = {Neuromorphic {Tactile} {Edge} {Orientation} {Classification} in an {Unsupervised} {Spiking} {Neural} {Network}},
	url = {https://www.mdpi.com/1424-8220/22/18/6998},
	urldate = {2022-09-26},
	volume = {22},
	year = {2022},
	bdsk-url-1 = {https://www.mdpi.com/1424-8220/22/18/6998},
	bdsk-url-2 = {https://doi.org/10.3390/s22186998}}

@article{haag_fly_2004,
	abstract = {The computational structure of an optimal motion detector was proposed to depend on the signal-to-noise ratio (SNR) of the stimulus: At low SNR, the optimal motion detector should be a correlation or "Reichardt" type, whereas at high SNR, the detector would employ a gradient scheme [Potters, M. \& Bialek, W. (1994) J. Physiol. (Paris) 4, 1755-1775]. Although a large body of experiments supports the Reichardt detector as the processing scheme leading to direction selectivity in fly motion vision, in most of these studies the SNR was rather low. We therefore reinvestigated the question over a much larger SNR range. Using 2-photon microscopy, we found that local dendritic [Ca(2+)] modulations, which are characteristic of Reichardt detectors, occur in response to drifting gratings over a wide range of luminance levels and contrasts. We also explored, as another fingerprint of Reichardt detectors, the dependence of the velocity optimum on the pattern wavelength. Again, we found Reichardt-typical behavior throughout the whole luminance and contrast range tested. Our results, therefore, provide strong evidence that only a single elementary processing scheme is used in fly motion vision.},
	author = {Haag, J. and Denk, W. and Borst, A.},
	doi = {10.1073/pnas.0407368101},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	keywords = {\#nosource, Algorithms, Animals, Calcium Signaling, Diptera, Electrophysiology, Female, Models, Neurological, Motion, Motion Perception, Optics and Photonics, Photic Stimulation, Vision, Ocular, biology, delay-learning, insects, ⛔ No INSPIRE recid found},
	language = {eng},
	month = nov,
	number = {46},
	pages = {16333--16338},
	pmcid = {PMC526200},
	pmid = {15534201},
	title = {Fly motion vision is based on {Reichardt} detectors regardless of the signal-to-noise ratio},
	volume = {101},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.0407368101}}

@article{paredes-valles_unsupervised_2020,
	abstract = {The combination of spiking neural networks and event-based vision sensors holds the potential of highly efficient and high-bandwidth optical flow estimation. This paper presents the first hierarchical spiking architecture in which motion (direction and speed) selectivity emerges in an unsupervised fashion from the raw stimuli generated with an event-based camera. A novel adaptive neuron model and stable spike-timing-dependent plasticity formulation are at the core of this neural network governing its spike-based processing and learning, respectively. After convergence, the neural architecture exhibits the main properties of biological visual motion systems, namely feature extraction and local and global motion perception. Convolutional layers with input synapses characterized by single and multiple transmission delays are employed for feature and local motion perception, respectively; while global motion selectivity emerges in a final fully-connected layer. The proposed solution is validated using synthetic and real event sequences. Along with this paper, we provide the cuSNN library, a framework that enables GPU-accelerated simulations of large-scale spiking neural networks. Source code and samples are available at https://github.com/tudelft/cuSNN.},
	author = {Paredes-Vall{\'e}s, Federico and Scheper, Kirk Y. W. and de Croon, Guido C. H. E.},
	doi = {10.1109/tpami.2019.2903179},
	issn = {1939-3539},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {\#nosource, Biological information theory, Biological system modeling, Biomedical optical imaging, Event-based vision, Neurons, Optical sensors, Vision sensors, Visualization, feature extraction, motion detection, neural nets, neuromorphic computing, unsupervised learning, ⛔ No INSPIRE recid found},
	month = aug,
	note = {00047 Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	number = {8},
	pages = {2051--2064},
	shorttitle = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}},
	title = {Unsupervised {Learning} of a {Hierarchical} {Spiking} {Neural} {Network} for {Optical} {Flow} {Estimation}: {From} {Events} to {Global} {Motion} {Perception}},
	volume = {42},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1109/tpami.2019.2903179}}

@inproceedings{lee_real-time_2014,
	abstract = {Fast and efficient motion estimation is essential for a number of applications including the gesture-based user interface (UI) for portable devices like smart phones. In this paper, we propose a highly efficient method that can estimate four degree of freedom (DOF) motional components of a moving object based on an event-based vision sensor, the dynamic vision sensor (DVS). The proposed method finds informative events occurred at edges and estimates their velocities for global motion analysis. We will also describe a novel method to correct the aperture problem in the motion estimation.},
	address = {Paris, France},
	author = {Lee, Jun Haeng and Lee, Kyoobin and Ryu, Hyunsurk and Park, Paul K. J. and Shin, Chang-Woo and Woo, Jooyeon and Kim, Jun-Seok},
	booktitle = {2014 {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
	doi = {10.1109/ICIP.2014.7025040},
	isbn = {978-1-4799-5751-4},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = oct,
	pages = {204--208},
	publisher = {IEEE},
	title = {Real-time motion estimation based on event-based vision sensor},
	url = {http://ieeexplore.ieee.org/document/7025040/},
	urldate = {2022-07-19},
	year = {2014},
	bdsk-url-1 = {http://ieeexplore.ieee.org/document/7025040/},
	bdsk-url-2 = {https://doi.org/10.1109/ICIP.2014.7025040}}

@article{benosman_event-based_2014,
	abstract = {This paper introduces a new methodology to compute dense visual flow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artificial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual flow from the local properties of events' spatiotemporal space. We will show that precise visual flow orientation and amplitude can be estimated using a local differential approach on the surface defined by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion flow with microsecond accuracy and at very low computational cost.},
	author = {Benosman, Ryad and Clercq, Charles and Lagorce, Xavier and {Sio-Hoi Ieng} and Bartolozzi, Chiara},
	doi = {10.1109/tnnls.2013.2273537},
	issn = {2162-237X, 2162-2388},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = feb,
	number = {2},
	pages = {407--417},
	title = {Event-{Based} {Visual} {Flow}},
	url = {https://www.neuromorphic-vision.com/public/publications/3/publication.pdf},
	urldate = {2022-02-01},
	volume = {25},
	year = {2014},
	bdsk-url-1 = {https://www.neuromorphic-vision.com/public/publications/3/publication.pdf},
	bdsk-url-2 = {https://doi.org/10.1109/tnnls.2013.2273537}}

@article{frye_elementary_2015,
	author = {Frye, Mark},
	doi = {10.1016/j.cub.2015.01.013},
	issn = {09609822},
	journal = {Current Biology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = mar,
	number = {6},
	pages = {R215--R217},
	title = {Elementary motion detectors},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982215000159},
	urldate = {2022-03-21},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0960982215000159},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.01.013}}

@article{brette_exact_2007,
	abstract = {Neural networks can be simulated exactly using event-driven strategies, in which the algorithm advances directly from one spike to the next spike. It applies to neuron models for which we have (1) an explicit expression for the evolution of the state variables between spikes and (2) an explicit test on the state variables that predicts whether and when a spike will be emitted. In a previous work, we proposed a method that allows exact simulation of an integrate-and-fire model with exponential conductances, with the constraint of a single synaptic time constant. In this note, we propose a method, based on polynomial root finding, that applies to integrate-and-fire models with exponential currents, with possibly many different synaptic time constants. Models can include biexponential synaptic currents and spike-triggered adaptation currents.},
	author = {Brette, Romain},
	doi = {10.1162/neco.2007.19.10.2604},
	issn = {0899-7667, 1530-888X},
	journal = {Neural Computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = oct,
	number = {10},
	pages = {2604--2609},
	title = {Exact {Simulation} of {Integrate}-and-{Fire} {Models} with {Exponential} {Currents}},
	url = {https://direct.mit.edu/neco/article/19/10/2604-2609/7220},
	urldate = {2022-09-15},
	volume = {19},
	year = {2007},
	bdsk-url-1 = {https://direct.mit.edu/neco/article/19/10/2604-2609/7220},
	bdsk-url-2 = {https://doi.org/10.1162/neco.2007.19.10.2604}}

@article{engbert_integrated_2011,
	abstract = {When we fixate a stationary target, our eyes generate miniature (or fixational) eye movements involuntarily. These fixational eye movements are classified as slow components (physiological drift, tremor) and microsaccades, which represent rapid, small-amplitude movements. Here we propose an integrated mathematical model for the generation of slow fixational eye movements and microsaccades. The model is based on the concept of self-avoiding random walks in a potential, a process driven by a self-generated activation field. The self-avoiding walk generates persistent movements on a short timescale, whereas, on a longer timescale, the potential produces antipersistent motions that keep the eye close to an intended fixation position. We introduce microsaccades as fast movements triggered by critical activation values. As a consequence, both slow movements and microsaccades follow the same law of motion; i.e., movements are driven by the self-generated activation field. Thus, the model contributes a unified explanation of why it has been a long-standing problem to separate slow movements and microsaccades with respect to their motion-generating principles. We conclude that the concept of a self-avoiding random walk captures fundamental properties of fixational eye movements and provides a coherent theoretical framework for two physiologically distinct movement types.},
	author = {Engbert, Ralf and Mergenthaler, Konstantin and Sinn, Petra and Pikovsky, Arkady},
	doi = {10.1073/pnas.1102730108},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = sep,
	number = {39},
	pages = {E765--E770},
	title = {An integrated model of fixational eye movements and microsaccades},
	url = {https://www.pnas.org/content/108/39/E765},
	urldate = {2021-02-18},
	volume = {108},
	year = {2011},
	bdsk-url-1 = {https://www.pnas.org/content/108/39/E765},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1102730108}}

@article{perrinet_emergence_2004,
	abstract = {As an alternative to classical representations in machine learning algorithms, we explore coding strategies using events as is observed for spiking neurons in the central nervous system. Focusing on visual processing, we have previously shown that we may define a sparse spike coding scheme by implementing accordingly lateral interactions (Neurocomputing 57 (2004) 125). This class of algorithms is both compatible with biological constraints and also to neurophysiological observations and yields a performant algorithm of computing by events. We explore here learning mechanisms to unsupervisely derive an optimal overcomplete set of filters based on previous work of (Vision Res. 37 (1998) 3311) and show its biological relevance. {\copyright} 2004 Elsevier B.V. All rights reserved.},
	author = {Perrinet, Laurent U},
	copyright = {All rights reserved},
	doi = {10.1016/j.neucom.2004.01.133},
	issn = {09252312},
	journal = {Neurocomputing},
	keywords = {\#nosource, Sparse spike coding, Unsupervised learning, Vision, area-v1, receptive field, receptive\_field, sparse coding, sparse\_coding, ⛔ No INSPIRE recid found},
	number = {C},
	pages = {821--826},
	title = {Emergence of filters from natural scenes in a sparse spike coding scheme},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204001389},
	volume = {58-60},
	year = {2004},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204001389},
	bdsk-url-2 = {https://doi.org/10.1016/j.neucom.2004.01.133}}

@article{masquelier_competitive_2009,
	author = {Masquelier, Timoth{\'e}e and Guyonneau, Rudy and Thorpe, Simon J.},
	doi = {10.1162/neco.2008.06-08-804},
	issn = {0899-7667, 1530-888X},
	journal = {Neural Computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = may,
	note = {00203},
	number = {5},
	pages = {1259--1276},
	title = {Competitive {STDP}-{Based} {Spike} {Pattern} {Learning}},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.2008.06-08-804},
	urldate = {2018-09-10},
	volume = {21},
	year = {2009},
	bdsk-url-1 = {http://www.mitpressjournals.org/doi/10.1162/neco.2008.06-08-804},
	bdsk-url-2 = {https://doi.org/10.1162/neco.2008.06-08-804}}

@article{barlow_unsupervised_1989,
	abstract = {What use can the brain make of the massive flow of sensory information that occurs without any associated rewards or punishments? This question is reviewed in the light of connectionist models of unsupervised learning and some older ideas, namely the cognitive maps and working models of Tolman and Craik, and the idea that redundancy is important for understanding perception (Attneave 1954), the physiology of sensory pathways (Barlow 1959), and pattern recognition (Watanabe 1960). It is argued that (1) The redundancy of sensory messages provides the knowledge incorporated in the maps or models. (2) Some of this knowledge can be obtained by observations of mean, variance, and covariance of sensory messages, and perhaps also by a method called ``minimum entropy coding.'' (3) Such knowledge may be incorporated in a model of ``what usually happens'' with which incoming messages are automatically compared, enabling unexpected discrepancies to be immediately identified. (4) Knowledge of the sort incorporated into such a filter is a necessary prerequisite of ordinary learning, and a representation whose elements are independent makes it possible to form associations with logical functions of the elements, not just with the elements themselves.},
	author = {Barlow, H.B.},
	doi = {10.1162/neco.1989.1.3.295},
	issn = {0899-7667},
	journal = {Neural Computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = sep,
	number = {3},
	pages = {295--311},
	title = {Unsupervised {Learning}},
	url = {https://doi.org/10.1162/neco.1989.1.3.295},
	urldate = {2022-09-15},
	volume = {1},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1162/neco.1989.1.3.295}}

@article{rogers_motion_1979,
	abstract = {The perspective transformations of the retinal image, produced by either the movement of an observer or the movement of objects in the visual world, were found to produce a reliable, consistent, and unambiguous impression of relative depth in the absence of all other cues to depth and distance. The stimulus displays consisted of computer-generated random-dot patterns that could be transformed by each movement of the observer or the display oscilloscope to simulate the relative movement information produced by a three-dimensional surface. Using a stereoscopic matching task, the second experiment showed that the perceived depth from parallax transformations is in close agreement with the degree of relative image displacement, as well as producing a compelling impression of three-dimensionality not unlike that found with random-dot stereograms.},
	author = {Rogers, Brian and Graham, Maureen},
	doi = {10.1068/p080125},
	issn = {0301-0066},
	journal = {Perception},
	keywords = {\#nosource},
	language = {en},
	month = apr,
	note = {Publisher: SAGE Publications Ltd STM},
	number = {2},
	pages = {125--134},
	title = {Motion {Parallax} as an {Independent} {Cue} for {Depth} {Perception}},
	url = {https://doi.org/10.1068/p080125},
	urldate = {2022-09-15},
	volume = {8},
	year = {1979},
	bdsk-url-1 = {https://doi.org/10.1068/p080125}}

@article{yoonessi_contribution_2011,
	abstract = {Relative image motion resulting from active movement of the observer could potentially serve as a powerful perceptual cue, both for segmentation of object boundaries and for depth perception. To examine the perceptual role of motion parallax from shearing motion, we measured human performance in three psychophysical tasks: segmentation, depth ordering, and depth magnitude estimation. Stimuli consisted of random dot textures that were synchronized to head movement with sine- or square-wave modulation patterns. Segmentation was assessed with a 2AFC orientation judgment of a motion-defined boundary. In the depth-ordering task, observers reported which modulation half-cycle appeared in front of the other. Perceived depth magnitude was matched to that of a 3D rendered image with multiple static cues. The results indicate that head movement might not be important for segmentation, even though it is crucial for obtaining depth from motion parallax---thus, concomitant depth perception does not appear to facilitate segmentation. Our findings suggest that segmentation works best for abrupt, sharply defined motion boundaries, whereas smooth gradients are more powerful for obtaining depth from motion parallax. Thus, motion parallax may contribute in a different manner to segmentation and to depth perception and suggests that their underlying mechanisms might be distinct.},
	author = {Yoonessi, Ahmad and Baker, Jr., Curtis L.},
	doi = {10.1167/11.9.13},
	issn = {1534-7362},
	journal = {Journal of Vision},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = aug,
	number = {9},
	pages = {13},
	title = {Contribution of motion parallax to segmentation and depth perception},
	url = {https://doi.org/10.1167/11.9.13},
	urldate = {2022-09-15},
	volume = {11},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1167/11.9.13}}

@article{nawrot_eye_2003,
	abstract = {It has been unclear whether the perception of depth from motion parallax is an entirely visual process or whether it requires extra-retinal information such as head movements, vestibular activation, or eye movements. Using a motion aftereffect and static test stimulus technique to eliminate visual cues to depth, this psychophysical study demonstrates that the visual system employs a slow eye movement signal, optokinetic response (OKR) in particular, for the unambiguous perception of depth from motion parallax. A vestibular signal, or vestibularly driven eye movement signal is insufficient for unambiguous depth from motion parallax. Removal of the OKR eye movement signal gives rise to ambiguous perceived depth in motion parallax conditions. Neurophysiological studies suggest a possible neural mechanism in medial temporal and medial superior temporal cortical neurons that are selective to depth, motion, and direction of eye movement.},
	author = {Nawrot, Mark},
	doi = {10.1016/S0042-6989(03)00144-5},
	issn = {0042-6989},
	journal = {Vision Research},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = jun,
	number = {14},
	pages = {1553--1562},
	title = {Eye movements provide the extra-retinal signal required for the perception of depth from motion parallax},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698903001445},
	urldate = {2022-09-15},
	volume = {43},
	year = {2003},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0042698903001445},
	bdsk-url-2 = {https://doi.org/10.1016/S0042-6989(03)00144-5}}

@article{villette_internally_2015,
	abstract = {The hippocampus is essential for spatiotemporal cognition. Sequences of neuronal activation provide a substrate for this fundamental function. At the behavioral timescale, these sequences have been shown to occur either in the presence of successive external landmarks or through internal mechanisms within an episodic memory task. In both cases, activity is externally constrained by the organization of the task and by the size of the environment explored. Therefore, it remains unknown whether hippocampal activity can self-organize into a default mode in the absence of any external memory demand or spatiotemporal boundary. Here we show that, in the presence of self-motion cues, a population code integrating distance naturally emerges in the hippocampus in the form of recurring sequences. These internal dynamics clamp spontaneous travel since run distance distributes into integer multiples of the span of these sequences. These sequences may thus guide navigation when external landmarks are reduced.},
	author = {Villette, Vincent and Malvache, Arnaud and Tressard, Thomas and Dupuy, Nathalie and Cossart, Rosa},
	doi = {10.1016/j.neuron.2015.09.052},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = oct,
	number = {2},
	pages = {357--366},
	title = {Internally {Recurring} {Hippocampal} {Sequences} as a {Population} {Template} of {Spatiotemporal} {Information}},
	urldate = {2022-01-17},
	volume = {88},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1016/j.neuron.2015.09.052}}

@article{malvache_awake_2016,
	abstract = {The chained activation of neuronal assemblies is thought to support major cognitive processes, including memory. In the hippocampus, this is observed during population bursts often associated with sharp-wave ripples, in the form of an ordered reactivation of neurons. However, the organization and lifetime of these assemblies remain unknown. We used calcium imaging to map patterns of synchronous neuronal activation in the CA1 region of awake mice during runs on a treadmill. The patterns were composed of the recurring activation of anatomically intermingled, but functionally orthogonal, assemblies. These assemblies reactivated discrete temporal segments of neuronal sequences observed during runs and could be stable across consecutive days. A binding of these assemblies into longer chains revealed temporally ordered replay. These modules may represent the default building blocks for encoding or retrieving experience.},
	author = {Malvache, Arnaud and Reichinnek, Susanne and Villette, Vincent and Haimerl, Caroline and Cossart, Rosa},
	doi = {10.1126/science.aaf3319},
	issn = {1095-9203},
	journal = {Science (New York, N.Y.)},
	keywords = {\#nosource, Animals, Brain Mapping, CA1 Region, Hippocampal, Calcium Signaling, Exercise Test, Male, Mice, Nerve Net, Neurons, Running, Wakefulness, ⛔ No INSPIRE recid found},
	language = {eng},
	month = sep,
	number = {6305},
	pages = {1280--1283},
	title = {Awake hippocampal reactivations project onto orthogonal neuronal assemblies},
	volume = {353},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1126/science.aaf3319}}

@article{haimerl_internal_2019,
	abstract = {The hippocampus plays a critical role in episodic memory: the sequential representation of visited places and experienced events. This function is mirrored by hippocampal activity that self organizes into sequences of neuronal activation that integrate spatiotemporal information. What are the underlying mechanisms of such integration is still unknown. Single cell activity was recently shown to combine time and distance information; however, it remains unknown whether a degree of tuning between space and time can be defined at the network level. Here, combining daily calcium imaging of CA1 sequence dynamics in running head-fixed mice and network modeling, we show that CA1 network activity tends to represent a specific combination of space and time at any given moment, and that the degree of tuning can shift within a continuum from 1 day to the next. Our computational model shows that this shift in tuning can happen under the control of the external drive power. We propose that extrinsic global inputs shape the nature of spatiotemporal integration in the hippocampus at the population level depending on the task at hand, a hypothesis which may guide future experimental studies.},
	author = {Haimerl, Caroline and Angulo-Garcia, David and Villette, Vincent and Reichinnek, Susanne and Torcini, Alessandro and Cossart, Rosa and Malvache, Arnaud},
	doi = {10.1073/pnas.1718518116},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {\#nosource, attractor network, hippocampus, neural model, space representation, time representation, ⛔ No INSPIRE recid found},
	language = {en},
	month = apr,
	number = {15},
	pages = {7477--7482},
	title = {Internal representation of hippocampal neuronal population spans a time-distance continuum},
	url = {https://www.pnas.org/content/116/15/7477},
	urldate = {2022-01-17},
	volume = {116},
	year = {2019},
	bdsk-url-1 = {https://www.pnas.org/content/116/15/7477},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1718518116}}

@article{pastalkova_internally_2008,
	abstract = {A longstanding conjecture in neuroscience is that aspects of cognition depend on the brain's ability to self-generate sequential neuronal activity. We found that reliably and continually-changing cell assemblies in the rat hippocampus appeared not only during spatial navigation but also in the absence of changing environmental or body-derived inputs. During the delay period of a memory task each moment in time was characterized by the activity of a unique assembly of neurons. Identical initial conditions triggered a similar assembly sequence, whereas different conditions gave rise, uniquely, to different sequences, thereby predicting behavioral choices, including errors. Such sequences were not formed in control, non-memory, tasks. We hypothesize that neuronal representations, evolved for encoding distance in spatial navigation, also support episodic recall and the planning of action sequences.},
	author = {Pastalkova, Eva and Itskov, Vladimir and Amarasingham, Asohan and Buzs{\'a}ki, Gy{\"o}rgy},
	doi = {10.1126/science.1159775},
	issn = {0036-8075},
	journal = {Science (New York, N.Y.)},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = sep,
	number = {5894},
	pages = {1322--1327},
	title = {Internally {Generated} {Cell} {Assembly} {Sequences} in the {Rat} {Hippocampus}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570043/},
	urldate = {2022-02-23},
	volume = {321},
	year = {2008},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570043/},
	bdsk-url-2 = {https://doi.org/10.1126/science.1159775}}

@article{luczak_sequential_2007,
	abstract = {Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating ``DOWN'' states of generalized neural silence and ``UP'' states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50--200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.},
	author = {Luczak, Artur and Barth{\'o}, Peter and Marguet, Stephan L. and Buzs{\'a}ki, Gy{\"o}rgy and Harris, Kenneth D.},
	doi = {10.1073/pnas.0605643104},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {\#nosource, microcircuits, neuronal assembly, repeating sequences, slow oscillations, syntire chains, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	number = {1},
	pages = {347--352},
	title = {Sequential structure of neocortical spontaneous activity in vivo},
	url = {https://www.pnas.org/content/104/1/347},
	urldate = {2022-02-23},
	volume = {104},
	year = {2007},
	bdsk-url-1 = {https://www.pnas.org/content/104/1/347},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0605643104}}

@article{ikegaya_synfire_2004,
<<<<<<< HEAD
	title = {Synfire Chains and Cortical Songs: Temporal Modules of Cortical Activity},
	volume = {304},
	url = {http://www.science.org/doi/10.1126/science.1093173},
	doi = {10.1126/science.1093173},
	number = {5670},
	urldate = {2021-11-29},
	journal = {Science},
=======
>>>>>>> 54fa16285d42085d7998858503f94f2677494c06
	author = {Ikegaya, Yuji and Aaron, Gloster and Cossart, Rosa and Aronov, Dmitriy and Lampl, Ilan and Ferster, David and Yuste, Rafael},
	doi = {10.1126/science.1093173},
	journal = {Science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = apr,
	number = {5670},
	pages = {559--564},
	shorttitle = {Synfire {Chains} and {Cortical} {Songs}},
	title = {Synfire {Chains} and {Cortical} {Songs}: {Temporal} {Modules} of {Cortical} {Activity}},
	url = {http://www.science.org/doi/10.1126/science.1093173},
	urldate = {2021-11-29},
	volume = {304},
	year = {2004},
	bdsk-url-1 = {http://www.science.org/doi/10.1126/science.1093173},
	bdsk-url-2 = {https://doi.org/10.1126/science.1093173}}

@article{hanuschkin_general_2010,
<<<<<<< HEAD
	title = {A General and Efficient Method for Incorporating Precise Spike Times in Globally Time-Driven Simulations},
	volume = {4},
	issn = {1662-5196},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965048/},
	doi = {10.3389/fninf.2010.00113},
=======
>>>>>>> 54fa16285d42085d7998858503f94f2677494c06
	abstract = {Traditionally, event-driven simulations have been limited to the very restricted class of neuronal models for which the timing of future spikes can be expressed in closed form. Recently, the class of models that is amenable to event-driven simulation has been extended by the development of techniques to accurately calculate firing times for some integrate-and-fire neuron models that do not enable the prediction of future spikes in closed form. The motivation of this development is the general perception that time-driven simulations are imprecise. Here, we demonstrate that a globally time-driven scheme can calculate firing times that cannot be discriminated from those calculated by an event-driven implementation of the same model; moreover, the time-driven scheme incurs lower computational costs. The key insight is that time-driven methods are based on identifying a threshold crossing in the recent past, which can be implemented by a much simpler algorithm than the techniques for predicting future threshold crossings that are necessary for event-driven approaches. As run time is dominated by the cost of the operations performed at each incoming spike, which includes spike prediction in the case of event-driven simulation and retrospective detection in the case of time-driven simulation, the simple time-driven algorithm outperforms the event-driven approaches. Additionally, our method is generally applicable to all commonly used integrate-and-fire neuronal models; we show that a non-linear model employing a standard adaptive solver can reproduce a reference spike train with a high degree of precision.},
	author = {Hanuschkin, Alexander and Kunkel, Susanne and Helias, Moritz and Morrison, Abigail and Diesmann, Markus},
	doi = {10.3389/fninf.2010.00113},
	issn = {1662-5196},
	journal = {Frontiers in Neuroinformatics},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = oct,
	pages = {113},
	title = {A {General} and {Efficient} {Method} for {Incorporating} {Precise} {Spike} {Times} in {Globally} {Time}-{Driven} {Simulations}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965048/},
	urldate = {2022-09-14},
	volume = {4},
	year = {2010},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965048/},
	bdsk-url-2 = {https://doi.org/10.3389/fninf.2010.00113}}

@article{dandekar_neural_2012,
	abstract = {Studying neural activity during natural viewing conditions is not often attempted. Isolating the neural response of a single saccade is necessary to study neural activity during natural viewing; however, the close temporal spacing of saccades that occurs during natural viewing makes it difficult to determine the response to a single saccade. Herein, a general linear model (GLM) approach is applied to estimate the EEG neural saccadic response for different segments of the saccadic main sequence separately. It is determined that, in visual search conditions, neural responses estimated by conventional event-related averaging are significantly and systematically distorted relative to GLM estimates due to the close temporal spacing of saccades during visual search. Before the GLM is applied, analyses are applied that demonstrate that saccades during visual search with intersaccadic spacings as low as 100--150 ms do not exhibit significant refractory effects. Therefore, saccades displaying different intersaccadic spacings during visual search can be modeled using the same regressor in a GLM. With the use of the GLM approach, neural responses were separately estimated for five different ranges of saccade amplitudes during visual search. Occipital responses time locked to the onsets of saccades during visual search were found to account for, on average, 79 percent of the variance of EEG activity in a window 90--200 ms after the onsets of saccades for all five saccade amplitude ranges that spanned a range of 0.2--6.0 degrees. A GLM approach was also used to examine the lateralized ocular artifacts associated with saccades. Possible extensions of the methods presented here to account for the superposition of microsaccades in event-related EEG studies conducted in nominal fixation conditions are discussed.},
	author = {Dandekar, Sangita and Privitera, Claudio and Carney, Thom and Klein, Stanley A.},
	doi = {10.1152/jn.00237.2011},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = mar,
	number = {6},
	pages = {1776--1790},
	title = {Neural saccadic response estimation during natural viewing},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3311669/},
	urldate = {2022-09-14},
	volume = {107},
	year = {2012},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3311669/},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00237.2011}}

@article{roelfsema_early_2016,
	author = {Roelfsema, Pieter R and de Lange, Floris P},
	doi = {10.1146/annurev-vision-111815-114443},
	journal = {Annual review of vision science},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	note = {Publisher: Annual Reviews},
	pages = {131--151},
	title = {Early visual cortex as a multiscale cognitive blackboard},
	volume = {2},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1146/annurev-vision-111815-114443}}

@article{Pasturel2020,
	abstract = {Humans are able to accurately track a moving object with a combination of saccades and smooth eye movements. These movements allow us to align and stabilize the object on the fovea, thus enabling high*resolution visual analysis. When predictive information is available about target motion, anticipatory smooth pursuit eye movements (aSPEM) are efficiently generated before target appearance, which reduce the typical sensorimotor delay between target motion onset and foveation. It is generally assumed that the role of anticipatory eye movements is to limit the behavioral impairment due to eye*to*target position and velocity mismatch. By manipulating the probability for target motion direction we were able to bias the direction and mean velocity of aSPEM, as measured during a fixed duration gap before target ramp*motion onset. This suggests that probabilistic information may be used to inform the internal representation of motion prediction for the initiation of anticipatory movements. However, such estimate may become particularly challenging in a dynamic context, where the probabilistic contingencies vary in time in an unpredictable way. In addition, whether and how the information processing underlying the buildup of aSPEM is linked to an explicit estimate of probabilities is unknown. We developed a new paired* task paradigm in order to address these two questions. In a first session, participants observe a target moving horizontally with constant speed from the center either to the right or left across trials. The probability of either motion direction changes randomly in time. Participants are asked to estimate "how much they are confident that the target will move to the right or left in the next trial" and to adjust the cursor's position on the screen accordingly. In a second session the participants eye movements are recorded during the observation of the same sequence of random*direction trials. In parallel, we are developing new automatic routines for the advanced analysis of oculomotor traces. In order to extract the relevant parameters of the oculomotor responses (latency, gain, initial acceleration, catch*up saccades), we developed new tools based on best*fitting procedure of predefined patterns (i.e. the typical smooth pursuit velocity profile).},
	author = {Pasturel, Chlo{\'e} and Montagnini, Anna and Perrinet, Laurent U},
	copyright = {All rights reserved},
	doi = {10.1371/journal.pcbi.1007438},
	journal = {PLoS Computational Biology},
	month = jan,
	title = {Humans adapt their anticipatory eye movements to the volatility of visual motion properties},
	url = {https://doi.org/10.1371/journal.pcbi.1007438},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pcbi.1007438}}

@article{Benvenuti2020,
	abstract = {What are the neural mechanisms underlying motion integration of translating objects? Visual motion integration is generally conceived of as a feedforward, hierarchical, information processing. However, feedforward models fail to account for many contextual effects revealed using natural moving stimuli. In particular, a translating object evokes a sequence of transient feedforward responses in the primary visual cortex but also propagations of activity through horizontal and feedback pathways. We investigated how these pathways shape the representation of a translating bar in monkey V1. We show that, for long trajectories, spiking activity builds-up hundreds of milliseconds before the bar enters the neurons receptive fields. Using VSDI and LFP recordings guided by a phenomenological model of propagation dynamics, we demonstrate that this anticipatory response arises from the interplay between horizontal and feedback networks driving V1 neurons well ahead of their feedforward inputs. This mechanism could subtend several perceptual contextual effects observed with translating objects.},
	author = {Benvenuti, Giacomo and Chemla, Sandrine and Boonman, Arjan and Perrinet, Laurent U and Masson, Guillaume S and Chavane, Frederic},
	copyright = {All rights reserved},
	doi = {10.1101/2020.03.26.010017},
	journal = {bioRxiv : the preprint server for biology},
	language = {english},
	month = mar,
	title = {Anticipatory responses along motion trajectories in awake monkey area {V1}},
	url = {https://www.biorxiv.org/content/10.1101/2020.03.26.010017v1},
	urldate = {2020-03-31},
	year = {2020},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/2020.03.26.010017v1},
	bdsk-url-2 = {https://doi.org/10.1101/2020.03.26.010017}}

@article{vanHateren1998,
	abstract = {Properties of the receptive fields of simple cells in macaque cortex were compared with properties of independent component filters generated by independent component analysis (ICA) on a large set of natural images. Histograms of spatial frequency bandwidth, orientation tuning bandwidth, aspect ratio and length of the receptive fields match well. This indicates that simple cells are well tuned to the expected statistics of natural stimuli. There is no match, however, in calculated and measured distributions for the peak of the spatial frequency response: the filters produced by ICA do not vary their spatial scale as much as simple cells do, but are fixed to scales close to the finest ones allowed by the sampling lattice. Possible ways to resolve this discrepancy are discussed.},
	author = {van Hateren, J H and van der Schaaf, A},
	doi = {10.1098/rspb.1998.0303},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	month = mar,
	number = {1394},
	pages = {359{\^a}€``366},
	title = {Independent component filters of natural images compared with simple cells in primary visual cortex.},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1688904&amp;rendertype=abstract},
	volume = {265},
	year = {1998},
	bdsk-url-1 = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1688904&amp;rendertype=abstract},
	bdsk-url-2 = {https://doi.org/10.1098/rspb.1998.0303}}

@article{perrinet_motion-based_2012,
	abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to physio-logy and behavior. We demonstrate that this solution is the result of two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independent of their texture. Second, we observe that incoherent features are explained away, while coherent information diffuses progressively to the global scale. Most previous models included ad hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features as necessary conditions to solve the aperture problem. Here, we have proved that motion-based predictive coding, as it is implemented in this functional model, is sufficient to solve the aperture problem. This solution may give insights into the role of prediction underlying a large class of sensory computations.},
	author = {Perrinet, Laurent U and Masson, Guillaume S},
	copyright = {All rights reserved},
	doi = {10.1162/neco_a_00332},
	issn = {0899-7667},
	journal = {Neural Computation},
	keywords = {\#nosource, Bayesian model, aperture, aperture problem, aperture-problem, association field, coding, emergence, khoei12jpp, khoei13jpp, motion detection, motion prediction, perrinet12pred, predictive, predictive coding, predictive-coding, probabilistic, probabilistic representation, problem, representation, thesis, toupate-inpress, ⛔ No INSPIRE recid found},
	month = aug,
	number = {10},
	pages = {2726--2750},
	title = {Motion-Based Prediction Is Sufficient to Solve the Aperture Problem},
	volume = {24},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1162/neco_a_00332}}

@article{luo_supervised_2022,
	abstract = {The brain-inspired spiking neural networks (SNNs) hold the advantages of lower power consumption and powerful computing capability. However, the lack of effective learning algorithms has obstructed the theoretical advance and applications of SNNs. The majority of the existing learning algorithms for SNNs are based on the synaptic weight adjustment. However, neuroscience findings confirm that synaptic delays can also be modulated to play an important role in the learning process. Here, we propose a gradient descent-based learning algorithm for synaptic delays to enhance the sequential learning performance of single spiking neuron. Moreover, we extend the proposed method to multilayer SNNs with spike temporal-based error backpropagation. In the proposed multilayer learning algorithm, information is encoded in the relative timing of individual neuronal spikes, and learning is performed based on the exact derivatives of the postsynaptic spike times with respect to presynaptic spike times. Experimental results on both synthetic and realistic datasets show significant improvements in learning efficiency and accuracy over the existing spike temporal-based learning algorithms. We also evaluate the proposed learning method in an SNN-based multimodal computational model for audiovisual pattern recognition, and it achieves better performance compared with its counterparts.},
	author = {Luo, Xiaoling and Qu, Hong and Wang, Yuchen and Yi, Zhang and Zhang, Jilun and Zhang, Malu},
	doi = {10.1109/TNNLS.2022.3164930},
	issn = {2162-2388},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {\#nosource, Backpropagation, Biological system modeling, Delays, Heuristic algorithms, Membrane potentials, Neurons, Nonhomogeneous media, spike neural networks, spike neurons, supervised learning, synaptic delay plasticity., ⛔ No INSPIRE recid found},
	pages = {1--13},
	title = {Supervised {Learning} in {Multilayer} {Spiking} {Neural} {Networks} {With} {Spike} {Temporal} {Error} {Backpropagation}},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/TNNLS.2022.3164930}}

@article{koenderink_representation_1987,
	abstract = {It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.},
	author = {Koenderink, J. J. and van Doorn, A. J.},
	doi = {10.1007/BF00318371},
	issn = {1432-0770},
	journal = {Biological Cybernetics},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = mar,
	number = {6},
	pages = {367--375},
	title = {Representation of local geometry in the visual system},
	url = {https://doi.org/10.1007/BF00318371},
	urldate = {2022-08-31},
	volume = {55},
	year = {1987},
	bdsk-url-1 = {https://doi.org/10.1007/BF00318371}}

@article{lin_supervised_2021,
	abstract = {As a new brain-inspired computational model of artificial neural networks, spiking neural networks transmit and process information via precisely timed spike trains. Constructing efficient learning methods is a significant research field in spiking neural networks. In this paper, we present a supervised learning algorithm for multilayer feedforward spiking neural networks; all neurons can fire multiple spikes in all layers. The feedforward network consists of spiking neurons governed by biologically plausible long-term memory spike response model, in which the effect of earlier spikes on the refractoriness is not neglected to incorporate adaptation effects. The gradient descent method is employed to derive synaptic weight updating rule for learning spike trains. The proposed algorithm is tested and verified on spatiotemporal pattern learning problems, including a set of spike train learning tasks and nonlinear pattern classification problems on four UCI datasets. Simulation results indicate that the proposed algorithm can improve learning accuracy in comparison with other supervised learning algorithms.},
	author = {Lin, Xianghong and Zhang, Mengwei and Wang, Xiangwen},
	doi = {10.1155/2021/8592824},
	issn = {1687-5265},
	journal = {Computational Intelligence and Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = nov,
	pages = {8592824},
	title = {Supervised {Learning} {Algorithm} for {Multilayer} {Spiking} {Neural} {Networks} with {Long}-{Term} {Memory} {Spike} {Response} {Model}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8635912/},
	urldate = {2022-09-14},
	volume = {2021},
	year = {2021},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8635912/},
	bdsk-url-2 = {https://doi.org/10.1155/2021/8592824}}

@article{wang_delay_2019,
	abstract = {Neuroscience research confirms that the synaptic delays are not constant, but can be modulated. This paper proposes a supervised delay learning algorithm for spiking neurons with temporal encoding, in which both the weight and delay of a synaptic connection can be adjusted to enhance the learning performance. The proposed algorithm firstly defines spike train kernels to transform discrete spike trains during the learning phase into continuous analog signals so that common mathematical operations can be performed on them, and then deduces the supervised learning rules of synaptic weights and delays by gradient descent method. The proposed algorithm is successfully applied to various spike train learning tasks, and the effects of parameters of synaptic delays are analyzed in detail. Experimental results show that the network with dynamic delays achieves higher learning accuracy and less learning epochs than the network with static delays. The delay learning algorithm is further validated on a practical example of an image classification problem. The results again show that it can achieve a good classification performance with a proper receptive field. Therefore, the synaptic delay learning is significant for practical applications and theoretical researches of spiking neural networks.},
	author = {Wang, Xiangwen and Lin, Xianghong and Dang, Xiaochao},
	issn = {1662-453X},
	journal = {Frontiers in Neuroscience},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	title = {A {Delay} {Learning} {Algorithm} {Based} on {Spike} {Train} {Kernels} for {Spiking} {Neurons}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2019.00252},
	urldate = {2022-09-14},
	volume = {13},
	year = {2019},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2019.00252}}

@article{khoei_flash-lag_2017,
	abstract = {Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object's motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects' position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.},
	author = {Khoei, Mina A and Masson, Guillaume S and Perrinet, Laurent U},
	copyright = {Licence Creative Commons Attribution - Pas d'utilisation commerciale - Partage dans les m{\^e}mes conditions 4.0 International (CC-BY-NC-SA)},
	doi = {10.1371/journal.pcbi.1005068},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {\#nosource, Coding mechanisms, Extrapolation, Motion, Psychophysics, Sensory perception, Velocity, Vision, Visual system, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	number = {1},
	pages = {e1005068},
	title = {The {Flash}-{Lag} {Effect} as a {Motion}-{Based} {Predictive} {Shift}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068},
	urldate = {2022-08-31},
	volume = {13},
	year = {2017},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1005068}}

@article{perrinet_active_2014,
	abstract = {This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalised coordinates of motion. Representing hidden states in generalised coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the generative model to simulate smooth pursuit eye movements in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system, like the oculomotor system, tries to control its environment with delayed signals.},
	author = {Perrinet, Laurent U and Adams, Rick A and Friston, Karl J},
	copyright = {All rights reserved},
	doi = {10.1007/s00422-014-0620-8},
	issn = {1432-0770},
	journal = {Biological Cybernetics},
	keywords = {\#nosource, Active inference, Bayesian model, Biologically Inspired Computer vision, Generalised coordinates, Oculomotor delays, Smooth pursuit eye movements, Tracking eye movements, Variational free energy, active inference, active-inference, bayesian, bicv-motion, bicv-sparse, delays, eye, eye movements, eye-movements, free energy, free-energy, generalized-coordinates, generalized-filtering, motion detection, oculomotor, perception, perrinetadamsfriston14, smooth-pursuit, tracking-eye-movements, variational-filtering, ⛔ No INSPIRE recid found},
	month = dec,
	number = {6},
	pages = {777--801},
	title = {Active inference, eye movements and oculomotor delays},
	url = {https://doi.org/10.1007/s00422-014-0620-8},
	volume = {108},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1007/s00422-014-0620-8}}

@article{hogendoorn_predictive_2019,
	author = {Hogendoorn, Hinze and Burkitt, Anthony N},
	doi = {10.1523/eneuro.0412-18.2019},
	issn = {2373-2822},
	journal = {eNeuro},
	language = {en},
	month = mar,
	number = {2},
	pages = {ENEURO.0412--18.2019},
	shorttitle = {Predictive {Coding} with {Neural} {Transmission} {Delays}},
	title = {Predictive {Coding} with {Neural} {Transmission} {Delays}: {A} {Real}-{Time} {Temporal} {Alignment} {Hypothesis}},
	url = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0412-18.2019},
	urldate = {2019-11-12},
	volume = {6},
	year = {2019},
	bdsk-url-1 = {http://eneuro.org/lookup/doi/10.1523/ENEURO.0412-18.2019},
	bdsk-url-2 = {https://doi.org/10.1523/eneuro.0412-18.2019}}

@article{boutin_pooling_2022,
	abstract = {Neurons in the primary visual cortex are selective to orientation with various degrees of selectivity to the spatial phase, from high selectivity in simple cells to low selectivity in complex cells. Various computational models have suggested a possible link between the presence of phase invariant cells and the existence of orientation maps in higher mammals' V1. These models, however, do not explain the emergence of complex cells in animals that do not show orientation maps. In this study, we build a theoretical model based on a convolutional network called Sparse Deep Predictive Coding (SDPC) and show that a single computational mechanism, pooling, allows the SDPC model to account for the emergence in V1 of complex cells with or without that of orientation maps, as observed in distinct species of mammals. In particular, we observed that pooling in the feature space is directly related to the orientation map formation while pooling in the retinotopic space is responsible for the emergence of a complex cells population. Introducing different forms of pooling in a predictive model of early visual processing as implemented in SDPC can therefore be viewed as a theoretical framework that explains the diversity of structural and functional phenomena observed in V1.},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Fr{\'e}d{\'e}ric and Perrinet, Laurent U},
	doi = {10.1371/journal.pcbi.1010270},
	issn = {1553-7358},
	journal = {PLoS Computational Biology},
	keywords = {\#nosource, Coding mechanisms, Convolution, Neural networks, Neuronal tuning, Neurons, Neurophysiology, Visual cortex, Visual system, ⛔ No INSPIRE recid found},
	language = {en},
	number = {7},
	pages = {e1010270},
	title = {Pooling strategies in {V1} can account for the functional and structural diversity across species},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010270},
	urldate = {2022-09-14},
	volume = {18},
	year = {2022},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010270},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1010270}}

@article{boutin_effect_2020,
	abstract = {Hierarchical Sparse Coding (HSC) is a powerful model to efficiently represent multi-dimensional, structured data such as images. The simplest solution to solve this computationally hard problem is to decompose it into independent layer-wise subproblems. However, neuroscientific evidence would suggest inter-connecting these subproblems as in the Predictive Coding (PC) theory, which adds top-down connections between consecutive layers. In this study, a new model called 2-Layers Sparse Predictive Coding (2L-SPC) is introduced to assess the impact of this inter-layer feedback connection. In particular, the 2L-SPC is compared with a Hierarchical Lasso (Hi-La) network made out of a sequence of independent Lasso layers. The 2L-SPC and the 2-layers Hi-La networks are trained on 4 different databases and with different sparsity parameters on each layer. First, we show that the overall prediction error generated by 2L-SPC is lower thanks to the feedback mechanism as it transfers prediction error between layers. Second, we demonstrate that the inference stage of the 2L-SPC is faster to converge than for the Hi-La model. Third, we show that the 2L-SPC also accelerates the learning process. Finally, the qualitative analysis of both models dictionaries, supported by their activation probability, show that the 2L-SPC features are more generic and informative.},
	author = {Boutin, Victor and Franciosini, Angelo and Ruffier, Franck and Perrinet, Laurent U},
	copyright = {All rights reserved},
	doi = {10/fnqm},
	journal = {Neural Computation},
	keywords = {\#nosource, deep-learning, sparse coding, ⛔ No INSPIRE recid found},
	month = feb,
	number = {11},
	pages = {2279--2309},
	title = {Effect of top-down connections in {Hierarchical} {Sparse} {Coding}},
	url = {https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/},
	volume = {32},
	year = {2020},
	bdsk-url-1 = {https://laurentperrinet.github.io/publication/boutin-franciosini-ruffier-perrinet-20-feedback/},
	bdsk-url-2 = {https://doi.org/10/fnqm}}

@article{chavane_revisiting_2022,
	abstract = {Horizontal connections in the primary visual cortex of carnivores, ungulates and primates organize on a near-regular lattice. Given the similar length scale for the regularity found in cortical orientation maps, the currently accepted theoretical standpoint is that these maps are underpinned by a like-to-like connectivity rule: horizontal axons connect preferentially to neurons with similar preferred orientation. However, there is reason to doubt the rule's explanatory power, since a growing number of quantitative studies show that the like-to-like connectivity preference and bias mostly observed at short-range scale, are highly variable on a neuron-to-neuron level and depend on the origin of the presynaptic neuron. Despite the wide availability of published data, the accepted model of visual processing has never been revised. Here, we review three lines of independent evidence supporting a much-needed revision of the like-to-like connectivity rule, ranging from anatomy to population functional measures, computational models and to theoretical approaches. We advocate an alternative, distance-dependent connectivity rule that is consistent with new structural and functional evidence: from like-to-like bias at short horizontal distance to like-to-all at long horizontal distance. This generic rule accounts for the observed high heterogeneity in interactions between the orientation and retinotopic domains, that we argue is necessary to process non-trivial stimuli in a task-dependent manner.},
	author = {Chavane, Fr{\'e}d{\'e}ric and Perrinet, Laurent U and Rankin, James},
	copyright = {All rights reserved},
	doi = {10.1007/s00429-022-02455-4},
	issn = {1863-2661},
	journal = {Brain Structure and Function},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = feb,
	shorttitle = {Revisiting horizontal connectivity rules in {V1}},
	title = {Revisiting horizontal connectivity rules in {V1}: from like-to-like towards like-to-all},
	url = {https://doi.org/10.1007/s00429-022-02455-4},
	urldate = {2022-02-06},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/s00429-022-02455-4}}

@article{boutin_sparse_2020,
	abstract = {Both neurophysiological and psychophysical experiments have pointed out the crucial role of recurrent and feedback connections to process context-dependent information in the early visual cortex. While numerous models have accounted for feedback effects at either neural or representational level, none of them were able to bind those two levels of analysis. Is it possible to describe feedback effects at both levels using the same model? We answer this question by combining Predictive Coding (PC) and Sparse Coding (SC) into a hierarchical and convolutional framework. In this Sparse Deep Predictive Coding (SDPC) model, the SC component models the internal recurrent processing within each layer, and the PC component describes the interactions between layers using feedforward and feedback connections. Here, we train a 2-layered SDPC on two different databases of images, and we interpret it as a model of the early visual system (V1 \& V2). We first demonstrate that once the training has converged, SDPC exhibits oriented and localized receptive fields in V1 and more complex features in V2. Second, we analyze the effects of feedback on the neural organization beyond the classical receptive field of V1 neurons using interaction maps. These maps are similar to association fields and reflect the Gestalt principle of good continuation. We demonstrate that feedback signals reorganize interaction maps and modulate neural activity to promote contour integration. Third, we demonstrate at the representational level that the SDPC feedback connections are able to overcome noise in input images. Therefore, the SDPC captures the association field principle at the neural level which results in better disambiguation of blurred images at the representational level.},
	author = {Boutin, Victor and Franciosini, Angelo and Chavane, Fr{\'e}d{\'e}ric Y and Ruffier, Franck and Perrinet, Laurent U},
	copyright = {All rights reserved},
	doi = {10.1371/journal.pcbi.1008629},
	journal = {PLoS Computational Biology},
	keywords = {\#nosource, deep-learning, sparse coding, ⛔ No INSPIRE recid found},
	month = may,
	title = {Sparse {Deep} {Predictive} {Coding} captures contour integration capabilities of the early visual system},
	url = {https://doi.org/10.1371/journal.pcbi.1008629},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pcbi.1008629}}

@article{perrinet_edge_2015,
	author = {Perrinet, Laurent U and Bednar, James A},
	doi = {10.1038/srep11400},
	journal = {Scientific reports},
	pages = {11400},
	title = {Edge co-occurrences can account for rapid categorization of natural versus animal images},
	volume = {5},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1038/srep11400}}

@article{tatler_eye_2011,
	abstract = {Models of gaze allocation in complex scenes are derived mainly from studies of static picture viewing. The dominant framework to emerge has been image salience, where properties of the stimulus play a crucial role in guiding the eyes. However, salience-based schemes are poor at accounting for many aspects of picture viewing and can fail dramatically in the context of natural task performance. These failures have led to the development of new models of gaze allocation in scene viewing that address a number of these issues. However, models based on the picture-viewing paradigm are unlikely to generalize to a broader range of experimental contexts, because the stimulus context is limited, and the dynamic, task-driven nature of vision is not represented. We argue that there is a need to move away from this class of model and find the principles that govern gaze allocation in a broader range of settings. We outline the major limitations of salience-based selection schemes and highlight what we have learned from studies of gaze allocation in natural vision. Clear principles of selection are found across many instances of natural vision and these are not the principles that might be expected from picture-viewing studies. We discuss the emerging theoretical framework for gaze allocation on the basis of reward maximization and uncertainty reduction.},
	author = {Tatler, Benjamin W and Hayhoe, Mary M and Land, Michael F and Ballard, Dana H},
	doi = {10.1167/11.5.5},
	issn = {1534-7362},
	journal = {Journal of Vision},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = may,
	number = {5},
	pages = {5},
	shorttitle = {Eye guidance in natural vision},
	title = {Eye guidance in natural vision: {Reinterpreting} salience},
	url = {https://doi.org/10.1167/11.5.5},
	urldate = {2022-09-14},
	volume = {11},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1167/11.5.5}}

@incollection{perrinet_sparse_2015,
	address = {Weinheim, Germany},
	author = {Perrinet, Laurent U},
	booktitle = {Biologically {Inspired} {Computer} {Vision}},
	editor = {Keil, Matthias and Crist{\'o}bal, Gabriel and Perrinet, Laurent U},
	keywords = {\#nosource, Biologically Inspired Computer vision, anr-trax, bicv-sparse, sanz12jnp, sparse coding, vacher14, ⛔ No INSPIRE recid found},
	month = aug,
	pages = {319--346},
	publisher = {Wiley-VCH Verlag GmbH \& Co. KGaA},
	title = {Sparse {Models} for {Computer} {Vision}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9783527680863.ch14/summary},
	year = {2015},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/9783527680863.ch14/summary}}

@article{olshausen_emergence_1996,
	abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
	author = {Olshausen, Bruno A and Field, David J},
	doi = {10.1038/381607a0},
	issn = {0028-0836},
	journal = {Nature},
	keywords = {\#nosource, Algorithms, Learning, Models, Neurological, Neurons, Neurons: physiology, Ocular, Ocular: physiology, Vision, Visual Cortex, Visual Cortex: cytology, Visual Cortex: physiology, anr-trax, bicv-sparse, perrinetadamsfriston14, sparse\_coding, sparse\_hebbian\_learning, sparse\_spike\_coding, ⛔ No INSPIRE recid found},
	number = {6583},
	pages = {607--609},
	title = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images.},
	volume = {381},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1038/381607a0}}

@article{poletti_head-eye_2015,
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Humans explore static visual scenes by alternating rapid eye movements (saccades) with periods of slow and incessant eye drifts [1--3]. These drifts are commonly believed to be the consequence of physiological limits in maintaining steady gaze, resulting in Brownian-like trajectories [4--7], which are almost independent in the two eyes [8--10]. However, because of the technical difficulty of recording minute eye movements, most knowledge on ocular drift comes from artificial laboratory conditions, in which the head of the observer is strictly immobilized. Little is known about eye drift during natural head-free fixation, when microscopic head movements are also continually present [11--13]. We have recently observed that the power spectrum of the visual input to the retina during ocular drift is largely unaffected by fixational head movements [14]. Here we elucidate the mechanism responsible for this invariance. We show that, contrary to common assumption, ocular drift does not move the eyes randomly, but compensates for microscopic head movements, thereby yielding highly correlated movements in the two eyes. This compensatory behavior is extremely fast, persists with one eye patched, and results in image motion trajectories that are only partially correlated on the two retinas. These findings challenge established views of how humans acquire visual information. They show that ocular drift is precisely controlled, as long speculated [15], and imply the existence of neural mechanisms that integrate minute multimodal signals.{\textless}/p{\textgreater}},
	author = {Poletti, Martina and Aytekin, Murat and Rucci, Michele},
	doi = {10.1016/j.cub.2015.11.004},
	issn = {0960-9822},
	journal = {Current Biology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {English},
	month = dec,
	number = {24},
	pages = {3253--3259},
	title = {Head-{Eye} {Coordination} at a {Microscopic} {Scale}},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(15)01365-2},
	urldate = {2022-09-13},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {https://www.cell.com/current-biology/abstract/S0960-9822(15)01365-2},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.11.004}}

@article{van_der_stigchel_eye_2006,
	abstract = {In the last two decades, research has shown that eye movement trajectories can be modified by situational determinants. These modifications can inform us about the mechanisms that control eye movements and they can yield information about the oculomotor, memory and attention system that is not easily obtained via other sources. Eye movement trajectories can deviate either towards or away from elements in the visual field. We review the conditions in which these deviations are found and the mechanisms underlying trajectory deviations. It is argued that deviations towards an element are caused by the unresolved competition in the oculomotor system between elements in a visual scene. Deviations away from an element are mainly observed in situations in which top-down preparation can influence the target selection process, but the exact cause of such deviations remains unclear.},
	author = {Van der Stigchel, Stefan and Meeter, Martijn and Theeuwes, Jan},
	doi = {10.1016/j.neubiorev.2005.12.001},
	issn = {0149-7634},
	journal = {Neuroscience \& Biobehavioral Reviews},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = jan,
	number = {5},
	pages = {666--679},
	title = {Eye movement trajectories and what they tell us},
	url = {https://www.sciencedirect.com/science/article/pii/S0149763405001740},
	urldate = {2022-09-13},
	volume = {30},
	year = {2006},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0149763405001740},
	bdsk-url-2 = {https://doi.org/10.1016/j.neubiorev.2005.12.001}}

@article{riehle_spike_1997,
	author = {Riehle, Alexa and Grun, Sonja and Diesmann, Markus and Aertsen, Ad},
	doi = {10.1126/science.278.5345.1950},
	journal = {Science (New York, N.Y.)},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	note = {Publisher: American Association for the Advancement of Science},
	number = {5345},
	pages = {1950--1953},
	title = {Spike synchronization and rate modulation differentially involved in motor cortical function},
	volume = {278},
	year = {1997},
	bdsk-url-1 = {https://doi.org/10.1126/science.278.5345.1950}}

@article{rasetto_challenges_2022,
	abstract = {Neuromorphic engineering has led to the necessary process of rethinking of how we process and integrate information, analyze data, and use the resulting insights to improve computation and avoid the current high power and latency of Artificial Intelligence (AI) hardware. Current neuromorphic processors are, however, limited by digital technologies, which cannot reproduce the abilities of biological neural computation in terms of power, latency and area cost. In this paper, we show that the combined use of the dynamic properties of memristors to implement a model of synaptic integration and the determination of the correct level of abstraction of biological neural networks has the potential to open a new range of capabilities for neuromorphic processors. We test this approach using a novel three-terminal LixWO3 electrochemical memristor, by deriving its conductance model and using it to emulate synaptic temporal kernel computation in the context of a pattern recognition task. We show that these devices allow for robust results with no loss in precision while opening the path for an energy efficient approach to build novel bio-inspired processing units in silicon.},
	author = {Rasetto, Marco and Wan, Qingzhou and Akolkar, Himanshu and Shi, Bertram and Xiong, Feng and Benosman, Ryad},
	journal = {arXiv:2201.12673 [cs]},
	keywords = {\#nosource, Computer Science - Emerging Technologies, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	language = {english},
	month = jan,
	note = {arXiv: 2201.12673 [cs]},
	shorttitle = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}},
	title = {The {Challenges} {Ahead} for {Bio}-inspired {Neuromorphic} {Event} {Processors}: {How} {Memristors} {Dynamic} {Properties} {Could} {Revolutionize} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2201.12673},
	urldate = {2022-02-02},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2201.12673}}

@article{zhang_supervised_2020,
	author = {Zhang, Malu and Wu, Jibin and Belatreche, Ammar and Pan, Zihan and Xie, Xiurui and Chua, Yansong and Li, Guoqi and Qu, Hong and Li, Haizhou},
	doi = {10.1016/j.neucom.2020.03.079},
	journal = {Neurocomputing},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	note = {Publisher: Elsevier},
	pages = {103--118},
	title = {Supervised learning in spiking neural networks with synaptic delay-weight plasticity},
	volume = {409},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1016/j.neucom.2020.03.079}}

@article{perrinet_coding_2004,
	author = {Perrinet, Laurent and Samuelides, Manuel and Thorpe, Simon},
	doi = {10.1109/TNN.2004.833303},
	journal = {IEEE Transactions on neural networks},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	note = {Publisher: IEEE},
	number = {5},
	pages = {1164--1175},
	title = {Coding static natural images using spiking event times: do neurons cooperate?},
	volume = {15},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1109/TNN.2004.833303}}

@article{nessler_bayesian_2013-1,
	author = {Nessler, Bernhard and Pfeiffer, Michael and Buesing, Lars and Maass, Wolfgang},
	doi = {10.1371/journal.pcbi.1003037},
	journal = {PLoS computational biology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {4},
	pages = {e1003037},
	title = {Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity},
	volume = {9},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pcbi.1003037}}

@article{leon_motion_2012,
	author = {Leon, Paula Sanz and Vanzetta, Ivo and Masson, Guillaume S and Perrinet, Laurent U},
	doi = {10.1152/jn.00737.2011},
	journal = {Journal of Neurophysiology},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {11},
	pages = {3217--3226},
	title = {Motion {Clouds}: {Model}-based stimulus synthesis of natural-like random textures for the study of motion perception},
	volume = {107},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1152/jn.00737.2011}}

@article{lagorce_hots_2017,
	abstract = {This paper describes novel event-based spatiotemporal features called time-surfaces and how they can be used to create a hierarchical event-based pattern recognition architecture. Unlike existing hierarchical architectures for pattern recognition, the presented model relies on a time oriented approach to extract spatio-temporal features from the asynchronously acquired dynamics of a visual scene. These dynamics are acquired using biologically inspired frameless asynchronous event-driven vision sensors. Similarly to cortical structures, subsequent layers in our hierarchy extract increasingly abstract features using increasingly large spatio-temporal windows. The central concept is to use the rich temporal information provided by events to create contexts in the form of time-surfaces which represent the recent temporal activity within a local spatial neighborhood. We demonstrate that this concept can robustly be used at all stages of an event-based hierarchical model. First layer feature units operate on groups of pixels, while subsequent layer feature units operate on the output of lower level feature units. We report results on a previously published 36 class character recognition task and a 4 class canonical dynamic card pip task, achieving near 100\% accuracy on each. We introduce a new 7 class moving face recognition task, achieving 79\% accuracy.},
	author = {Lagorce, Xavier and Orchard, Garrick and Galluppi, Francesco and Shi, Bertram E. and Benosman, Ryad B},
	doi = {10.1109/TPAMI.2016.2574707},
	issn = {0162-8828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {\#nosource, Neuromorphic sensing, event-based vision, feature extraction, ⛔ No INSPIRE recid found},
	number = {7},
	pages = {1346--1359},
	title = {{HOTS}: {A} {Hierarchy} of {Event}-{Based} {Time}-{Surfaces} for {Pattern} {Recognition}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	volume = {39},
	year = {2017},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pubmed/27411216%20http://ieeexplore.ieee.org/document/7508476/},
	bdsk-url-2 = {https://doi.org/10.1109/TPAMI.2016.2574707}}

@article{guise_bayesian_2014,
	author = {Guise, Mira and Knott, Alistair and Benuskova, Lubica},
	doi = {10/f6chbq},
	journal = {Neural Computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {9},
	pages = {2052--2073},
	title = {A {Bayesian} model of polychronicity},
	volume = {26},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10/f6chbq}}

@article{deweese_binary_2002,
	author = {DeWeese, Michael and Zador, Anthony},
	journal = {Advances in neural information processing systems},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	title = {Binary coding in auditory cortex},
	volume = {15},
	year = {2002}}

@article{davis_spontaneous_2021,
	author = {Davis, Zachary W and Benigno, Gabriel B and Fletterman, Charlee and Desbordes, Theo and Steward, Christopher and Sejnowski, Terrence J and H Reynolds, John and Muller, Lyle},
	doi = {10.1038/s41467-021-26175-1},
	journal = {Nature Communications},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {1},
	pages = {1--16},
	title = {Spontaneous traveling waves naturally emerge from horizontal fiber time delays and travel through locally asynchronous-irregular states},
	volume = {12},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1038/s41467-021-26175-1}}

@article{gutig_tempotron_2006,
	abstract = {The timing of action potentials in sensory neurons contains substantial information about the eliciting stimuli. Although the computational advantages of spike timing--based neuronal codes have long been recognized, it is unclear whether, and if so how, neurons can learn to read out such representations. We propose a new, biologically plausible supervised synaptic learning rule that enables neurons to efficiently learn a broad range of decision rules, even when information is embedded in the spatiotemporal structure of spike patterns rather than in mean firing rates. The number of categorizations of random spatiotemporal patterns that a neuron can implement is several times larger than the number of its synapses. The underlying nonlinear temporal computation allows neurons to access information beyond single-neuron statistics and to discriminate between inputs on the basis of multineuronal spike statistics. Our work demonstrates the high capacity of neural systems to learn to decode information embedded in distributed patterns of spike synchrony.},
	author = {G{\"u}tig, Robert and Sompolinsky, Haim},
	doi = {10.1038/nn1643},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {english},
	month = mar,
	number = {3},
	pages = {420--428},
	shorttitle = {The tempotron},
	title = {The tempotron: {A} neuron that learns spike {Timing}--{Based} decisions},
	url = {http://www.nature.com/articles/nn1643/},
	urldate = {2022-01-31},
	volume = {9},
	year = {2006},
	bdsk-url-1 = {http://www.nature.com/articles/nn1643/},
	bdsk-url-2 = {https://doi.org/10.1038/nn1643}}

@article{gollisch_rapid_2008,
	author = {Gollisch, Tim and Meister, Markus},
	doi = {10.1126/science.1149639},
	journal = {Science (New York, N.Y.)},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {5866},
	pages = {1108--1111},
	title = {Rapid neural coding in the retina with relative spike latencies},
	volume = {319},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1126/science.1149639}}

@article{benosman_asynchronous_2012,
	abstract = {This paper introduces a process to compute optical flow using an asynchronous event-based retina at high speed and low computational load. A new generation of artificial vision sensors has now started to rely on biologically inspired designs for light acquisition. Biological retinas, and their artificial counterparts, are totally asynchronous and data driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework for processing visual data using asynchronous event-based acquisition, providing a method for the evaluation of optical flow. The paper shows that current limitations of optical flow computation can be overcome by using event-based visual acquisition, where high data sparseness and high temporal resolution permit the computation of optical flow with micro-second accuracy and at very low computational cost.},
	author = {Benosman, Ryad},
	doi = {10.1016/j.neunet.2011.11.001},
	journal = {Neural Networks},
	keywords = {\#nosource, Asynchronous acquisition, Event-based vision, Frameless vision, Optical flow, Spikes, Temporal dynamics, ⛔ No INSPIRE recid found},
	language = {english},
	pages = {6},
	title = {Asynchronous frameless event-based optical flow},
	url = {https://doi.org/10/b55t75},
	volume = {27},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10/b55t75},
	bdsk-url-2 = {https://doi.org/10.1016/j.neunet.2011.11.001}}

@article{carr_circuit_1990,
	author = {Carr, CE and Konishi, M},
	doi = {10.1523/JNEUROSCI.10-10-03227.1990},
	journal = {Journal of Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {10},
	pages = {3227--3246},
	title = {A circuit for detection of interaural time differences in the brain stem of the barn owl},
	volume = {10},
	year = {1990},
	bdsk-url-1 = {https://doi.org/10.1523/JNEUROSCI.10-10-03227.1990}}

@article{bohte_evidence_2004,
	author = {Bohte, Sander M},
	doi = {10.1023/B:NACO.0000027755.02868.60},
	journal = {Natural Computing},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {2},
	pages = {195--206},
	title = {The evidence for neural information processing with precise spike-times: {A} survey},
	volume = {3},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1023/B:NACO.0000027755.02868.60}}

@article{abeles_role_1982,
	author = {Abeles, Moshe},
	journal = {Israel journal of medical sciences},
	keywords = {\#nosource, ⛔ No DOI found, ⛔ No INSPIRE recid found},
	number = {1},
	pages = {83--92},
	title = {Role of the cortical neuron: integrator or coincidence detector?},
	volume = {18},
	year = {1982}}

@article{lecun_gradient-based_1998,
	author = {Lecun, Y and Bottou, L and Bengio, Y and Haffner, P},
	doi = {10.1109/5.726791},
	issn = {00189219},
	journal = {Proceedings of the IEEE},
	keywords = {⛔ No INSPIRE recid found},
	month = nov,
	note = {tex.bdsk-url-2: https://doi.org/10.1109/5.726791 tex.date-added: 2022-05-05 19:08:15 +0200 tex.date-modified: 2022-05-05 19:08:15 +0200},
	number = {11},
	pages = {2278--2324},
	title = {Gradient-based learning applied to document recognition},
	url = {http://ieeexplore.ieee.org/document/726791/},
	urldate = {2021-05-18},
	volume = {86},
	year = {1998},
	bdsk-url-1 = {http://ieeexplore.ieee.org/document/726791/},
	bdsk-url-2 = {https://doi.org/10.1109/5.726791}}

@inproceedings{howard_searching_2019,
	author = {Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and Le, Quoc V. and Adam, Hartwig},
	booktitle = {Proceedings of the {IEEE}/{CVF} international conference on computer vision ({ICCV})},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, ⛔ No INSPIRE recid found},
	month = oct,
	title = {Searching for {MobileNetV3}},
	year = {2019}}

@misc{yu_stsc-snn_2022,
	abstract = {Spiking Neural Networks (SNNs), as one of the algorithmic models in neuromorphic computing, have gained a great deal of research attention owing to temporal information processing capability, low power consumption, and high biological plausibility. The potential to efficiently extract spatio-temporal features makes it suitable for processing the event streams. However, existing synaptic structures in SNNs are almost full-connections or spatial 2D convolution, neither of which can extract temporal dependencies adequately. In this work, we take inspiration from biological synapses and propose a spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the spatio-temporal receptive fields of synaptic connections, thereby establishing temporal dependencies across layers. Concretely, we incorporate temporal convolution and attention mechanisms to implement synaptic filtering and gating functions. We show that endowing synaptic models with temporal dependencies can improve the performance of SNNs on classification tasks. In addition, we investigate the impact of performance vias varied spatial-temporal receptive fields and reevaluate the temporal modules in SNNs. Our approach is tested on neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST, CIFAR10-DVS (image classification), and SHD (speech digit recognition). The results show that the proposed model outperforms the state-of-the-art accuracy on nearly all datasets.},
	author = {Yu, Chengting and Gu, Zheming and Li, Da and Wang, Gaoang and Wang, Aili and Li, Erping},
	keywords = {Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning, ⛔ No INSPIRE recid found},
	month = oct,
	note = {arXiv:2210.05241 [cs, q-bio, stat]},
	publisher = {arXiv},
	shorttitle = {{STSC}-{SNN}},
	title = {{STSC}-{SNN}: {Spatio}-{Temporal} {Synaptic} {Connection} with {Temporal} {Convolution} and {Attention} for {Spiking} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2210.05241},
	urldate = {2022-10-25},
	year = {2022},
	bdsk-url-1 = {http://arxiv.org/abs/2210.05241}}

@article{vinje_sparse_2000,
	abstract = {Theoretical studies suggest that primary visual cortex (area V1) uses a sparse code to efficiently represent natural scenes. This issue was investigated by recording from V1 neurons in awake behaving macaques during both free viewing of natural scenes and conditions simulating natural vision. Stimulation of the nonclassical receptive field increases the selectivity and sparseness of individual V1 neurons, increases the sparseness of the population response distribution, and strongly decorrelates the responses of neuron pairs. These effects are due to both excitatory and suppressive modulation of the classical receptive field by the nonclassical receptive field and do not depend critically on the spatiotemporal structure of the stimuli. During natural vision, the classical and nonclassical receptive fields function together to form a sparse representation of the visual world. This sparse code may be computationally efficient for both early vision and higher visual processing.},
	author = {Vinje, William E and Gallant, Jack L},
	doi = {10.1126/science.287.5456.1273},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	keywords = {\#nosource, bicv-sparse, motion-clouds, motion\_clouds, natural-scenes, natural\_scenes, sanz12jnp, vacher14, ⛔ No INSPIRE recid found},
	language = {en},
	month = feb,
	note = {tex.ids= Vinje2000},
	number = {5456},
	pages = {1273--1276},
	pmid = {10678835},
	title = {Sparse {Coding} and {Decorrelation} in {Primary} {Visual} {Cortex} {During} {Natural} {Vision}},
	url = {https://www.science.org/doi/10.1126/science.287.5456.1273},
	urldate = {2022-10-03},
	volume = {287},
	year = {2000},
	bdsk-url-1 = {https://www.science.org/doi/10.1126/science.287.5456.1273},
	bdsk-url-2 = {https://doi.org/10.1126/science.287.5456.1273}}

@incollection{paugam-moisy_computing_2012,
	author = {Paugam-Moisy, H{\'e}l{\`e}ne and Bohte, Sander M},
	booktitle = {Handbook of natural computing},
	keywords = {⛔ No INSPIRE recid found},
	month = sep,
	publisher = {Springer-Verlag},
	title = {Computing with spiking neuron networks},
	year = {2012}}

@article{izhikevich_polychronization_2006,
	author = {Izhikevich, Eugene M},
	doi = {10.1162/089976606775093882},
	journal = {Neural computation},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	number = {2},
	pages = {245--282},
	title = {Polychronization: computation with spikes},
	volume = {18},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1162/089976606775093882}}

@article{Levy2021,
	author = {Levy, William B and Calvert, Victoria G.},
	doi = {10.1073/pnas.2008173118},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = may,
	number = {18},
	pages = {e2008173118},
	title = {Communication consumes 35 times more energy than computation in the human cortex, but both costs are needed to predict synapse number},
	url = {https://pnas.org/doi/full/10.1073/pnas.2008173118},
	urldate = {2023-06-27},
	volume = {118},
	year = {2021},
	bdsk-url-1 = {https://pnas.org/doi/full/10.1073/pnas.2008173118},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.2008173118}}

@article{Perrinet2007,
	abstract = {The machinery behind the visual perception of motion and the subsequent sensori-motor transformation, such as in ocular following response (OFR), is confronted to uncertainties which are efficiently resolved in the primate's visual system. We may understand this response as an ideal observer in a probabilistic framework by using Bayesian theory [Weiss, Y., Simoncelli, E.P., Adelson, E.H., 2002. Motion illusions as optimal percepts. Nature Neuroscience, 5(6), 598-604, doi:10.1038/nn858] which we previously proved to be successfully adapted to model the OFR for different levels of noise with full field gratings. More recent experiments of OFR have used disk gratings and bipartite stimuli which are optimized to study the dynamics of center-surround integration. We quantified two main characteristics of the spatial integration of motion: (i) a finite optimal stimulus size for driving OFR, surrounded by an antagonistic modulation and (ii) a direction selective suppressive effect of the surround on the contrast gain control of the central stimuli [Barth{\'e}lemy, F.V., Vanzetta, I., Masson, G.S., 2006. Behavioral receptive field for ocular following in humans: dynamics of spatial summation and center-surround interactions. Journal of Neurophysiology, (95), 3712-3726, doi:10.1152/jn.00112.2006]. Herein, we extended the ideal observer model to simulate the spatial integration of the different local motion cues within a probabilistic representation. We present analytical results which show that the hypothesis of independence of local measures can describe the spatial integration of the motion signal. Within this framework, we successfully accounted for the contrast gain control mechanisms observed in the behavioral data for center-surround stimuli. However, another inhibitory mechanism had to be added to account for suppressive effects of the surround.},
	author = {Perrinet, Laurent U and Masson, Guillaume S},
	copyright = {All rights reserved},
	doi = {10/bnqsnb},
	issn = {0928-4257},
	journal = {Journal of physiology, Paris},
	number = {1-3},
	title = {Modeling spatial integration in the ocular following response using a probabilistic framework},
	url = {http://dx.doi.org/10.1016/j.jphysparis.2007.10.011 http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6VMC-4R0CK36-3&_user=1069146&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000051262&_version=1&_urlVersion=0&_userid=1069146&md5=5f29c7b7a6bd6},
	volume = {101},
	year = {2007},
	bdsk-url-1 = {http://dx.doi.org/10.1016/j.jphysparis.2007.10.011%20http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6VMC-4R0CK36-3&_user=1069146&_rdoc=1&_fmt=&_orig=search&_sort=d&view=c&_acct=C000051262&_version=1&_urlVersion=0&_userid=1069146&md5=5f29c7b7a6bd6},
	bdsk-url-2 = {http://dx.doi.org/10/bnqsnb}}

@article{Perrinet2002,
	abstract = {It is generally assumed that neurons in the central nervous system communicate through temporal firing patterns. As a first step, we will study the learning of a layer of realistic neurons in the particular case where the relevant messages are formed by temporally cor- related patterns, or synfire patterns. The model is a layer of Integrate-and-Fire (IF) neurons with synaptic current dynamics that adapts by minimizing a cost according to a gradient descent scheme. This leads to a rule similar to Spike-Time Dependent Hebbian Plasticity (STDHP). Our results show that the rule that we derive is biologically plausible and leads to the detection of the coherence in the input in an unsupervised way. An application to shape recognition is shown as an illustration.},
	author = {Perrinet, Laurent U},
	copyright = {All rights reserved},
	doi = {10/fsk9mk},
	issn = {09252312},
	journal = {Neurocomputing},
	number = {C},
	title = {Coherence detection in a spiking neuron via {Hebbian} learning},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231202003740 http://linkinghub.elsevier.com/retrieve/pii/S0925-2312(02)00374-0},
	volume = {44-46},
	year = {2002},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0925231202003740%20http://linkinghub.elsevier.com/retrieve/pii/S0925-2312(02)00374-0},
	bdsk-url-2 = {https://doi.org/10/fsk9mk}}

@article{le_bec_horizontal_2022,
	abstract = {This study demonstrates the functional importance of the Surround context relayed laterally in V1 by the horizontal connectivity, in controlling the latency and the gain of the cortical response to the feedforward visual drive. We report here four main findings: 1) a centripetal apparent motion sequence results in a shortening of the spiking latency of V1 cells, when the orientation of the local inducer and the global motion axis are both co-aligned with the RF orientation preference; 2) this contextual effects grows with visual flow speed, peaking at 150--250$\,^{\circ}$/s when it matches the propagation speed of horizontal connectivity (0.15--0.25 mm/ms); 3) For this speed range, the axial sensitivity of V1 cells is tilted by 90$\,^{\circ}$ to become co-aligned with the orientation preference axis; 4) the strength of modulation by the surround context correlates with the spatiotemporal coherence of the apparent motion flow. Our results suggest an internally-generated binding process, linking local (orientation /position) and global (motion/direction) features as early as V1. This long-range diffusion process constitutes a plausible substrate in V1 of the human psychophysical bias in speed estimation for collinear motion. Since it is demonstrated in the anesthetized cat, this novel form of contextual control of the cortical gain and phase is a built-in property in V1, whose expression does not require behavioral attention and top-down control from higher cortical areas. We propose that horizontal connectivity participates in the propagation of an internal ``prediction'' wave, shaped by visual experience, which links contour co-alignment and global axial motion at an apparent speed in the range of saccade-like eye movements.},
	author = {Le Bec, Benoit and Troncoso, Xoana G. and Desbois, Christophe and Passarelli, Yannick and Baudot, Pierre and Monier, Cyril and Pananceau, Marc and Fr{\'e}gnac, Yves},
	doi = {10.1371/journal.pone.0268351},
	editor = {Charpier, St{\'e}phane},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = jul,
	number = {7},
	pages = {e0268351},
	shorttitle = {Horizontal connectivity in {V1}},
	title = {Horizontal connectivity in {V1}: {Prediction} of coherence in contour and motion integration},
	url = {https://dx.plos.org/10.1371/journal.pone.0268351},
	urldate = {2022-09-26},
	volume = {17},
	year = {2022},
	bdsk-url-1 = {https://dx.plos.org/10.1371/journal.pone.0268351},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0268351}}

@article{berens_fast_2012,
	abstract = {Orientation tuning has been a classic model for understanding single-neuron computation in the neocortex. However, little is known about how orientation can be read out from the activity of neural populations, in particular in alert animals. Our study is a first step toward that goal. We recorded from up to 20 well isolated single neurons in the primary visual cortex of alert macaques simultaneously and applied a simple, neurally plausible decoder to read out the population code. We focus on two questions: First, what are the time course and the timescale at which orientation can be read out from the population response? Second, how complex does the decoding mechanism in a downstream neuron have to be to reliably discriminate between visual stimuli with different orientations? We show that the neural ensembles in primary visual cortex of awake macaques represent orientation in a way that facilitates a fast and simple readout mechanism: With an average latency of 30--80 ms, the population code can be read out instantaneously with a short integration time of only tens of milliseconds, and neither stimulus contrast nor correlations need to be taken into account to compute the optimal synaptic weight pattern. Our study shows that---similar to the case of single-neuron computation---the representation of orientation in the spike patterns of neural populations can serve as an exemplary case for understanding the computations performed by neural ensembles underlying visual processing during behavior.},
	author = {Berens, Philipp and Ecker, Alexander S and Cotton, R James and Ma, Wei Ji and Bethge, Matthias and Tolias, Andreas S},
	copyright = {Copyright {\copyright} 2012 the authors 0270-6474/12/3210618-09\$15.00/0. This article is freely available online through the J Neurosci Open Choice option.},
	doi = {10.1523/jneurosci.1335-12.2012},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	language = {en},
	month = aug,
	note = {00000 tex.ids= Berens12a publisher: Society for Neuroscience section: Articles},
	number = {31},
	pages = {10618--10626},
	pmid = {22855811},
	title = {A {Fast} and {Simple} {Population} {Code} for {Orientation} in {Primate} {V1}},
	url = {https://www.jneurosci.org/content/32/31/10618},
	urldate = {2020-11-09},
	volume = {32},
	year = {2012},
	bdsk-url-1 = {https://www.jneurosci.org/content/32/31/10618},
	bdsk-url-2 = {https://doi.org/10.1523/jneurosci.1335-12.2012}}

@techreport{bernert_fully_2017,
	abstract = {Spike sorting is a crucial step of neural data processing widely used in neuroscience and neuroprosthetics. However, current methods remain not fully automatic and require heavy computations making them not embeddable in implantable devices. To overcome these limitations, we propose a novel method based on an artificial spiking neural network designed to process neural data online and completely automatically. An input layer continuously encodes the data stream into artificial spike trains, which are then processed by two further layers to output artificial trains of spikes reproducing the real spiking activity present in the input signal. The proposed method can be adapted to process several channels simultaneously in the case of tetrode recordings. It outperforms two existing algorithms at low SNR and has the advantage to be compatible with neuromorphic computing and the perspective of being embedded in very low-power analog systems for future implantable devices serving neurorehabilitation applications.},
	author = {Bernert, Marie and Yvert, Blaise},
	copyright = {{\copyright} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	doi = {10.1101/236224},
	institution = {bioRxiv},
	keywords = {⛔ No INSPIRE recid found},
	language = {en},
	month = dec,
	note = {tex.ids= Bernert2017a section: New Results type: article},
	pages = {236224},
	title = {Fully unsupervised online spike sorting based on an artificial spiking neural network},
	url = {https://www.biorxiv.org/content/10.1101/236224v1},
	urldate = {2022-04-08},
	year = {2017},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/236224v1},
	bdsk-url-2 = {https://doi.org/10.1101/236224}}

@article{bernert_attention-based_2018,
	abstract = {Bio-inspired computing using artificial spiking neural networks promises performances outperforming currently available computational approaches. Yet, the number of applications of such networks remains limited due to the absence of generic training procedures for complex pattern recognition, which require the design of dedicated architectures for each situation. We developed a spike-timing-dependent plasticity (STDP) spiking neural network (SSN) to address spike-sorting, a central pattern recognition problem in neuroscience. This network is designed to process an extracellular neural signal in an online and unsupervised fashion. The signal stream is continuously fed to the network and processed through several layers to output spike trains matching the truth after a short learning period requiring only few data. The network features an attention mechanism to handle the scarcity of action potential occurrences in the signal, and a threshold adaptation mechanism to handle patterns with different sizes. This method outperforms two existing spike-sorting algorithms at low signal-to-noise ratio (SNR) and can be adapted to process several channels simultaneously in the case of tetrode recordings. Such attention-based STDP network applied to spike-sorting opens perspectives to embed neuromorphic processing of neural data in future brain implants.},
	author = {Bernert, Marie and Yvert, Blaise},
	doi = {10.1142/s0129065718500594},
	issn = {0129-0657},
	journal = {International Journal of Neural Systems},
	keywords = {⛔ No INSPIRE recid found},
	month = dec,
	note = {00016 tex.ids= Bernert2019, Bernert2019a publisher: World Scientific Publishing Co.},
	number = {08},
	pages = {1850059},
	title = {An {Attention}-{Based} {Spiking} {Neural} {Network} for {Unsupervised} {Spike}-{Sorting}},
	url = {https://www.worldscientific.com/doi/10.1142/S0129065718500594},
	urldate = {2021-01-26},
	volume = {29},
	year = {2018},
	bdsk-url-1 = {https://www.worldscientific.com/doi/10.1142/S0129065718500594},
	bdsk-url-2 = {https://doi.org/10.1142/s0129065718500594}}

@article{dan_efficient_1996,
	author = {Dan, Yang and Atick, Joseph J and Reid, R C},
	doi = {10.1523/jneurosci.16-10-03351.1996},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	keywords = {\#nosource, ⛔ No INSPIRE recid found},
	month = may,
	number = {10},
	pages = {3351--3362},
	title = {Efficient coding of natural scenes in the lateral geniculate nucleus: experimental test of a computational theory},
	volume = {16},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1523/jneurosci.16-10-03351.1996}}
